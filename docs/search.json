[
  {
    "objectID": "los.html",
    "href": "los.html",
    "title": "los",
    "section": "",
    "text": "# tutaj bedzie losowanie pytan"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tu beda fajne dashbordy i w ogóle",
    "section": "",
    "text": "Untitled\n\n\n\n\n\n\nSzymon Door\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Post\n\n\n\nIAD\n\n\n\nPost description\n\n\n\nSzymon Door\n\n\nAug 10, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#algebra-zaawansowana",
    "href": "posts/10-08-2025-first-post/index.html#algebra-zaawansowana",
    "title": "My Post",
    "section": "1. Algebra zaawansowana",
    "text": "1. Algebra zaawansowana\n\n1. Definicja, własności i wybrane zastosowania macierzy Jordana.\n\nDEFINICJA (Klatka Jordana)\nMacierz \\(J_r(\\lambda) \\in M_r(\\mathbb{K})\\) postaci: \\[\nJ_r(\\lambda) =\n\\begin{pmatrix}\n\\lambda & 1 & 0 & \\cdots & 0 \\\\\n0 & \\lambda & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda & 1 \\\\\n0 & 0 & \\cdots & 0 & \\lambda\n\\end{pmatrix}\n\\] gdzie \\(\\lambda \\in \\mathbb{K}\\), nazywamy klatką Jordana stopnia \\(r\\). W szczególnym przypadku \\(J_1(\\lambda) = [\\lambda]\\).\n\n\nDEFINICJA (Macierz Jordana)\nMacierz blokową \\(J \\in M_n(\\mathbb{K})\\) postaci: \\[\nJ =\n\\begin{pmatrix}\nJ_{n_1}(\\lambda_1) & & & \\\\\n& J_{n_2}(\\lambda_2) & & \\\\\n& & \\ddots & \\\\\n& & & J_{n_k}(\\lambda_k)\n\\end{pmatrix}\n\\] gdzie \\(n_1 + n_2 + \\dots + n_k = n\\), \\(\\lambda_1, \\dots, \\lambda_k \\in \\mathbb{K}\\) oraz wszystkie niewypisane elementy są zerami, nazywamy macierzą Jordana.\n\n\nTWIERDZENIE (Postać Jordana macierzy)\nNiech \\(A \\in M_n(\\mathbb{K})\\), gdzie \\(\\mathbb{K} = \\mathbb{R}\\) lub \\(\\mathbb{K} = \\mathbb{C}\\). Wtedy istnieje macierz nieosobliwa \\(P \\in M_n(\\mathbb{K})\\) taka, że macierz \\(J = P^{-1}AP\\) jest macierzą Jordana. Macierz \\(J\\) nazywamy macierzą Jordana macierzy A. Jest ona wyznaczona jednoznacznie z dokładnością do kolejności klatek Jordana.\n\n\nWłasności Macierzy Jordana\n\nWartości własne: Skalary \\(\\lambda_1, \\dots, \\lambda_k\\) tworzące główną przekątną macierzy Jordana \\(J\\) są jej wartościami własnymi.\nZwiązek z diagonalizacją: Każda macierz diagonalna jest macierzą Jordana (z klatkami wymiaru 1x1). Oznacza to, że każda macierz diagonalizowalna jest podobna do pewnej macierzy Jordana.\nLiczba klatek Jordana:\n\nLiczba wszystkich klatek Jordana w macierzy \\(J\\) jest równa liczbie liniowo niezależnych wektorów własnych macierzy \\(A\\).\nLiczba klatek Jordana odpowiadających konkretnej wartości własnej \\(\\lambda\\) jest równa wymiarowi podprzestrzeni własnej \\(W_\\lambda\\) (krotności geometrycznej tej wartości własnej).\n\nRozmiar klatek Jordana: Suma stopni (wymiarów) wszystkich klatek Jordana odpowiadających wartości własnej \\(\\lambda\\) jest równa krotności algebraicznej tej wartości własnej (czyli jej krotności jako pierwiastka wielomianu charakterystycznego).\nWektory dołączone: Struktura macierzy Jordana (liczba i rozmiary klatek) jest ściśle powiązana z istnieniem tzw. wektorów dołączonych. Dla wartości własnej \\(\\lambda\\) o krotności algebraicznej \\(r\\) istnieje dokładnie \\(r\\) liniowo niezależnych wektorów dołączonych, które tworzą bazę Jordana.\n\n\n\nWybrane Zastosowania Macierzy Jordana\nGłównym zastosowaniem przedstawionym w materiałach jest uproszczenie obliczeń funkcji macierzy.\n\n\nTWIERDZENIE\nJeżeli \\(f\\) jest wielomianem o współczynnikach z ciała \\(\\mathbb{K}\\), zaś \\(J\\) jest macierzą Jordana w postaci blokowej jak w definicji, to zachodzi równość: \\[\nf(J) =\n\\begin{pmatrix}\nf(J_{n_1}(\\lambda_1)) & & & \\\\\n& f(J_{n_2}(\\lambda_2)) & & \\\\\n& & \\ddots & \\\\\n& & & f(J_{n_k}(\\lambda_k))\n\\end{pmatrix}\n\\] Obliczenie funkcji dla całej macierzy sprowadza się do obliczenia jej dla poszczególnych klatek Jordana.\n\n\nTWIERDZENIE (Funkcja klatki Jordana)\nJeżeli \\(J_r(\\lambda)\\) jest klatką Jordana stopnia \\(r\\), to wartość funkcji \\(f(J_r(\\lambda))\\) można obliczyć za pomocą następującego wzoru, wykorzystującego pochodne funkcji \\(f\\): \\[\nf(J_r(\\lambda)) =\n\\begin{pmatrix}\nf(\\lambda) & f'(\\lambda) & \\frac{f''(\\lambda)}{2!} & \\cdots & \\frac{f^{(r-1)}(\\lambda)}{(r-1)!} \\\\\n0 & f(\\lambda) & f'(\\lambda) & \\cdots & \\frac{f^{(r-2)}(\\lambda)}{(r-2)!} \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & f(\\lambda) & f'(\\lambda) \\\\\n0 & 0 & \\cdots & 0 & f(\\lambda)\n\\end{pmatrix}\n\\] To zastosowanie jest kluczowe np. przy obliczaniu eksponenty macierzy \\(e^{At}\\), co jest fundamentalne w rozwiązywaniu układów równań różniczkowych liniowych.\n\n\n\n2. Definicja przestrzeni unitarnej i metoda ortogonalizacji Grama-Schmidta.\nDefinicja: Przestrzeń wektorową, w której wprowadzono iloczyn skalarny nazywamy przestrzenią unitarną.\n\n\nMetroda ortogonalizacji Grama-Schmidta:\n\n\n\n3. Wybrane metody dekompozycji macierzy.\n\nRozkład \\(LU\\)\n\n\n\nRozkład \\(QR\\)\n\n\n\nRozkład \\(SVD\\)\n\n\n\nRozkład \\(Shura\\)\n\n\n\nRozkłąd \\(Choleskiego\\)"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#zaawansowane-metody-uczenia-maszynowego",
    "href": "posts/10-08-2025-first-post/index.html#zaawansowane-metody-uczenia-maszynowego",
    "title": "My Post",
    "section": "2. Zaawansowane metody uczenia maszynowego",
    "text": "2. Zaawansowane metody uczenia maszynowego\n\n1. Zasada działania sieci typu Transformer.\n\nEnkoder Dostaje na wejściu dane wejściowe które następnie są konwertowane na tzw. embeddingi (osadzenia) ponieważ dla komputera łatwiej jest interpretować cyfry. Do powstałej reprezentacji dodajemy tzw. positional embedding’s aby mógł interpretować pozycje słów występujących w sekwencji z uwagi na to, że słowa mogą mieć różne znaczenie ze względu na kolejnośc w zdaniu.\nDziałanie Self-Attention można opisać następująco:\nDla każdego tokenu tworzone są trzy wektory: Query (Q), Key (K) i Value (V).\n\nQuery (Q): Reprezentuje zapytanie, czyli to, czego szukamy w innych tokenach.\nKey (K): Reprezentuje cechy tokenu, które mogą być istotne dla innych tokenów.\nValue (V): Reprezentuje faktyczną wartość lub informację, którą token niesie.\n\nPorównując Query jednego tokenu z Key pozostałych tokenów, obliczana jest waga (stopień „uwagi”), czyli jak bardzo dany token powinien brać pod uwagę inny token.\nWagi te są następnie używane do zsumowania Value tokenów w sposób ważony, co daje nową reprezentację tokenu uwzględniającą kontekst całego zdania.\nPonieważ jeden mechanizm uwagi mógłby koncentrować się tylko na jednym aspekcie relacji między słowami, w transformerze stosuje się Multi-Head Attention – wiele równoległych głów uwagi. Każda z nich może analizować inny typ powiązań (np. składnię, znaczenie, zależności czasowe), a wyniki są łączone w jedną bogatszą reprezentację.\nPo bloku uwagi wyniki są przekazywane przez Feed-Forward Network – prostą, w pełni połączoną sieć neuronową, która przetwarza każdy token niezależnie, umożliwiając modelowi tworzenie bardziej złożonych reprezentacji. Każda warstwa transformera zawiera również resztkowe połączenia (residual connections) i normalizację warstw (Layer Normalization), co pozwala na stabilniejsze i szybsze uczenie się głębokiego modelu.\nDekoder\nDekoder odpowiedzialny jest za generowanie sekwencji wyjściowej. Token wyjściowy jest tworzony na podstawie: - wcześniej wygenerowanych tokenów, - reprezentacji wejściowej dostarczonej przez enkoder\n\nMasked Multi-Head Self Attention\n\n\nDekoder używa mechanizmu samo-uwagi na już wygenerowanych tokenach\nMaskowanie, czyli model nie może “patrzeć w przyszłość”, znaczy to, że uwaga jest ograniczona do aktualnych i wcześniejszych tokenów.\nDzięki temuu dredykcja kolejnego słowa bazuje tylko na wcześniejszych słowach, a nie na tych które właśnie będą generowane\n\n\nAdd & Norm\n\n\nWarstwy normalizacji oraz reszt\n\n\nMulti-Head Cross-Attention\n\n\nDekoder zwraca uwagę na wyjście z enkodera\nMechanizm polega na tym, że Query(Q) pochodzi z dekodera, a Key(K) i Value(V) z enkodera dzięki temu dekoder szuka odpowiednich fragmentów informacji potrzebnych do wygenerowania kolejnego słowa\n\n\nAdd & Norm\nFeed-Forward Network (FFN)\nAdd & Norm\n\n\n\n2. Problem zanikającego i eksplodującego gradientu w modelach rekurencyjnych.\nProblemy zanikającegi i eksplodującego gradientu można przedstawić w następujący sposób:\n\nZanikający gradient: Coraz mniejsze gradienty powodują coraz mniejsze zmniany wag w węzłach głebkiej sieci neuronowej, co porowadzi do niewielkiego lub żadnego uczenia się.\n\nAby zminimalizować ten problem stosuje się techniki takie jak:\n\nMniejszy batch size podczas uczenia sieci;\nW przypadku sieci\nEksplodujący gradient: Gradienty stają się zaskakująco duże, przez co następują duże aktualizacje wag (powtarzające się mnożenie dużych wag) każdego węzła w głebokiej sieci neuronowej\n\n\n\n3. Rozwiązania z zakresu technik głębokiego uczenia dedykowanych do zadań wizji komputerowej.\n\nKonwolucyjne sieci neuronowe (CNN, Convolutional Neural Networks)\nSieci generatywne\n\n\nGAN (Geeral Adversarial Networks)\nVariacynjy Auroenkoder (VAE) - probabilistyczne modele generatywne\nDiffusion Models (np. DALLE) - obecnie dominujące\n\n\nTransformery w wizji komputerowej\n\n\nVision Transformer (ViT) - dzieli obraz na fragmenty, a następnie traktuje je jak sekwencje tokenów\n\n\nSieci detekcji obiektów\n\n\nOne-stage detectors:\n\nSieci YOLO (You Only Look Once) - szybkie modele które wykrywają obiekty w czasie rzeczywistym\n\nTwo-stage detectors:\n\nR-CNN, Fast R-CNN - najpierw generują regiony zainteresowanie (RoI), potem klasyfikują"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#wdrażanie-modeli-uczenia-maszynowego",
    "href": "posts/10-08-2025-first-post/index.html#wdrażanie-modeli-uczenia-maszynowego",
    "title": "My Post",
    "section": "3. Wdrażanie modeli uczenia maszynowego",
    "text": "3. Wdrażanie modeli uczenia maszynowego\n\n1. Podstawowe komendy REST API służące do komunikacji.\nGET - Pobiera dane z serwera. Nie modyfikuje zasobów.\n\nPrzykład: GET /users — pobierz listę użytkowników.\n\nPOST - Tworzy nowy zasób na serwerze. Przykład: POST /users — dodaj nowego użytkownika (dane w body).\nPUT - Aktualizuje istniejący zasób w całości (zastępuje go nowym).\n\nPrzykład: PUT /users/123 — nadpisz dane użytkownika o ID 123.\n\nPATCH - Aktualizuje tylko część zasobu.\n\nPrzykład: PATCH /users/123 — zmień np. tylko email użytkownika 123.\n\nDELETE - Usuwa zasób z serwera.\n\nPrzykład: DELETE /users/123 — usuń użytkownika o ID 123.\n\n\n\n2. Reaktywność i realizacja w aplikacjach Shiny.\nReaktywność w Shiny to mechanizm, który śledzi zależności między częscią wejściową a wyjściową. Dzięki temu, aplikacja przelicza tylko te elementy, które są od siebie zależne niż wykonywać cały kod od nowa.\n\nPowyższa ilustracja przedstawia etapy reaktywności w Shiny:\n\nW momencie uruchomienia aplikacji Shiny uruchamia (losowe) wyjście. Ponieważ wywołanie to jest zależne od wyników wywołań reaktywnych, tworzy się połączenia z wyrażeniami reaktywnymi. W tym przypadku pierwsze wywołanie nazwijmy je x.\nNastępnie inicjalizowane są wyrażenia reaktywne które są zależne od wyjścia, a następnie kolejno te które są zależne od innych metod aplikacji\nNa sam koniec, wszystkie operacje wymagane do egzekucji wyjścia x zostały policzone a następnie wyświetlone\n\n\nPowyższa ilustracja przedstawia moment w którym dochodzi do modyfikacji danych wejściowych]\n\nWyjście oraz metody, które były zależne do wykonania obliczeń oznacza się jako “invalidated”. Również połączenia z innymi metodami, które bezpośrednio nie miałyby zostać wyświetlone (patrz środkowe wyjście) oraz jednocześnie przypisywana jest nowa wartość dla wejścia (patrz pierwsze wejście od góry).\nW dalszej kolejności znów jedno z wyjść unieważnionych (ang. invalidated) jest poddane egzekucji, która pociąga za sobą egzekucje tych wejść i wyrażeń reaktywnych, które są wymagane do obliczenia wartości lub wyświetlenia wyjścia.\n\n\n\n3. Metody optymalizacji wydajności aplikacji Shiny obsługującej duże zbiory danych.\nOptymalizacja w Shiny sprowadza się do:\n\nMinimalizacji danych w pamięci (agregacje, filtrowanie, server-side processing).\nRozsądnego użycia reaktywności (tylko to, co trzeba, kiedy trzeba).\nWydzielenia ciężkich obliczeń do backendu lub równoległości (future, API).\nSkalowania serwera przy produkcyjnych wdrożeniach."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#wybrane-problemy-teorii-niezawodności",
    "href": "posts/10-08-2025-first-post/index.html#wybrane-problemy-teorii-niezawodności",
    "title": "My Post",
    "section": "4. Wybrane problemy teorii niezawodności",
    "text": "4. Wybrane problemy teorii niezawodności\n\n1. Rozkłady statystyczne stosowane w analizie niezawodności.\n\n1. Rozkład wykładniczy\nFunkcja gęstości prawdopodobieństwa dla zmiennej losowej \\(x \\ge 0\\).\n\nParametr: \\(\\lambda &gt; 0\\) (parametr częstości, rate parameter)\n\n\\[\nf(x; \\lambda) = \\lambda e^{-\\lambda x}\n\\]\n\n\n2. Rozkład Weibulla\nFunkcja gęstości prawdopodobieństwa dla zmiennej losowej \\(x \\ge 0\\).\n\nParametry:\n\n\\(k &gt; 0\\) (parametr kształtu, shape parameter)\n\\(\\lambda &gt; 0\\) (parametr skali, scale parameter)\n\n\n\\[\nf(x; k, \\lambda) = \\frac{k}{\\lambda} \\left(\\frac{x}{\\lambda}\\right)^{k-1} e^{-(x/\\lambda)^k}\n\\]\nUwaga: Gdy \\(k=1\\), rozkład Weibulla sprowadza się do rozkładu wykładniczego z parametrem \\(\\lambda\\).\n\n\n3. Rozkład normalny\nFunkcja gęstości prawdopodobieństwa (PDF) dla zmiennej losowej \\(x \\in (-\\infty, \\infty)\\).\n\nParametry:\n\n\\(\\mu\\) (wartość oczekiwana, mean)\n\\(\\sigma^2 &gt; 0\\) (wariancja, variance), gdzie \\(\\sigma\\) to odchylenie standardowe\n\n\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{ - \\frac{1}{2} \\left( \\frac{x-\\mu}{\\sigma} \\right)^2 }\n\\]\n\n\n4. Rozkład Gamma\nFunkcja gęstości prawdopodobieństwa dla zmiennej losowej \\(x \\ge 0\\).\n\nParametry:\n\n\\(\\alpha &gt; 0\\) (parametr kształtu, shape parameter)\n\\(\\beta &gt; 0\\) (parametr częstości, rate parameter)\n\n\n\\[\nf(x; \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-\\beta x}\n\\]\ngdzie \\(\\Gamma(\\alpha) = \\int_0^\\infty t^{\\alpha-1}e^{-t}dt\\) to funkcja Gamma.\n\n\n5. Rozkład Rayleigha\nFunkcja gęstości prawdopodobieństwa dla zmiennej losowej \\(x \\ge 0\\).\n\nParametr: \\(\\sigma &gt; 0\\) (parametr skali, scale parameter)\n\n\\[\nf(x; \\sigma) = \\frac{x}{\\sigma^2} e^{-x^2 / (2\\sigma^2)}\n\\]\nUwaga: Jest to szczególny przypadek rozkładu Weibulla dla \\(k=2\\).\n\n\n\nRozkład Bernoulliego\nOpisuje wynik pojedynczej próby, która może zakończyć się sukcesem (1) lub porażką (0).\n\nParametr: \\(p \\in [0, 1]\\) (prawdopodobieństwo sukcesu)\nWartości: \\(k \\in \\{0, 1\\}\\)\n\n\\[\nP(X=k) = p^k (1-p)^{1-k}\n\\]\n\n\nRozkład dwumianowy\nOpisuje liczbę sukcesów (\\(k\\)) w \\(n\\) niezależnych próbach Bernoulliego.\n\nParametry:\n\n\\(n \\ge 0\\) (liczba prób, liczba całkowita)\n\\(p \\in [0, 1]\\) (prawdopodobieństwo sukcesu w pojedynczej próbie)\n\nWartości: \\(k \\in \\{0, 1, 2, ..., n\\}\\)\n\n\\[\nP(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}\n\\]\ngdzie \\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\) to symbol Newtona.\n\n\nRozkład Poissona\nOpisuje liczbę zdarzeń w ustalonym przedziale czasu lub przestrzeni, jeśli zdarzenia te zachodzą ze stałą średnią częstotliwością.\n\nParametr: \\(\\lambda &gt; 0\\) (średnia liczba zdarzeń w przedziale)\nWartości: \\(k \\in \\{0, 1, 2, ...\\}\\)\n\n\\[\nP(X=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\n\n\n\n2. Modele szeregowe, równoległe i mieszane obiektów technicznych.\n\nModel szeregowy (ang. series system)\n\nSystem działa tylko wtedy, gdy działają wszystkie jego elementy.\nAwaria jednego elementu powoduje awarię całego systemu.\n\nModel równoległy (ang. parallel system)\n\nSystem działa, jeżeli działa przynajmniej jeden z elementów.\nAwaria następuje dopiero, gdy wszystkie elementy zawiodą.\n\nModel mieszany (ang. mixed system)\n\nRzeczywiste systemy rzadko są idealnie szeregowe lub równoległe.\nNajczęściej są to kombinacje obu typów — niektóre podzespoły muszą działać wszystkie (połączenie szeregowe), a inne mają redundancję (połączenie równoległe).\n\n\n\n\n3. Wskaźniki gotowości systemu - MTBF, MTTR, dostępność eksploatacyjna.\n\nMTBF – Mean Time Between Failures (Średni czas między awariami)\n\nDefinicj: Średni czas pracy systemu pomiędzy kolejnymi awariami wymagającymi naprawy.\nInterpretacja: Jest to miara niezawodności – im większy MTBF, tym system rzadziej ulega awarii.\n\nMTTR – Mean Time To Repair (Średni czas naprawy)\n\nDefinicja: Średni czas potrzebny do przywrócenia systemu do pracy po awarii.\nInterpretacja: Jest to miara utrzymywalności (maintainability) – im mniejszy MTTR, tym szybciej system wraca do działania.\n\nDostępność eksploatacyjna (Availability, A)\n\nDefinicja: Prawdopodobieństwo, że system jest w danym momencie zdolny do wykonania swojej funkcji."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#metody-numeryczne-w-zastosowaniach",
    "href": "posts/10-08-2025-first-post/index.html#metody-numeryczne-w-zastosowaniach",
    "title": "My Post",
    "section": "5 Metody numeryczne w zastosowaniach",
    "text": "5 Metody numeryczne w zastosowaniach\n\n1. Wartości własne macierzy i sposoby ich wyznaczania.\n\nMetoda potęgowa\nSłuży do wyznaczenia maksymalnej co do modułu wartości własnej i odpowiadającego jej wektora własnego\n\n\n\nMetoda iteracji odwrotnej\n\nWariant metody potęgowej służący do wyznaczenia wartości własnej macierzy, najbliższej zeru​\nPodstawą jest twierdzenie, że wartości własne macierzy odwrotnej są odwrotnościami wartości własnych macierzy danej\nSposób postępowania jest podobny do metody zwykłej z zastrzeżeniem dotyczącym kroku potęgowego\n\n\n\n\nMacierz Hessenbergowska (górna)\n\n\n\n2. Metody Rungego-Kutty do rozwiązywania równań różniczkowych.\n\nMetoda Rungego-Kutty (RK)\nMetody Rungego-Kutty służą do numerycznego rozwiązywania równań różniczkowych postaci \\(y' = f(t, y)\\) z warunkiem początkowym \\(y(t_0) = y_0\\). Idea polega na zastąpieniu prostego przybliżenia z metody Eulera (używającej nachylenia tylko na początku kroku) przez ważoną średnią nachyleń obliczonych w kilku punktach wewnątrz kroku czasowego \\(h\\). Daje to znacznie dokładniejszą aproksymację.\n\n\nPorównanie metod RK 1., 2. i 4. rzędu\n\n1. Metoda 1. rzędu (RK1) – Metoda Eulera\nTo najprostsza forma, stanowiąca punkt odniesienia.\n\nIdea: Ekstrapolacja rozwiązania na podstawie nachylenia w punkcie początkowym kroku.\nWzór: \\[ y_{n+1} = y_n + h \\cdot f(t_n, y_n) \\]\n\n\n\n2. Metoda 2. rzędu (RK2) – np. Metoda Heuna\nZnaczne ulepszenie w stosunku do metody Eulera przy niewielkim dodatkowym koszcie.\n\nIdea: Uśrednienie nachylenia z początku i (oszacowanego) końca kroku.\nWzór:\n\n\\(k_1 = f(t_n, y_n)\\) (nachylenie na początku)\n\\(k_2 = f(t_n + h, y_n + h \\cdot k_1)\\) (nachylenie na końcu, oszacowane metodą Eulera)\n\\(y_{n+1} = y_n + h \\cdot \\frac{k_1 + k_2}{2}\\) (użycie średniego nachylenia)\n\n\n\n\n3. Metoda 4. rzędu (RK4) – Klasyczna metoda Rungego-Kutty\nNajpopularniejsza metoda, oferująca doskonały kompromis między dokładnością a kosztem obliczeniowym.\n\nIdea: Obliczenie ważonej średniej nachyleń z początku, dwóch punktów w środku i końca kroku. Wagi są dobrane tak, by zmaksymalizować dokładność.\nWzór:\n\n\\(k_1 = f(t_n, y_n)\\)\n\\(k_2 = f(t_n + \\frac{h}{2}, y_n + h \\frac{k_1}{2})\\)\n\\(k_3 = f(t_n + \\frac{h}{2}, y_n + h \\frac{k_2}{2})\\)\n\\(k_4 = f(t_n + h, y_n + h k_3)\\)\n\\(y_{n+1} = y_n + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)\\)\n\n\n\n\n\nJak wyznaczane są parametry metody?\nParametry (współczynniki wagowe i punkty pośrednie) nie są przypadkowe. Wyznacza się je poprzez porównanie rozwinięcia w szereg Taylora numerycznej formuły metody z rozwinięciem w szereg Taylora dokładnego rozwiązania \\(y(t_n+h)\\).\nAlgorytm wyznaczania parametrów:\n\nZapisz dokładne rozwiązanie w postaci szeregu Taylora wokół punktu \\(t_n\\) do rzędu \\(p\\): \\(y(t_n+h) = y_n + h \\cdot y'(t_n) + \\frac{h^2}{2} y''(t_n) + \\dots + \\frac{h^p}{p!} y^{(p)}(t_n) + O(h^{p+1})\\)\nWyraź pochodne \\(y', y'', \\dots\\) za pomocą funkcji \\(f(t,y)\\) i jej pochodnych cząstkowych (np. \\(y' = f\\), \\(y'' = \\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial y} f\\), itd.).\nRozwiń wzór numeryczny metody RK (z niewiadomymi parametrami) również w szereg Taylora względem potęg kroku \\(h\\).\nPorównaj współczynniki przy tych samych potęgach \\(h\\) (\\(h^1, h^2, \\dots, h^p\\)) w obu rozwinięciach.\nRozwiąż powstały układ równań (zazwyczaj nieliniowych) na nieznane parametry. Co ciekawe, dla rzędów wyższych niż 1, układ ten ma często więcej niewiadomych niż równań, co prowadzi do istnienia całych rodzin metod RK tego samego rzędu (np. istnieje wiele różnych metod RK2).\n\n\n\nRząd metody a dokładność obliczeń\nRząd metody (\\(p\\)) jest kluczowym wskaźnikiem jej dokładności. Określa on, jak szybko maleje globalny błąd obliczeń wraz ze zmniejszaniem kroku \\(h\\). Zależność ta jest następująca:\nGlobalny błąd \\(\\approx C \\cdot h^p\\)\ngdzie \\(C\\) to stała zależna od problemu.\n\nRK1 (rząd 1): Błąd jest proporcjonalny do \\(h\\). Dwukrotne zmniejszenie kroku zmniejsza błąd dwukrotnie. Jest to bardzo wolna zbieżność.\nRK2 (rząd 2): Błąd jest proporcjonalny do \\(h^2\\). Dwukrotne zmniejszenie kroku zmniejsza błąd czterokrotnie.\nRK4 (rząd 4): Błąd jest proporcjonalny do \\(h^4\\). Dwukrotne zmniejszenie kroku zmniejsza błąd aż szesnastokrotnie!\n\nWniosek: Metoda RK4 pozwala osiągnąć bardzo wysoką dokładność przy znacznie większym kroku \\(h\\) w porównaniu do metod niższych rzędów, co czyni ją niezwykle wydajną i popularną w praktycznych zastosowaniach.\n\n\n\n3. Generatory liczb pseudolosowych i ich zastosowanie do obliczania całek oznaczonych metodą Monte-Carlo.\nDlaczego generatory liczb pseudolosowych? Ponieważ znając algorytm oraz ziarno generatora jesteśmy w stanie przewidzieć kolejne elementy ciągu - brak w tym losowości\nGeneratory możemy podzielić na:\n\nLiniowe\n\nLinowy generator kongruentny \\[\nx_{n+1} = (ax_n+b)(\\text{mod} m)  \n\\]\nGenerator Fibbonacciego \\[\nx_n = (x_{n-l} + n_{n-k})(\\text{mod} m)\n\\]\n\nNieliniowe\n\nCharakteryzują się bardzo długim okresem i dobrą równomiernością rozkładu liczb. Oparte na bardziej złożonych zależnościach, np. Mersenne Twister\n\n\n\nMetoda Monte Carlo to technika numeryczna służąca do przybliżania wartości całek oznaczonych. Jest szczególnie użyteczna w przypadkach, gdy: * Funkcja podcałkowa jest bardzo skomplikowana. * Obszar całkowania ma nieregularny kształt. * Całka jest wielowymiarowa (np. całka podwójna lub potrójna), co sprawia, że tradycyjne metody analityczne lub numeryczne (jak metoda trapezów czy Simpsona) stają się nieefektywne.\nGłówna idea: Zamiast analitycznie obliczać pole pod wykresem funkcji, “strzelamy” losowo punktami w zdefiniowany obszar i na podstawie proporcji trafień szacujemy wynik.\n\n2. Generatory liczb pseudolosowych\nGeneratory liczb pseudolosowych to algorytmy, które produkują sekwencje liczb naśladujące właściwości liczb losowych. W kontekście całkowania potrzebujemy generatora, który potrafi tworzyć liczby z rozkładu jednostajnego (każda liczba w danym zakresie ma takie samo prawdopodobieństwo wylosowania).\nSłużą one do generowania współrzędnych (x, y) dla każdego z losowych “strzałów”. Jakość i statystyczne właściwości generatora (np. brak korelacji między kolejnymi liczbami) mają bezpośredni wpływ na dokładność uzyskanej aproksymacji całki.\nZałóżmy, że chcemy obliczyć całkę oznaczoną: \\[ I = \\int_a^b f(x) dx \\]\nReprezentuje ona pole powierzchni pod krzywą \\(y = f(x)\\) na przedziale od \\(x=a\\) do \\(x=b\\).\nAlgorytm postępowania:\n\nOkreślenie obszaru próbkowania: Tworzymy prostokąt, który całkowicie zawiera interesujący nas obszar pod wykresem.\n\nSzerokość prostokąta to długość przedziału całkowania: \\(w = b - a\\).\nWysokość prostokąta \\(M\\) musi być równa lub większa od maksymalnej wartości funkcji \\(f(x)\\) na przedziale \\([a, b]\\). Czyli \\(M \\ge \\max_{x \\in [a,b]} f(x)\\).\nPole tego prostokąta wynosi: \\(A_{\\text{prostokąt}} = (b-a) \\cdot M\\).\n\nLosowe próbkowanie: Przy użyciu generatora liczb pseudolosowych generujemy dużą liczbę \\(N\\) losowych punktów \\((x_i, y_i)\\) o współrzędnych równomiernie rozłożonych wewnątrz prostokąta:\n\n\\(x_i\\) jest losowane z przedziału \\([a, b]\\).\n\\(y_i\\) jest losowane z przedziału \\([0, M]\\).\n\nZliczanie “trafień”: Dla każdego wygenerowanego punktu \\((x_i, y_i)\\) sprawdzamy, czy znajduje się on pod wykresem funkcji \\(f(x)\\). Warunek ten jest spełniony, jeśli: \\[ y_i \\le f(x_i) \\] Zliczamy wszystkie punkty, które spełniają ten warunek. Nazwijmy tę liczbę \\(k\\).\nAproksymacja pola: Założenie metody Monte Carlo mówi, że stosunek pola pod wykresem do pola całego prostokąta jest w przybliżeniu równy stosunkowi liczby punktów pod wykresem (\\(k\\)) do całkowitej liczby wylosowanych punktów (\\(N\\)).\n\\[ \\frac{\\text{Pole pod wykresem}}{\\text{Pole prostokąta}} \\approx \\frac{k}{N} \\]\nPrzekształcając ten wzór, otrzymujemy przybliżoną wartość całki:\n\\[ I \\approx \\frac{k}{N} \\cdot \\text{Pole prostokąta} \\]\nCo daje: \\[ \\int_a^b f(x) dx \\approx \\frac{k}{N} \\cdot (b-a) \\cdot M \\]\n\n#### 4. Właściwości i uwagi\n\nZbieżność: Dokładność metody rośnie wraz ze wzrostem liczby prób \\(N\\). Błąd statystyczny aproksymacji jest proporcjonalny do \\(\\frac{1}{\\sqrt{N}}\\), co oznacza, że aby dziesięciokrotnie zwiększyć dokładność, trzeba stukrotnie zwiększyć liczbę losowań.\nZalety:\n\nProstota implementacji.\nNiezwykła skuteczność przy całkach wielowymiarowych (gdzie inne metody zawodzą z powodu tzw. “klątwy wymiarowości”).\nŁatwość adaptacji do nieregularnych i złożonych obszarów całkowania.\n\nWady:\n\nWolna zbieżność w porównaniu do deterministycznych metod numerycznych dla prostych całek jednowymiarowych.\nWynik jest probabilistyczny – każde uruchomienie algorytmu da nieco inny, choć zbliżony, rezultat."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#podstawy-teorii-sterowania-notatki-na-podstawie-książki",
    "href": "posts/10-08-2025-first-post/index.html#podstawy-teorii-sterowania-notatki-na-podstawie-książki",
    "title": "My Post",
    "section": "6. Podstawy teorii sterowania Notatki na podstawie książki",
    "text": "6. Podstawy teorii sterowania Notatki na podstawie książki\n\n1. Sposoby tworzenia modeli matematycznych obiektów lub procesów sterowania. Identyfikacja procesu sterowania.\nModel matematyczny jest zdefiniowany jako zależność sygnałów wyjściowych od sygnałów wejściowych, wyrażona w postaci równań matematycznych (s. 13).\nSposoby tworzenia modeli matematycznych to (s. 52):\n\nRównania różniczkowe i różnicowe:\n\nRównania różniczkowe opisują obiekty ciągłe. Ogólna postać dla obiektu liniowego, stacjonarnego i jednowymiarowego jest przedstawiona na s. 52.\nRównania różnicowe są odpowiednikiem dla układów dyskretnych, gdzie czas ma wartość dyskretną (s. 53).\n\nTransmitancje operatorowe:\n\nDla układów ciągłych jest to stosunek transformaty Laplace’a sygnału wyjściowego Y(s) do transformaty Laplace’a sygnału wejściowego U(s), przy zerowych warunkach początkowych (s. 56).\nDla układów dyskretnych jest to stosunek transformaty Z sygnału wyjściowego Y(z) do transformaty sygnału wejściowego U(z) (s. 58).\n\nRównania stanu:\n\nOpisują dynamikę układu za pomocą układu równań różniczkowych (dla układów ciągłych) lub różnicowych (dla układów dyskretnych) pierwszego rzędu. Model ten składa się z równania stanu (opisującego dynamikę wewnętrznych zmiennych stanu) i równania wyjścia (wiążącego zmienne stanu z sygnałem wyjściowym) (s. 63-65).\n\nCharakterystyki czasowe i częstotliwościowe:\n\nChociaż są to głównie narzędzia analizy, mogą również służyć jako forma modelu matematycznego, zwłaszcza gdy są wyznaczane eksperymentalnie. Przykłady to odpowiedź skokowa h(t), odpowiedź impulsowa g(t) (s. 68) oraz charakterystyki częstotliwościowe (np. amplitudowo-fazowa) (s. 72).\n\n\nIdentyfikacja procesu sterowania (s. 84):\n\nAnaliza teoretyczna: Budowa modelu na podstawie znanych praw fizycznych rządzących procesem.\nAnaliza eksperymentalna: Określenie modelu na podstawie obserwacji “odpowiedzi układu na […] typowe wymuszenia” (s. 85). Konkretnym przykładem jest “Eksperymentalne wyznaczanie charakterystyk częstotliwościowych” (s. 81), które polega na rejestrowaniu odpowiedzi obiektu na sygnał harmoniczny o różnej częstotliwości i na tej podstawie budowaniu modelu. Innym przykładem jest wyznaczanie charakterystyki statycznej przez pomiary w stanie ustalonym (s. 53).\n\n\n\n\n2. Charakterystyka statyczna i charakterystyka dynamiczna procesu. Przykłady obu charakterystyk dla wybranego procesu.\nCharakterystyka statyczna:\nJest to zależność sygnału wyjściowego od wejściowego w stanie ustalonym (s. 53). Wyznacza się ją z równania różniczkowego poprzez przyrównanie wszystkich pochodnych do zera. W przypadku opisu za pomocą transmitancji operatorowej G(s), charakterystykę statyczną uzyskuje się, przyjmując s = 0 (s. 57). Definiuje ona statyczne wzmocnienie obiektu.\nCharakterystyka dynamiczna:\nCharakterystyka dynamiczna pokazuje, jak układ zachowuje się w czasie w odpowiedzi na zmianę sygnału wejściowego. Główne formy opisu właściwości dynamicznych to (s. 52, 68, 72):\n\nCharakterystyki czasowe: Pokazują odpowiedź układu w dziedzinie czasu. Najważniejsze z nich:\n\nOdpowiedź skokowa h(t): Odpowiedź na sygnał jednostkowy 1(t).\nOdpowiedź impulsowa g(t): Odpowiedź na impuls Diraca δ(t).\n\nCharakterystyki częstotliwościowe: Opisują zachowanie układu w stanie ustalonym przy wymuszeniu sinusoidalnym o różnej częstotliwości. Przykłady to charakterystyka amplitudowo-fazowa (wykres Nyquista) oraz logarytmiczne charakterystyki amplitudowa i fazowa (wykresy Bodego).\n\nPrzykład dla wybranego procesu (Człon inercyjny pierwszego rzędu, s. 112):\n\nRównanie różniczkowe: \\(T * \\frac{dy(t)}{dt} + y(t) = K * u(t)\\)\nTransmitancja: \\(G(s) = \\frac{K}{(Ts + 1)}\\)\n\n\nCharakterystyka statyczna:\n\nZ równania różniczkowego: W stanie ustalonym \\(\\frac{dy(t)}{dt} = 0\\), co daje \\(y(t) = K * u(t)\\). Jest to zależność liniowa, a jej nachylenie \\(K\\) to wzmocnienie statyczne.\nZ transmitancji: \\(G(0) = \\frac{K}{(T*0 + 1)}= K\\).\n\nCharakterystyki dynamiczne:\n\nOdpowiedź skokowa (czasowa): \\(h(t) = K(1 - e^{(\\frac{-t}{T})})\\). Jest to narastająca funkcja wykładnicza, która asymptotycznie dąży do wartości \\(K\\) (pokazana na Rys. 4.11).\nCharakterystyka amplitudowo-fazowa (częstotliwościowa): Jest to półokrąg o średnicy \\(K\\) w prawej półpłaszczyźnie zespolonej (pokazana na Rys. 4.11).\nLogarytmiczna charakterystyka amplitudowa: Dla małych częstotliwości jest to linia pozioma na poziomie \\(20logK\\), a dla dużych częstotliwości opada z nachyleniem -20 dB/dekadę (pokazana na Rys. 4.11).\n\n\n\n\n\n3. Metody ograniczania skutków niepożądanego oddziaływania na proces.\nNiepożądane oddziaływania na proces są “zakłóceniami” (s. 12). Główną metodą ograniczania ich skutków jest zastosowanie sterowania w układzie zamkniętym, czyli regulacji ze sprzężeniem zwrotnym (s. 15).\nMechanizm działania tej metody jest następujący (s. 15-17):\n\nPomiar sygnału wyjściowego: Wartość regulowanej wielkości wyjściowej \\(y(t)\\) jest stale mierzona.\nPorównanie z wartością zadaną: Zmierzona wartość jest porównywana z wartością pożądaną (zadaną) \\(w(t)\\). Różnica tych sygnałów \\(e(t) = w(t) - y(t)\\) nazywana jest uchybem regulacji.\nDziałanie regulatora: Uchyb \\(e(t)\\) jest wprowadzany do regulatora, który na jego podstawie generuje odpowiedni sygnał sterujący \\(u(t)\\). Sygnał ten ma na celu takie oddziaływanie na obiekt, aby zminimalizować uchyb, a tym samym skompensować wpływ zakłóceń."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#systemy-obsługi-masowej",
    "href": "posts/10-08-2025-first-post/index.html#systemy-obsługi-masowej",
    "title": "My Post",
    "section": "7. Systemy obsługi masowej",
    "text": "7. Systemy obsługi masowej\n\n1. Korzystając z oznaczenia Kendalla podać charakterystykę systemu M/D/n/m.\n\nCharakterystyka systemu M/D/n/m:\n\nM - czas przybycia klientów jest rozkładem wykładniczym;\nD - czas trwania obsługi jest opisany rozkładem deterministycznym (stałym);\nn - liczba liczba serwerów równoległych\nm - maksymalna liczba osób w systemie (w kolejce (poczekalni) i w obsłudze).\n\n\n\n2. Korzystając z formuł Littla opisz zależność pomiędzy oczekiwaną liczbą klientów w systemie a średnim czasem spędzonym w systemie.\n\n\n\n3. Różnice w oszacowaniu własności systemów obsługi ze względu na sposób połączenia serwerów\nAnaliza systemów kolejkowych wymaga zrozumienia, jak architektura połączeń między serwerami wpływa na kluczowe metryki wydajności, takie jak czas oczekiwania czy wykorzystanie zasobów. Poniżej przedstawiono trzy fundamentalne modele połączeń i metody ich analizy.\n\nSerwery połączone równolegle z jedną, wspólną kolejką.\nSerwery połączone równolegle z oddzielnymi kolejkami dla każdego serwera.\nSerwery połączone szeregowo (kaskadowo).\n\n\n\n1. Serwery Równoległe z Jedną Wspólną Kolejką (Model M/M/c)\nJest to najczęściej spotykany i zazwyczaj najwydajniejszy model obsługi w miejscach takich jak banki (jedna kolejka do wielu okienek), infolinie czy lotniska (jedna kolejka do kontroli bezpieczeństwa).\nOpis:\n\nKlienci (zgłoszenia) wchodzą do jednej, wspólnej kolejki.\nGdy dowolny z \\(c\\) serwerów staje się wolny, pierwszy klient z kolejki jest kierowany do jego obsługi.\nSystem jest opisywany w notacji Kendalla jako M/M/c.\n\n\nWłaściwości i sposób oszacowania:\n\nWydajność i równoważenie obciążenia: System jest wysoce wydajny. Żaden serwer nie jest bezczynny, jeśli w kolejce czeka choćby jedno zgłoszenie. Obciążenie jest automatycznie i idealnie zrównoważone między wszystkimi serwerami.\nZłożoność analizy: Analiza matematyczna jest bardziej złożona niż dla pojedynczego serwera. Wykorzystuje się wzory Erlanga-C, które pozwalają obliczyć kluczowe metryki:\n\nPrawdopodobieństwo, że system jest pusty (\\(P_0\\)): Wymaga obliczenia sumy szeregu.\nPrawdopodobieństwo oczekiwania w kolejce (\\(P_w\\)): Znane jako wzór C Erlanga, zależy od \\(P_0\\), liczby serwerów \\(c\\) i współczynnika wykorzystania systemu \\(\\rho\\).\nŚrednia liczba klientów w kolejce (\\(L_q\\)): \\(L_q = P_w \\cdot \\frac{\\rho}{1 - \\rho}\\)\nŚredni czas oczekiwania w kolejce (\\(W_q\\)): \\(W_q = L_q / \\lambda\\) (gdzie \\(\\lambda\\) to średnie natężenie zgłoszeń).\nŚredni czas pobytu w systemie (\\(W\\)): \\(W = W_q + 1/\\mu\\) (gdzie \\(\\mu\\) to średnie tempo obsługi jednego serwera).\n\nKluczowa metryka: Współczynnik wykorzystania systemu \\(\\rho = \\lambda / (c \\cdot \\mu)\\). Warunkiem stabilności systemu jest \\(\\rho &lt; 1\\).\n\nPodsumowując: Ten model minimalizuje średni czas oczekiwania klienta, ponieważ zasoby (serwery) są wykorzystywane w sposób optymalny.\n\n\n\n2. Serwery Równoległe z Oddzielnymi Kolejkami (Model \\(c \\times\\) M/M/1)\nTen model jest typowy dla supermarketów z wieloma kasami, gdzie każda kasa ma swoją własną kolejkę.\nOpis:\n\nIstnieje \\(c\\) niezależnych kolejek, po jednej dla każdego z \\(c\\) serwerów.\nKlient po przybyciu wybiera jedną z kolejek (np. najkrótszą) i pozostaje w niej.\n\n\nWłaściwości i sposób oszacowania:\n\nWydajność i równoważenie obciążenia: System ten jest z natury mniej wydajny niż system z jedną kolejką. Może wystąpić sytuacja, w której jeden serwer jest bezczynny (jego kolejka jest pusta), podczas gdy w innych kolejkach klienci oczekują na obsługę. Równoważenie obciążenia jest niedoskonałe i zależy od decyzji klientów.\nZłożoność analizy: Analiza jest znacznie prostsza, ponieważ system można traktować jako \\(c\\) niezależnych systemów M/M/1.\n\nZakładając, że strumień wejściowy \\(\\lambda\\) jest równomiernie rozłożony na \\(c\\) kolejek, każda z nich otrzymuje strumień zgłoszeń o natężeniu \\(\\lambda_i = \\lambda / c\\).\nDla każdej z tych kolejek stosuje się proste wzory dla systemu M/M/1:\n\nWspółczynnik wykorzystania pojedynczego serwera: \\(\\rho_i = \\lambda_i / \\mu = (\\lambda / c) / \\mu = \\rho\\).\nŚrednia liczba klientów w i-tej kolejce: \\(L_{q_i} = \\frac{\\rho_i^2}{1 - \\rho_i}\\).\nŚredni czas oczekiwania w i-tej kolejce: \\(W_{q_i} = L_{q_i} / \\lambda_i\\).\n\nCałkowite właściwości systemu uzyskuje się poprzez uśrednienie wyników z poszczególnych kolejek.\n\nZjawisko “Jockeying”: W praktyce klienci mogą zmieniać kolejki, jeśli widzą, że inna porusza się szybciej. To zjawisko komplikuje analizę i zbliża właściwości systemu do modelu z jedną wspólną kolejką, ale rzadko jest uwzględniane w podstawowych modelach analitycznych.\n\nPodsumowując: Choć prostszy w analizie, ten model prowadzi do dłuższego średniego czasu oczekiwania i mniejszej efektywności wykorzystania serwerów w porównaniu do modelu ze wspólną kolejką.\n\n\n\n3. Serwery Połączone Szeregowo (Systemy Tandemowe)\nModel ten opisuje procesy wieloetapowe, takie jak linia produkcyjna, proces składania zamówienia w restauracji (zamówienie -&gt; płatność -&gt; odbiór) czy przetwarzanie danych w potoku.\nOpis:\n\nSystem składa się z sekwencji serwerów (stacji).\nWyjście z jednego serwera staje się wejściem do kolejnego.\nMiędzy serwerami mogą znajdować się bufory (kolejki) o skończonej lub nieskończonej pojemności.\n\n\nWłaściwości i sposób oszacowania:\n\nZłożoność analizy: Sposób oszacowania silnie zależy od założeń dotyczących buforów i rozkładów czasów obsługi.\n\nPrzypadek prosty (Twierdzenie Burke’a): Jeśli każdy etap to system M/M/1 z nieskończonym buforem, to wyjściowy strumień zgłoszeń z każdego etapu jest również procesem Poissona o tym samym natężeniu \\(\\lambda\\). Dzięki temu cały system można analizować jako serię niezależnych systemów M/M/1.\n\nŚredni czas pobytu w całym systemie (\\(W_{\\text{total}}\\)) jest po prostu sumą średnich czasów pobytu na każdym etapie: \\(W_{\\text{total}} = W_1 + W_2 + \\dots + W_c\\).\nŚrednia liczba klientów w systemie (\\(L_{\\text{total}}\\)) to suma średnich liczb klientów na każdym etapie: \\(L_{\\text{total}} = L_1 + L_2 + \\dots + L_c\\).\n\nPrzypadek złożony (Skończone bufory): Jest to sytuacja znacznie bardziej realistyczna i trudniejsza analitycznie.\n\nZjawisko blokowania: Jeśli bufor między serwerem \\(i\\) a \\(i+1\\) jest pełny, serwer \\(i\\) po zakończeniu obsługi musi czekać (jest blokowany), aż zwolni się miejsce w buforze. To drastycznie obniża przepustowość całego systemu.\nWąskie gardło (Bottleneck): Przepustowość całego systemu jest ograniczona przez najwolniejszy etap (serwer o najniższym tempie obsługi \\(\\mu\\)). Ten etap nazywany jest “wąskim gardłem”.\nMetody analizy: Dokładne rozwiązania analityczne są rzadkie. Do oszacowania właściwości takich systemów najczęściej wykorzystuje się symulacje komputerowe lub metody aproksymacyjne.\n\n\n\nPodsumowując: Kluczowe dla analizy systemów szeregowych jest zjawisko blokowania i identyfikacja wąskiego gardła. Wydajność całego łańcucha jest determinowana przez jego najsłabsze ogniwo.\n\n\n\nTabela Porównawcza\n\n\n\n\n\n\n\n\n\nCecha\nSystem Równoległy - Jedna Kolejka (M/M/c)\nSystem Równoległy - Oddzielne Kolejki (c x M/M/1)\nSystem Szeregowy (Tandem)\n\n\n\n\nOpis\nJedna kolejka do wielu serwerów\nWiele kolejek, po jednej na serwer\nSekwencja serwerów, jeden po drugim\n\n\nWydajność\nNajwyższa\nNiższa (ryzyko bezczynności serwerów)\nOgraniczona przez “wąskie gardło”\n\n\nRównoważenie obciążenia\nIdealne, automatyczne\nNiedoskonałe, zależne od wyboru klienta\nNie dotyczy (każde zadanie przechodzi przez każdy serwer)\n\n\nZłożoność Analizy\nUmiarkowana (wzory Erlanga-C)\nNiska (analiza niezależnych systemów M/M/1)\nBardzo wysoka (zwłaszcza przy skończonych buforach)\n\n\nKluczowe Zjawisko\nEfektywność współdzielenia zasobów\nNiewydajność i możliwość “jockeyingu”\nBlokowanie i “wąskie gardło”\n\n\nTypowy Przykład\nObsługa w banku, infolinia\nKasy w supermarkecie\nLinia produkcyjna, myjnia samochodowa"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#multimedialne-metody-opracowywania-danych",
    "href": "posts/10-08-2025-first-post/index.html#multimedialne-metody-opracowywania-danych",
    "title": "My Post",
    "section": "8. Multimedialne metody opracowywania danych",
    "text": "8. Multimedialne metody opracowywania danych\n\n1. Mechanizm działania algorytmu najczęściej używanego do kompresji wideo.\n\n\n2. Pojęcie „przetwarzania obrazów cyfrowych”. Zasady postępowania.\n\nPozyskanie (akwizycja) obrazu i przetworzenie do postaci cyfrowej;\nWstępne przetworzenie obrazu, jego filtracja i wyostrzanie, a także jego binaryzacja;\nSegmentacja obrazu i wydzielenie poszczególnych obiektów oraz ich fragmentów (np. krawędzi i innych linii);\nAnaliza obrazu i wyznaczenie cech obiektów oraz informacji o ich lokalizacji;\nRozpoznanie i rozumienie obrazu (identyfikacja klasy).\n\n\n\n3. Formaty plików obrazów bez kompresji stratnej i ich charakterystyka.\n\nPNG (Portable Network Graphics):\n\nLepsza kompresja niż BMP/TIFF przy zachowaniu jakości,\nObsługa przezroczystości (kanał alfa).\n\nGIF\n\nObsługuje animacje,\nOgraniczona paleta kolorów - 256 kolorów (8 bitów),\n\nTIFF (Tagged Image File Format):\n\nWysoka jakość obrazu,\nObsługuje różne metody kompresji, w tym bezstratną (LZW) i stratną (JPEG).\nObsługuje bardzo wysoką jakość obrazu i głębię bitową (np. 16 bitów na kanał).\nObsługuje warstwy, kanały alfa i metadane.\n\nBMP (Bitmap, Windows Bitmap):\n\nProsty format bez kompresji,\nDuże rozmiary plików,\nObsługuje różne głębie kolorów (1, 4, 8, 16, 24, 32 bity)."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#zaawansowane-metody-probabilistyczne",
    "href": "posts/10-08-2025-first-post/index.html#zaawansowane-metody-probabilistyczne",
    "title": "My Post",
    "section": "9. Zaawansowane metody probabilistyczne",
    "text": "9. Zaawansowane metody probabilistyczne\n\n1. Proces Poissona – definicja, konstrukcja i zastosowania.\n\n\n\n\n\n\nDefinicja (Proces Poissona)\n\n\n\nRodzinę mierzalnych zmiennych losowych \\(\\{Z_t, t \\geq 0\\}\\) określonych na przestrzeni probabilistycznej \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) nazywamy procesem Poissona o intensywności \\(\\alpha &gt; 0\\), gdy spełnione są warunki:\n\n\\(\\mathbb{P}[Z_0 = 0] = 1\\)\nDla dowolnego układu \\(0 \\leq t_0 &lt; t_1 &lt; \\dots &lt; t_n\\) zmienne losowe\n\\[\nZ_{t_1} - Z_{t_0},\\; Z_{t_2} - Z_{t_1},\\; \\dots,\\; Z_{t_n} - Z_{t_{n-1}}\n\\]\nsą stochastycznie niezależne.\nDla dowolnych \\(0 \\leq s &lt; t\\) zmienna losowa \\(Z_t - Z_s\\) ma rozkład Poissona z parametrem \\(\\alpha (t-s)\\), tzn.\n\\[\n\\mathbb{P}[Z_t - Z_s = i] \\;=\\; \\frac{(\\alpha (t-s))^i}{i!} e^{-\\alpha (t-s)}, \\quad i = 0,1,2,\\dots\n\\]\n\n\n\n\n\n2.Proces urodzin i śmierci – definicja i przykłady zastosowania.\n\n\n\n\n\n\nDefinicja (Proces urodzin i śmierci)\n\n\n\nProces stochastyczny \\(\\{Z_t, t \\geq 0\\}\\) o wartościach w \\(\\mathbb{N}_0\\) nazywamy procesem urodzin i śmierci, jeżeli:\n\njest łańcuchem Markowa,\nistnieją stałe dodatnie \\(\\{\\lambda_n\\}_{n \\geq 0}\\) (intensywności urodzin) oraz \\(\\{\\mu_n\\}_{n \\geq 1}\\) (intensywności śmierci), dla których spełnione są równania:\n\n\\[\n\\begin{aligned}\nP_{n,n+1}'(t) &= \\lambda_n P_{n}(t), \\\\\nP_{n,n}'(t) &= -(\\lambda_n + \\mu_n) P_{n}(t), \\\\\nP_{n,n-1}'(t) &= \\mu_n P_{n}(t),\n\\end{aligned}\n\\]\ngdzie \\(P_n(t) = \\Pr(Z_t = n)\\).\n\n\nMacierz intensywności\nMacierz \\(Q = (q_{ij})\\) nazywamy macierzą intensywności procesu urodzin i śmierci (lub generatorem procesów Markowa w czasie ciągłym). Ma ona postać:\n\\[\nQ =\n\\begin{bmatrix}\n-\\lambda_0 & \\lambda_0 & 0 & 0 & 0 & \\cdots \\\\\n\\mu_1 & -(\\mu_1 + \\lambda_1) & \\lambda_1 & 0 & 0 & \\cdots \\\\\n0 & \\mu_2 & -(\\mu_2 + \\lambda_2) & \\lambda_2 & 0 & \\cdots \\\\\n0 & 0 & \\mu_3 & -(\\mu_3 + \\lambda_3) & \\lambda_3 & \\cdots \\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots\n\\end{bmatrix}\n\\]\n\n\n\nOznaczenia\n\n\\(\\lambda_n\\) – intensywność urodzin w stanie \\(n\\),\n\n\\(\\mu_n\\) – intensywność śmierci w stanie \\(n\\).\n\n\n\n\n\n\nZastosowania:\n\nproblemy czasu oczekiwania,\nproblemy związane z liniami telefonicznymi,\nproces obsługi klientów,\nproces odnowy.\n\n\n\n\n\n3. Twierdzenie ergodyczne i przykłady jego zastosowania.\n\nTwierdzenie o ergodyczności łańcucha Markowa\n\n\n\n\n\n\nDefinicja\n\n\n\nJednorodny łańcuch Markowa \\(\\{Z_n, n \\in \\mathbb{N}_0\\}\\) jest ergodyczny,\njeśli dla każdego \\(j \\in S\\) istnieją i nie zależą od \\(i \\in S\\) granice:\n\\[\nq_j = \\lim_{n \\to \\infty} p_{ij}^{(n)} &gt; 0,\n\\]\noraz\n\\[\n\\sum_{j \\in S} q_j = 1.\n\\]\n\n\n\n\n\nRozkład graniczny\n\n\n\n\n\n\nTip\n\n\n\nDefinicja:\nWektor \\(q = (q_j, \\, j \\in S)\\) nazywamy rozkładem ergodycznym.\n\n\n\n\n\nTwierdzenie\nJeśli łańcuch Markowa \\(\\{Z_n, n \\in \\mathbb{N}_0\\}\\) jest ergodyczny,\nto macierz przejścia w \\(n\\)-tym kroku spełnia:\n\\[\nP^{(n)} \\xrightarrow[n \\to \\infty]{}\n\\begin{bmatrix}\nq_1 & q_2 & q_3 & \\cdots \\\\\nq_1 & q_2 & q_3 & \\cdots \\\\\nq_1 & q_2 & q_3 & \\cdots \\\\\n\\vdots & \\vdots & \\vdots & \\ddots\n\\end{bmatrix}\n\\]\nczyli każdy wiersz macierzy granicznej jest identyczny i równy rozkładowi ergodycznemu \\(q\\).\n\n\n\nUwaga\n\nWektor \\(q\\) jest jedynym rozkładem stacjonarnym łańcucha.\n\nRozkład graniczny opisuje zachowanie procesu w nieskończoności, niezależnie od stanu początkowego."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#stochastyczne-równania-różniczkowe",
    "href": "posts/10-08-2025-first-post/index.html#stochastyczne-równania-różniczkowe",
    "title": "My Post",
    "section": "10. Stochastyczne równania różniczkowe",
    "text": "10. Stochastyczne równania różniczkowe\n\n1. Całki stochastyczne: ich rodzaje i definicje.\nCałka stochastyczna jest narzędziem analizy stochastycznej, uogólniającym pojęcie całki deterministycznej (np. Riemanna-Stieltjesa) na przypadki, w których funkcja, po której całkujemy, jest procesem stochastycznym. Klasyczne teorie całkowania zawodzą, ponieważ trajektorie wielu ważnych procesów, jak proces Wienera, mają nieskończone wahanie co zostało wspomniane w rozdziale 7.3 skryptu, co uniemożliwia zdefiniowanie dla nich całki w sensie Riemanna-Stieltjesa.\nNajważniejszymi rodzajami całek stochastycznych są całka Itô i całka Stratonowicza.\n\na) Całka Itô\nCałka Itô jest najczęściej stosowaną całką stochastyczną, głównie ze względu na jej kluczową własność: całka z procesu jest martyngałem. Jej konstrukcja, opisana w rozdziale 8 skryptu, przebiega w kilku krokach, analogicznie do konstrukcji całki Lebesgue’a.\nKrok 1: Definicja dla procesów prostych (elementarnych)\nNajpierw definiuje się całkę dla klasy tzw. procesów elementarnych (lub prostych, w skrypcie “prognozowalnych”), które są stałe na przedziałach czasowych. Proces elementarny \\(X_t\\) ma postać: \\[\nX_t = \\sum_{k=1}^{m} \\xi_{k-1} \\mathbb{I}_{(t_{k-1}, t_k]}(t)\n\\] gdzie \\(\\xi_{k-1}\\) jest zmienną losową mierzalną względem \\(\\sigma\\)-ciała \\(\\mathcal{F}_{t_{k-1}}\\) (informacji dostępnej do chwili \\(t_{k-1}\\)). Definicja całki Itô dla takiego procesu względem procesu Wienera \\(W_t\\) jest naturalna: \\[\n\\int_0^t X_s dW_s := \\sum_{k=1}^{m} \\xi_{k-1} (W_{t_k \\land t} - W_{t_{k-1} \\land t})\n\\] Kluczowe jest to, że wartość procesu \\(X_s\\) na przedziale \\((t_{k-1}, t_k]\\) jest ustalana na początku tego przedziału. Mówimy, że proces jest nieantycypujący.\nKrok 2: Izometria Itô\nDla procesów elementarnych zachodzi fundamentalna własność, tzw. izometria Itô (wspomniana w Stwierdzeniu 8.4). Łączy ona drugi moment całki z całką drugiego momentu integranda: \\[\nE\\left[ \\left( \\int_0^T X_s dW_s \\right)^2 \\right] = E\\left[ \\int_0^T X_s^2 ds \\right]\n\\] Ta równość oznacza, że operator całkowania stochastycznego jest izometrią pomiędzy przestrzenią procesów \\(L^2(\\Omega \\times [0,T])\\) a przestrzenią zmiennych losowych \\(L^2(\\Omega)\\).\nKrok 3: Rozszerzenie na ogólne procesy\nDzięki własności izometrii, definicję całki można rozszerzyć z gęstej podprzestrzeni procesów elementarnych na całą przestrzeń procesów prognozowalnych \\(X_t\\) spełniających warunek \\(E[\\int_0^T X_s^2 ds] &lt; \\infty\\).\nUogólnienie: Całka względem martyngałów\nKonstrukcję można uogólnić, zastępując proces Wienera \\(W_t\\) dowolnym ciągłym martyngałem (lub lokalnym martyngałem) \\(M_t\\) (rozdział 10. skryptu). Wówczas w izometrii Itô zwykła miara czasu \\(ds\\) zostaje zastąpiona przez miarę związaną z wariacją kwadratową martyngału, \\(d\\langle M \\rangle_s\\): \\[\nE\\left[ \\left( \\int_0^T X_s dM_s \\right)^2 \\right] = E\\left[ \\int_0^T X_s^2 d\\langle M \\rangle_s \\right]\n\\]\n\n\nb) Całka Stratonowicza\nCałka Stratonowicza (oznaczana jako \\(\\int Y_s \\circ dW_s\\)) jest alternatywną definicją, motywowaną chęcią zachowania klasycznych reguł rachunku różniczkowego, w szczególności reguły łańcuchowej. W jej definicji, zamiast brać wartość integranda na początku przedziału (jak w całce Itô), nieformalnie używa się punktu pośredniego.\nFormalnie, całkę Stratonowicza często definiuje się poprzez całkę Itô (jak w Ćwiczeniu 13.12 skryptu): \\[\n\\int_0^t Y_s \\circ dZ_s := \\int_0^t Y_s dZ_s + \\frac{1}{2} \\langle Y, Z \\rangle_t\n\\] gdzie \\(\\langle Y, Z \\rangle_t\\) to kowariacja kwadratowa procesów \\(Y\\) i \\(Z\\).\n\n\nPorównanie całki Itô i Stratonowicza\n\n\n\n\n\n\n\n\nCecha\nCałka Itô (\\(\\int X_s dW_s\\))\nCałka Stratonowicza (\\(\\int X_s \\circ dW_s\\))\n\n\n\n\nPunkt ewaluacji\nPoczątek przedziału (nieantycypująca)\nŚrodek przedziału (antycypująca)\n\n\nWłasność martyngałowa\n\\(\\int X_s dW_s\\) jest martyngałem (lokalnym)\nGeneralnie nie jest martyngałem\n\n\nReguła łańcuchowa\nWymaga dodatkowego członu (wzór Itô)\nMa taką samą postać jak w klasycznym rachunku\n\n\nZastosowania\nFinanse matematyczne, biologia, teoria filtracji\nInżynieria, fizyka (gdy szum jest idealizacją procesu gładkiego)\n\n\n\n\n\n\n\n2. Różniczka stochastyczna Itô, wzór Itô.\n\na) Różniczka stochastyczna\nRównanie w postaci różniczki stochastycznej jest zwięzłym zapisem stochastycznego równania całkowego. Zapis: \\[\ndX_t = b(t, X_t) dt + \\sigma(t, X_t) dW_t\n\\] jest formalnym skrótem dla równania (jak w Definicji 14.1 skryptu): \\[\nX_t = X_0 + \\int_0^t b(s, X_s) ds + \\int_0^t \\sigma(s, X_s) dW_s\n\\] - \\(b(t, X_t)\\) to dryf (drift), opisujący deterministyczną tendencję procesu. - \\(\\sigma(t, X_t)\\) to dyfuzja (diffusion) lub zmienność (volatility), opisująca losową składową procesu.\nProces \\(X_t\\) opisany takim równaniem nazywany jest procesem Itô lub procesem dyfuzji.\n\n\nb) Wzór Itô (Lemat Itô)\nWzór Itô jest jednym z najważniejszych wyników analizy stochastycznej. Jest to odpowiednik reguły łańcuchowej dla funkcji od procesów Itô. Pokazuje, jak zmienia się w czasie gładka funkcja \\(f\\) procesu stochastycznego.\nW odróżnieniu od klasycznego rachunku, ze względu na niezerową wariację kwadratową procesu Wienera (nieformalnie \\((dW_t)^2 = dt\\)), w rozwinięciu Taylora funkcji \\(f(X_t)\\) należy uwzględnić również wyraz drugiego rzędu.\nWzór Itô dla ogólnego semimartyngału\nW skrypcie (Twierdzenie 13.1) wzór jest podany dla ogólnego ciągłego semimartyngału \\(Z_t = Z_0 + M_t + A_t\\), gdzie \\(M_t\\) jest ciągłym martyngałem lokalnym, a \\(A_t\\) procesem o skończonym wahaniu. Jeśli \\(f\\) jest funkcją klasy \\(C^2\\), to \\(f(Z_t)\\) również jest semimartyngałem i zachodzi: \\[\nf(Z_t) = f(Z_0) + \\int_0^t f'(Z_s) dZ_s + \\frac{1}{2} \\int_0^t f''(Z_s) d\\langle M \\rangle_s\n\\] gdzie \\(\\langle M \\rangle_s\\) to wariacja kwadratowa procesu \\(M_s\\).\nWzór Itô dla procesu Itô\nNiech \\(X_t\\) będzie procesem Itô danym przez \\(dX_t = b_t dt + \\sigma_t dW_t\\), a \\(f(t, x)\\) będzie gładką funkcją (klasy \\(C^{1,2}\\)). Wówczas proces \\(Y_t = f(t, X_t)\\) również jest procesem Itô, a jego różniczka stochastyczna wynosi: \\[\ndY_t = \\frac{\\partial f}{\\partial t}(t, X_t) dt + \\frac{\\partial f}{\\partial x}(t, X_t) dX_t + \\frac{1}{2} \\frac{\\partial^2 f}{\\partial x^2}(t, X_t) (dX_t)^2\n\\] Stosując nieformalne reguły rachunku Itô: \\((dt)^2=0\\), \\(dt dW_t = 0\\) oraz \\((dW_t)^2 = dt\\), i podstawiając \\(dX_t\\), otrzymujemy pełną postać wzoru: \\[\ndf(t, X_t) = \\left( \\frac{\\partial f}{\\partial t} + b_t \\frac{\\partial f}{\\partial x} + \\frac{1}{2} \\sigma_t^2 \\frac{\\partial^2 f}{\\partial x^2} \\right) dt + \\sigma_t \\frac{\\partial f}{\\partial x} dW_t\n\\] Pojawienie się członu z drugą pochodną (\\(\\frac{\\partial^2 f}{\\partial x^2}\\)) jest kluczową różnicą w stosunku do klasycznego rachunku różniczkowego i stanowi sedno rachunku Itô.\nWzór Itô w wersji wielowymiarowej\nWzór ten można uogólnić na funkcje wielu procesów stochastycznych. Dla funkcji \\(f\\) i \\(d\\)-wymiarowego procesu \\(Z_t = (Z_t^{(1)}, ..., Z_t^{(d)})\\), wzór przyjmuje postać (Twierdzenie 13.2): \\[\ndf(Z_t) = \\sum_{i=1}^d \\frac{\\partial f}{\\partial x_i}(Z_t) dZ_t^{(i)} + \\frac{1}{2} \\sum_{i,j=1}^d \\frac{\\partial^2 f}{\\partial x_i \\partial x_j}(Z_t) d\\langle M^{(i)}, M^{(j)} \\rangle_t\n\\] gdzie \\(d\\langle M^{(i)}, M^{(j)} \\rangle_t\\) jest kowariacją kwadratową części martyngałowych procesów \\(Z^{(i)}\\) i \\(Z^{(j)}\\)."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#podstawy-analizy-danych-finansowych",
    "href": "posts/10-08-2025-first-post/index.html#podstawy-analizy-danych-finansowych",
    "title": "My Post",
    "section": "11. Podstawy analizy danych finansowych",
    "text": "11. Podstawy analizy danych finansowych\n\n1. Nominalna i efektywna stopa procentowa oraz twierdzenie charakteryzujące relacje między nimi.\nOczywiście, wyjaśnijmy te fundamentalne pojęcia analizy finansowej w prosty i zrozumiały sposób.\n\n\nWprowadzenie\nW świecie finansów rzadko kiedy sprawy są tak proste, jak się na pierwszy rzut oka wydaje. Dotyczy to zwłaszcza oprocentowania. Kiedy bank reklamuje lokatę lub kredyt, podaje tzw. nominalną stopę procentową. Jednak to, ile faktycznie zarobisz lub zapłacisz, zależy od efektywnej stopy procentowej. Zrozumienie różnicy między nimi jest kluczowe do podejmowania świadomych decyzji finansowych.\n\n\n\n1. Nominalna Stopa Procentowa (r_nom)\nNominalna stopa procentowa, często oznaczana jako stopa nominalna w skali roku (np. 8% p.a. - per annum), to podstawowa, “reklamowana” wartość oprocentowania.\nKluczowe cechy:\n\nJest to stopa deklarowana: Służy jako punkt wyjścia do obliczeń.\nNie uwzględnia częstotliwości kapitalizacji: Sama w sobie nie mówi, jak często odsetki są doliczane do kapitału. Dlatego informacja o stopie nominalnej jest niekompletna bez podania okresu kapitalizacji (np. roczna, kwartalna, miesięczna).\nJest użyteczna do prostych obliczeń: Jeśli kapitalizacja jest roczna, to stopa nominalna jest równa stopie efektywnej.\n\nAnalogia: Pomyśl o niej jak o cenie na metce produktu, która nie uwzględnia ewentualnych dodatkowych opłat czy podatków. To cena wyjściowa, a nie ostateczny koszt.\nPrzykład: Bank oferuje lokatę na 10% w skali roku. To jest właśnie nominalna stopa procentowa.\n\n\n\n2. Efektywna Stopa Procentowa (r_eff)\nEfektywna stopa procentowa to rzeczywista stopa zwrotu z inwestycji lub realny koszt kredytu po uwzględnieniu efektu procentu składanego (czyli doliczania odsetek do kapitału w ciągu roku).\nKluczowe cechy:\n\nOdzwierciedla realny zysk/koszt: Uwzględnia, że odsetki naliczone w jednym okresie (np. w jednym miesiącu) same zaczynają zarabiać w kolejnych okresach.\nJest narzędziem do porównywania ofert: To jedyny miarodajny wskaźnik, który pozwala porównać różne produkty finansowe, nawet jeśli mają różną nominalną stopę procentową i różną częstotliwość kapitalizacji.\nJest zawsze równa lub wyższa od stopy nominalnej (przy kapitalizacji rocznej są równe; im częstsza kapitalizacja, tym większa różnica).\n\nAnalogia: Wracając do poprzedniej analogii, efektywna stopa procentowa to ostateczna, całkowita cena, którą płacisz za produkt po doliczeniu wszystkich dodatkowych kosztów.\nPrzykład: Masz 1000 zł na lokacie z nominalnym oprocentowaniem 12% w skali roku.\n\nScenariusz A: Kapitalizacja roczna Po roku otrzymasz: 1000 zł * 12% = 120 zł odsetek. Stan konta: 1120 zł. Efektywna stopa procentowa = 12%.\nScenariusz B: Kapitalizacja kwartalna Nominalna stopa 12% rocznie oznacza 12% / 4 = 3% na kwartał.\n\nPo I kwartale: 1000 zł * 1,03 = 1030 zł\nPo II kwartale: 1030 zł * 1,03 = 1060,90 zł (odsetki naliczone od 1030 zł, a nie 1000 zł!)\nPo III kwartale: 1060,90 zł * 1,03 = 1092,73 zł\nPo IV kwartale: 1092,73 zł * 1,03 ≈ 1125,51 zł\n\nCałkowity zysk to 125,51 zł. Efektywna stopa procentowa = (125,51 zł / 1000 zł) * 100% = 12,55%.\n\nJak widać, mimo tej samej stopy nominalnej (12%), częstsza kapitalizacja sprawiła, że realny zysk był wyższy.\n\n\n\n3. Twierdzenie Charakteryzujące Relacje Między Nimi (Wzór)\nRelację między nominalną a efektywną stopą procentową opisuje precyzyjny wzór matematyczny.\nWzór:\n\n\n\nr_{eff} = (1 + )^m - 1\n\n\n\nGdzie:\n\nr_eff – efektywna roczna stopa procentowa (ang. Effective Interest Rate)\nr_nom – nominalna roczna stopa procentowa (ang. Nominal Interest Rate)\nm – liczba okresów kapitalizacji w ciągu roku\n\nWartości m dla różnych okresów kapitalizacji:\n\nRoczna: m = 1\nPółroczna: m = 2\nKwartalna: m = 4\nMiesięczna: m = 12\nTygodniowa: m = 52\nDzienna: m = 365\n\n\nZastosowanie wzoru na poprzednim przykładzie: Dane: * r_nom = 12% = 0,12 * m = 4 (kapitalizacja kwartalna)\nObliczenia: - r_eff = (1 + 0,12 / 4)^4 - 1 - r_eff = (1 + 0,03)^4 - 1 - r_eff = (1,03)^4 - 1 - r_eff ≈ 1,1255088 - 1 - r_eff ≈ 0,1255 - r_eff ≈ 12,55%\nWynik jest identyczny z tym, który uzyskaliśmy, licząc “krok po kroku”.\n\n\n\nPodsumowanie i Praktyczne Zastosowanie\n\n\n\n\n\n\n\n\nCecha\nNominalna Stopa Procentowa\nEfektywna Stopa Procentowa\n\n\n\n\nDefinicja\nDeklarowana, “reklamowa” stopa roczna.\nRzeczywista stopa zwrotu lub kosztu.\n\n\nCo uwzględnia?\nTylko wartość bazową oprocentowania.\nWartość bazową oraz efekt procentu składanego.\n\n\nKiedy używać?\nJako punkt wyjścia do obliczeń.\nDo porównywania różnych ofert finansowych.\n\n\nRelacja\nr_nom ≤ r_eff\nr_eff ≥ r_nom\n\n\n\nZłota zasada: Zawsze, gdy porównujesz dwie lokaty lub dwa kredyty, patrz na efektywną stopę procentową (lub jej odpowiednik, np. RRSO – Rzeczywistą Roczną Stopę Oprocentowania w przypadku kredytów). Tylko ona powie Ci, która oferta jest naprawdę korzystniejsza.\nPrzykład: * Kredyt A: 10% nominalnie, kapitalizacja miesięczna. * Kredyt B: 10,1% nominalnie, kapitalizacja półroczna.\nNa pierwszy rzut oka Kredyt A wydaje się tańszy. Obliczmy efektywne stopy: * Kredyt A (r_eff): (1 + 0,10 / 12)¹² - 1 ≈ 10,47% * Kredyt B (r_eff): (1 + 0,101 / 2)² - 1 ≈ 10,36%\nOkazuje się, że Kredyt B, mimo wyższej stopy nominalnej, jest w rzeczywistości tańszy, ponieważ odsetki są doliczane rzadziej.\n\n\n2. Pojęcie renty oraz główne rodzaje rent – ich wartości obecne, wartości przyszłe i przykłady zastosowań.\n\nRenty\nRenta to ciąg płatności (rat) dokonywanych w równych odstępach czasu.\n\n\nRenta odroczona (płatna z dołu)\n\n\\[\nPV = R \\cdot \\frac{1 - (1+i)^{-n}}{i},\n\\qquad\nFV = R \\cdot \\frac{(1+i)^n - 1}{i}\n\\]\n\n\nRenta płatna z góry\n\n\\[\nPV = R \\cdot \\frac{1 - (1+i)^{-n}}{i} \\cdot (1+i),\n\\qquad\nFV = R \\cdot \\frac{(1+i)^n - 1}{i} \\cdot (1+i)\n\\]\n\n\nRenta o ratach tworzących ciąg arytmetyczny\n\n\\[\nR_k = R_1 + (k-1)d\n\\]\n\\[\nPV = \\sum_{k=1}^{n} \\frac{R_1 + (k-1)d}{(1+i)^k},\n\\qquad\nFV = \\sum_{k=1}^{n} (R_1 + (k-1)d) \\cdot (1+i)^{\\,n-k}\n\\]\n\n\nRenta o ratach tworzących ciąg geometryczny\n\n\\[\nR_k = R_1 \\cdot q^{k-1}\n\\]\n\\[\nPV = \\sum_{k=1}^{n} \\frac{R_1 \\cdot q^{k-1}}{(1+i)^k},\n\\qquad\nFV = \\sum_{k=1}^{n} R_1 \\cdot q^{k-1} \\cdot (1+i)^{\\,n-k}\n\\]\n\n\nRenty ciągłe\n\n\\[\nPV = \\int_{0}^{n} R \\cdot e^{-i t} \\, dt\n    = \\frac{R}{i} \\left(1 - e^{-i n}\\right)\n\\]\n\\[\nFV = \\int_{0}^{n} R \\cdot e^{i (n-t)} \\, dt\n    = \\frac{R}{i} \\left(e^{i n} - 1\\right)\n\\]\n\n\n\n3. Procesy akumulacji i dyskontowania oraz ich rodzaje.\n\n\n\nProces\nRodzaj\nWzór matematyczny\n\n\n\n\nAkumulacja\nProsta\n\\(K(t)= K \\cdot (1 + i \\cdot t)\\)\n\n\n\nZłożona\n\\(K(t) = K \\cdot (1+i)^t\\)\n\n\n\nCiągła\n\\(K(t) = K \\cdot e^{i \\cdot t}\\)\n\n\nDyskontowanie\nProste\n\\(PV = \\frac{FV}{1 + i \\cdot t}\\)\n\n\n\nZłożone\n\\(PV = \\frac{FV}{(1+i)^t}\\)\n\n\n\nCiągłe\n\\(PV = FV \\cdot e^{-i \\cdot t}\\)\n\n\n\n\nAkumulacja:\n\nProsta: Opiera się na idei ciągu arytmetycznego. Odsetki dopisujemy po upływie okresu bazowego. Każdy okres daje nam taką samą wartość odsetek.\nZłożona: opiera się na idei ciągu geometrycznego – odsetki są doliczane do kapitału i w kolejnych okresach również pracują, dlatego kapitał rośnie szybciej niż w przypadku odsetek prostych.\nCiągła: zakładamy, że kapitalizacja następuje w nieskończenie wielu małych krokach, co prowadzi do użycia funkcji wykładniczej. To model najbardziej “teoretyczny”, ale użyteczny np. w analizach rynkowych.\n\nDyskontowanie: proces odwrotny do akumulacji (liczymy wartość bieżącą z wartości przyszłej).\n\nProste: zakładamy, że odsetki są odejmowane liniowo (tak jak w akumulacji prostej). Każdy kolejny okres obniża wartość przyszłą o taką samą “porcję” czasu\nZłożone: tu również działa mechanizm kapitalizacji odsetek składanych, tylko w odwrotną stronę – sprowadzamy przyszłą wartość poprzez dzielenie przez kolejne potęgi czynnika \\((1+i)\\).\nCiągłe: To podejście często używane w finansach matematycznych (np. przy wycenie obligacji i instrumentów pochodnych)."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#inżynieria-ubezpieczeń-majątkowych",
    "href": "posts/10-08-2025-first-post/index.html#inżynieria-ubezpieczeń-majątkowych",
    "title": "My Post",
    "section": "12. Inżynieria ubezpieczeń majątkowych",
    "text": "12. Inżynieria ubezpieczeń majątkowych\n\n1. Modele ryzyka stosowane w ubezpieczeniach majątkowych\nW teorii ubezpieczeń majątkowych do opisu i kwantyfikacji ryzyka portfela stosuje się dwa fundamentalne modele: model ryzyka indywidualnego oraz model ryzyka łącznego (kolektywnego).\n\nModel Ryzyka Indywidualnego\nModel ten koncentruje się na pojedynczych polisach w portfelu. Całkowita strata portfela (\\(S\\)) jest modelowana jako suma strat (\\(X_i\\)) z poszczególnych, niezależnych ryzyk (polis).\n\nDefinicja: \\[S = X_1 + X_2 + \\dots + X_n\\] gdzie:\n\n\\(n\\) jest ustaloną (nielosową) liczbą ryzyk w portfelu.\n\\(X_i\\) to zmienna losowa opisująca wysokość szkody z \\(i\\)-tej polisy.\n\nZałożenia:\n\nRyzyka (zmienne losowe \\(X_i\\)) są statystycznie niezależne.\nW okresie ubezpieczenia dla każdego ryzyka szkoda może wystąpić co najwyżej raz.\n\nZastosowanie: Model ten jest użyteczny do analizy jednorodnych portfeli. Jednak ze względu na złożoność obliczeniową (wymaga tzw. splotów rozkładów prawdopodobieństwa) jest mniej praktyczny dla dużych i zróżnicowanych portfeli ubezpieczeń majątkowych.\n\n\n\nModel Ryzyka Łącznego (Kolektywnego)\nModel ten traktuje portfel jako całość – jako proces, który w danym okresie generuje pewną liczbę szkód o różnej wysokości. Zamiast sumować straty po polisach, modeluje się zagregowaną (łączną) wartość szkód.\n\nDefinicja: \\[X = Y_1 + Y_2 + \\dots + Y_N\\] gdzie:\n\n\\(N\\) jest zmienną losową oznaczającą łączną liczbę szkód w portfelu.\n\\(Y_i\\) to zmienna losowa opisująca wysokość \\(i\\)-tej szkody.\nGdy \\(N=0\\), wtedy \\(X=0\\).\n\nZałożenia:\n\nProces generujący liczbę szkód (\\(N\\)) jest niezależny od wysokości poszczególnych szkód (\\(Y_i\\)).\nWysokości szkód (\\(Y_i\\)) są zmiennymi losowymi o identycznym rozkładzie i są wzajemnie niezależne.\n\nZastosowanie: Jest to dominujący model w ubezpieczeniach majątkowych. Jego siła polega na rozdzieleniu ryzyka na dwa kluczowe komponenty:\n\nCzęstotliwość szkód (modelowana przez rozkład zmiennej \\(N\\)).\nWysokość (dotkliwość) szkód (modelowana przez rozkład zmiennej \\(Y\\)). Rozkład łącznej wartości szkód \\(X\\) nazywany jest rozkładem złożonym.\n\n\n\n\n\n\n2. Podstawowe rozkłady liczby szkód w modelu ryzyka łącznego\nW modelu ryzyka łącznego kluczowym elementem jest właściwe zamodelowanie losowej liczby szkód (\\(N\\)). W praktyce aktuarialnej stosuje się głównie trzy poniższe rozkłady.\n\nRozkład Poissona\nJest to najczęściej stosowany i fundamentalny rozkład dla liczby szkód.\n\nCharakterystyka: Modeluje liczbę zdarzeń (szkód) zachodzących losowo i niezależnie w ustalonym przedziale czasu, przy stałej średniej intensywności (\\(\\lambda\\)).\nWzór: \\[P(N = k) = \\frac{\\lambda^k}{k!} e^{-\\lambda}, \\quad k=0, 1, 2, \\dots\\]\nWłasności w ubezpieczeniach:\n\nRówność wartości oczekiwanej i wariancji: \\(E(N) = \\text{Var}(N) = \\lambda\\).\nWłasność agregacji: Suma niezależnych zmiennych losowych o rozkładach Poissona również ma rozkład Poissona. Ułatwia to łączenie subportfeli.\n\n\n\n\nRozkład ujemny dwumianowy\nJest to uogólnienie rozkładu Poissona, które oferuje większą elastyczność.\n\nCharakterystyka: Stosowany, gdy wariancja liczby szkód jest większa niż jej wartość oczekiwana (zjawisko naddyspersji). Jest to częsta sytuacja w praktyce, gdy ryzyko w portfelu nie jest w pełni jednorodne.\nWłasności w ubezpieczeniach:\n\nWariancja większa od wartości oczekiwanej: \\(\\text{Var}(N) &gt; E(N)\\).\nLepiej dopasowuje się do danych, gdzie szkody występują w sposób bardziej skumulowany lub nieregularny niż w modelu Poissona.\n\n\n\n\nRozkład dwumianowy\nStosowany w bardziej specyficznych sytuacjach, gdy liczba potencjalnych szkód jest z góry ograniczona.\n\nCharakterystyka: Opisuje liczbę szkód w stałej liczbie \\(n\\) niezależnych polis, gdzie prawdopodobieństwo szkody \\(q\\) jest takie samo dla każdej polisy.\nWzór: \\[P(N = k) = \\binom{n}{k} q^k (1-q)^{n-k}, \\quad k=0, 1, \\dots, n\\]\nWłasności w ubezpieczeniach:\n\nWariancja mniejsza od wartości oczekiwanej: \\(\\text{Var}(N) &lt; E(N)\\).\nStosuje się go głównie w zamkniętych, jednorodnych portfelach o znanej liczbie ryzyk.\n\n\n\n\n\n\n\n\nPodsumowanie wyboru rozkładu\n\n\n\nWybór rozkładu zależy od charakterystyki portfela. Rozkład Poissona jest punktem wyjścia, rozkład ujemny dwumianowy jego elastycznym rozszerzeniem dla danych o dużej zmienności, a rozkład dwumianowy ma zastosowanie w specyficznych, ograniczonych przypadkach.\n\n\n\n\n\n\n3. Funkcja generująca momenty i funkcja generująca kumulanty oraz ich zastosowanie\nFunkcja generująca momenty (FGM) i funkcja generująca kumulanty (FGK) to potężne narzędzia matematyczne, które znacząco upraszczają analizę ryzyka w portfelu.\n\nDefinicje\n\nFunkcja Generująca Momenty (FGM): Dla zmiennej losowej \\(X\\), jej FGM jest zdefiniowana jako: \\[M_X(t) = E(e^{tX})\\] Jej \\(k\\)-ta pochodna w punkcie \\(t=0\\) jest równa \\(k\\)-temu momentowi zwykłemu (\\(E(X^k)\\)).\nFunkcja Generująca Kumulanty (FGK): Jest zdefiniowana jako logarytm naturalny z FGM: \\[C_X(t) = \\ln(M_X(t))\\] Jej \\(k\\)-ta pochodna w \\(t=0\\) jest równa \\(k\\)-tej kumulancie (\\(c_k\\)), która jest powiązana z momentami centralnymi (np. \\(c_1 = \\mu\\), \\(c_2 = \\sigma^2\\)).\n\n\n\nZastosowanie w teorii ubezpieczeń\n\nUproszczenie analizy sumy ryzyk: Analiza rozkładu sumy niezależnych ryzyk \\(S = X_1 + \\dots + X_n\\) za pomocą standardowych metod (splotów) jest bardzo skomplikowana. FGM i FGK zamieniają tę operację na proste działania algebraiczne:\n\nFGM sumy to iloczyn FGM składników: \\(M_S(t) = \\prod_{i=1}^n M_{X_i}(t)\\)\nFGK sumy to suma FGK składników: \\(C_S(t) = \\sum_{i=1}^n C_{X_i}(t)\\)\n\n\n\n\n\n\n\nKluczowa własność\n\n\n\nAddytywność kumulant jest niezwykle użyteczna. Pozwala obliczyć np. wariancję całego portfela poprzez proste zsumowanie wariancji poszczególnych, niezależnych ryzyk.\n\n\nAnaliza modelu ryzyka łącznego (rozkładu złożonego): To jedno z najważniejszych zastosowań. Dla modelu łącznego, gdzie \\(X = Y_1 + \\dots + Y_N\\), zachodzi fundamentalna zależność: \\[C_X(t) = C_N(C_Y(t))\\] Wzór ten pozwala w elegancki sposób wyprowadzić momenty całego portfela, znając jedynie charakterystyki rozkładu liczby i wysokości szkód. Z tej zależności wynikają m.in. kluczowe wzory: \\[E(X) = E(N) \\cdot E(Y)\\] \\[\\text{Var}(X) = \\text{Var}(N) \\cdot [E(Y)]^2 + E(N) \\cdot \\text{Var}(Y)\\]\nCharakterystyka i aproksymacja rozkładów: Momenty i kumulanty, obliczone za pomocą FGM i FGK, dostarczają kluczowych informacji o kształcie rozkładu łącznej straty (np. o jego symetrii i “grubości ogonów”). Informacje te są niezbędne do:\n\nKalkulacji składki ryzyka i kapitału wymaganego.\nWyboru odpowiedniej metody aproksymacji rozkładu łącznej straty (np. aproksymacji normalnej lub przesuniętym rozkładem gamma)."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#inżynieria-ubezpieczeń-życiowych",
    "href": "posts/10-08-2025-first-post/index.html#inżynieria-ubezpieczeń-życiowych",
    "title": "My Post",
    "section": "13. Inżynieria ubezpieczeń życiowych",
    "text": "13. Inżynieria ubezpieczeń życiowych\n\n1. Tablice trwania życia i ich zastosowanie w ubezpieczeniach życiowych.\nTablice trwania życia (ang. life tables) to fundamentalne narzędzie statystyczne i demograficzne, które w formie tabelarycznej przedstawia proces wymierania hipotetycznej grupy osób (tzw. kohorty - grupa badawcza która ze względu na jej właściwość jest poddawana analizie) od momentu urodzenia aż do śmierci ostatniego jej członka. Są one tworzone na podstawie historycznych danych o śmiertelności w danej populacji (np. dla danego kraju, płci i rocznika).\n\nZastosowanie w ubezpieczeniach życiowych:\nNa podstawie tablic trwania życia obliczane są wartości aktuarialne w ubezpieczeniach na życie. Generalne zastosowania:\n\nOcena Ryzyka: Ubezpieczyciel musi oszacować ryzyko, że będzie musiał wypłacić świadczenie. Prawdopodobieństwo zgonu (\\(q_x\\)) jest bezpośrednią miarą tego ryzyka. Im wyższe \\(q_x\\) dla danej grupy wiekowej, tym wyższe ryzyko dla ubezpieczyciela.\nKalkulacja Składek: Prawdopodobieństwa przeżycia i zgonu są podstawą do obliczania składek ubezpieczeniowych. Na przykład w ubezpieczeniu na życie składka będzie zależała od prawdopodobieństwa śmierci w każdym kolejnym roku trwania umowy. W ubezpieczeniu na dożycie kluczowe będzie prawdopodobieństwo przeżycia określonego okresu.\nTworzenie Rezerw Techniczno-Ubezpieczeniowych: Ubezpieczyciel ma obowiązek tworzenia rezerw finansowych na pokrycie przyszłych zobowiązań. Wysokość tych rezerw jest szacowana z wykorzystaniem tablic trwania życia, które pozwalają przewidzieć, ile świadczeń i kiedy będzie trzeba wypłacić w przyszłości.\nWycena Produktów Emerytalnych i Rentowych: W przypadku rent życiowych, które są wypłacane “do końca życia”, tablice pozwalają oszacować, jak długo statystycznie będą trwały wypłaty, co jest kluczowe dla ustalenia wartości takiego produktu i wysokości składki.\n\n\n\n\n2. Pojęcie wartości aktuarialnej w ubezpieczeniach życiowych.\nWartość aktuarialna (nazywana też wartością obecną netto świadczeń lub składką jednorazową netto) to wartość obecna oczekiwanych przyszłych płatności związanych z umową ubezpieczenia.\nwartość aktuarialna ubezpieczenia (składka jednorazowa netto \\(Ā_x\\)) jest zdefiniowana jako wartość oczekiwana zmiennej losowej \\(Z\\), która reprezentuje zdyskontowaną wartość przyszłego świadczenia: \\[Ā_x = E(Z) = E(v^{T(x)})\\] gdzie: - \\(T(x)\\) to przyszły czas życia osoby w wieku x (zmienna losowa). - \\(v^{T(x)}\\) to zdyskontowana wartość świadczenia w wysokości 1, wypłaconego w momencie śmierci.\nWartość aktuarialna świadczenia reprezentuje średni koszt, jaki ubezpieczyciel poniesie w związku z daną polisą, wyrażony w dzisiejszej wartości pieniądza. Jest to kwota, którą ubezpieczyciel musiałby otrzymać w momencie zawarcia umowy (jako jednorazową wpłatę), aby statystycznie być w stanie pokryć przyszłe zobowiązanie. Z tego powodu wartość aktuarialna świadczenia jest tożsama z jednorazową składką netto.\n\n\n3. Obliczanie składek netto w ubezpieczeniach życiowych.\nSkładka netto to część składki ubezpieczeniowej przeznaczona wyłącznie na pokrycie przewidywanych przyszłych świadczeń. Nie uwzględnia ona kosztów administracyjnych, prowizji, zysku ubezpieczyciela ani marginesu na nieprzewidziane ryzyko. Te dodatkowe elementy są zawarte w tzw. składce brutto, którą finalnie płaci klient.\nObliczanie składki netto opiera się na zasadzie równoważności, która mówi, że w momencie zawarcia umowy: \\[\\text{Wartość aktuarialna przyszłych składek} = \\text{Wartość aktuarialna przyszłych świadczeń}\\]\n\nSkładka jednorazowa netto (SJN): Jest to najprostszy przypadek. Skoro składka jest płacona tylko raz, na początku, to jej wartość aktuarialna jest równa jej wysokości. Zgodnie z zasadą równoważności, jest ona po prostu równa wartości aktuarialnej świadczeń. \\[JSN = A_x\\] (gdzie \\(A_x\\) to wartość aktuarialna świadczenia, np. w ubezpieczeniu na życie)\nRozczna składka netto: Jest to znacznie częstszy model, w którym klient płaci składki regularnie (np. co roku) przez cały okres trwania umowy. Strumień tych składek to tzw. renta życiowa.\n\nBezterminowe ubezpieczenie na życie, płatne nakoniec roku śmierci, równe składki coroczne:\n\\[L = v^{K(x)+1} - P_x \\cdot \\ddot{a}_{\\overline{K(x)+1}}\\] czyli\n\\[ P_x = \\frac{A_x}{\\ddot{a}_x} \\] gdzie: - \\(P_x\\) - roczna składka netto; - \\(\\ddot{a}_x\\) - wartość aktuarialna renty życiowej;\nSkładka roczna netto to nic innego jak całkowity, uśredniony koszt ubezpieczenia (\\(A_x\\)), “rozłożony na raty” płatne przez oczekiwany okres opłacania składek (którego wartość jest ujęta w \\(\\ddot{a}_x\\))"
  }
]