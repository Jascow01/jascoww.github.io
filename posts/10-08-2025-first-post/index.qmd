---
title: "My Post"
description: "Post description"

author: "Szymon Door"
date: "8/10/2025"
image: "preview-1.webp"
categories: [IAD]
#draft: true
---

## Pytania na egzamin dyplomowy IAD

<br>

## 1. Algebra zaawansowana

### 1. Definicja, własności i wybrane zastosowania macierzy Jordana.

#### **DEFINICJA (Klatka Jordana)**

Macierz $J_r(\lambda) \in M_r(\mathbb{K})$ postaci:
$$
J_r(\lambda) = 
\begin{pmatrix}
\lambda & 1 & 0 & \cdots & 0 \\
0 & \lambda & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \ddots & \vdots \\
0 & 0 & \cdots & \lambda & 1 \\
0 & 0 & \cdots & 0 & \lambda
\end{pmatrix}
$$
gdzie $\lambda \in \mathbb{K}$, nazywamy **klatką Jordana** stopnia $r$. W szczególnym przypadku $J_1(\lambda) = [\lambda]$.

#### **DEFINICJA (Macierz Jordana)**

Macierz blokową $J \in M_n(\mathbb{K})$ postaci:
$$
J = 
\begin{pmatrix}
J_{n_1}(\lambda_1) & & & \\
& J_{n_2}(\lambda_2) & & \\
& & \ddots & \\
& & & J_{n_k}(\lambda_k)
\end{pmatrix}
$$
gdzie $n_1 + n_2 + \dots + n_k = n$, $\lambda_1, \dots, \lambda_k \in \mathbb{K}$ oraz wszystkie niewypisane elementy są zerami, nazywamy **macierzą Jordana**.

#### **TWIERDZENIE (Postać Jordana macierzy)**

Niech $A \in M_n(\mathbb{K})$, gdzie $\mathbb{K} = \mathbb{R}$ lub $\mathbb{K} = \mathbb{C}$. Wtedy istnieje macierz nieosobliwa $P \in M_n(\mathbb{K})$ taka, że macierz $J = P^{-1}AP$ jest macierzą Jordana. Macierz $J$ nazywamy **macierzą Jordana macierzy A**. Jest ona wyznaczona jednoznacznie z dokładnością do kolejności klatek Jordana.

#### **Własności Macierzy Jordana**

*   **Wartości własne:** Skalary $\lambda_1, \dots, \lambda_k$ tworzące główną przekątną macierzy Jordana $J$ są jej wartościami własnymi.
*   **Związek z diagonalizacją:** Każda macierz diagonalna jest macierzą Jordana (z klatkami wymiaru 1x1). Oznacza to, że każda macierz diagonalizowalna jest podobna do pewnej macierzy Jordana.
*   **Liczba klatek Jordana:**
    *   Liczba wszystkich klatek Jordana w macierzy $J$ jest równa liczbie liniowo niezależnych wektorów własnych macierzy $A$.
    *   Liczba klatek Jordana odpowiadających konkretnej wartości własnej $\lambda$ jest równa wymiarowi podprzestrzeni własnej $W_\lambda$ (krotności geometrycznej tej wartości własnej).
*   **Rozmiar klatek Jordana:** Suma stopni (wymiarów) wszystkich klatek Jordana odpowiadających wartości własnej $\lambda$ jest równa krotności algebraicznej tej wartości własnej (czyli jej krotności jako pierwiastka wielomianu charakterystycznego).
*   **Wektory dołączone:** Struktura macierzy Jordana (liczba i rozmiary klatek) jest ściśle powiązana z istnieniem tzw. **wektorów dołączonych**. Dla wartości własnej $\lambda$ o krotności algebraicznej $r$ istnieje dokładnie $r$ liniowo niezależnych wektorów dołączonych, które tworzą bazę Jordana.

#### **Wybrane Zastosowania Macierzy Jordana**

Głównym zastosowaniem przedstawionym w materiałach jest uproszczenie obliczeń **funkcji macierzy**.

#### **TWIERDZENIE**

Jeżeli $f$ jest wielomianem o współczynnikach z ciała $\mathbb{K}$, zaś $J$ jest macierzą Jordana w postaci blokowej jak w definicji, to zachodzi równość:
$$
f(J) = 
\begin{pmatrix}
f(J_{n_1}(\lambda_1)) & & & \\
& f(J_{n_2}(\lambda_2)) & & \\
& & \ddots & \\
& & & f(J_{n_k}(\lambda_k))
\end{pmatrix}
$$
Obliczenie funkcji dla całej macierzy sprowadza się do obliczenia jej dla poszczególnych klatek Jordana.

#### **TWIERDZENIE (Funkcja klatki Jordana)**

Jeżeli $J_r(\lambda)$ jest klatką Jordana stopnia $r$, to wartość funkcji $f(J_r(\lambda))$ można obliczyć za pomocą następującego wzoru, wykorzystującego pochodne funkcji $f$:
$$
f(J_r(\lambda)) = 
\begin{pmatrix}
f(\lambda) & f'(\lambda) & \frac{f''(\lambda)}{2!} & \cdots & \frac{f^{(r-1)}(\lambda)}{(r-1)!} \\
0 & f(\lambda) & f'(\lambda) & \cdots & \frac{f^{(r-2)}(\lambda)}{(r-2)!} \\
\vdots & \vdots & \ddots & \ddots & \vdots \\
0 & 0 & \cdots & f(\lambda) & f'(\lambda) \\
0 & 0 & \cdots & 0 & f(\lambda)
\end{pmatrix}
$$
To zastosowanie jest kluczowe np. przy obliczaniu eksponenty macierzy $e^{At}$, co jest fundamentalne w rozwiązywaniu układów równań różniczkowych liniowych.

### 2. Definicja przestrzeni unitarnej i metoda ortogonalizacji Grama-Schmidta.

Definicja: Przestrzeń wektorową, w której wprowadzono iloczyn skalarny nazywamy przestrzenią unitarną.

![](images/unitarne.png)

![](images/unitarne2.png)

Metroda ortogonalizacji Grama-Schmidta:

![](images/ortogonalizacja-grama-schmidta.png)

### 3. Wybrane metody dekompozycji macierzy.

-   Rozkład $LU$

![](images/lu.png)

-   Rozkład $QR$

![](images/qr.png)

-   Rozkład $SVD$

![](images/svd.png)


![](images/svd1.png)

-   Rozkład $Shura$

![](images/schura.png)

-   Rozkłąd $Choleskiego$

![](images/choleskiego.png)

<br>

## 2. Zaawansowane metody uczenia maszynowego

### 1. Zasada działania sieci typu Transformer.

![](images/architektura-transformer.png)

**Enkoder** Dostaje na wejściu dane wejściowe które następnie są konwertowane na tzw. embeddingi (osadzenia) ponieważ dla komputera łatwiej jest interpretować cyfry. Do powstałej reprezentacji dodajemy tzw. positional embedding's aby mógł interpretować pozycje słów występujących w sekwencji z uwagi na to, że słowa mogą mieć różne znaczenie ze względu na kolejnośc w zdaniu.

Działanie Self-Attention można opisać następująco:

Dla każdego tokenu tworzone są trzy wektory: Query (Q), Key (K) i Value (V).

1.  **Query (Q)**: Reprezentuje zapytanie, czyli to, czego szukamy w innych tokenach.

2.  **Key (K)**: Reprezentuje cechy tokenu, które mogą być istotne dla innych tokenów.

3.  **Value (V)**: Reprezentuje faktyczną wartość lub informację, którą token niesie.

Porównując Query jednego tokenu z Key pozostałych tokenów, obliczana jest waga (stopień „uwagi”), czyli jak bardzo dany token powinien brać pod uwagę inny token.

Wagi te są następnie używane do zsumowania Value tokenów w sposób ważony, co daje nową reprezentację tokenu uwzględniającą kontekst całego zdania.

Ponieważ jeden mechanizm uwagi mógłby koncentrować się tylko na jednym aspekcie relacji między słowami, w transformerze stosuje się Multi-Head Attention – wiele równoległych głów uwagi. Każda z nich może analizować inny typ powiązań (np. składnię, znaczenie, zależności czasowe), a wyniki są łączone w jedną bogatszą reprezentację.

Po bloku uwagi wyniki są przekazywane przez Feed-Forward Network – prostą, w pełni połączoną sieć neuronową, która przetwarza każdy token niezależnie, umożliwiając modelowi tworzenie bardziej złożonych reprezentacji. Każda warstwa transformera zawiera również resztkowe połączenia (residual connections) i normalizację warstw (Layer Normalization), co pozwala na stabilniejsze i szybsze uczenie się głębokiego modelu.

**Dekoder**

Dekoder odpowiedzialny jest za generowanie sekwencji wyjściowej. Token wyjściowy jest tworzony na podstawie: - wcześniej wygenerowanych tokenów, - reprezentacji wejściowej dostarczonej przez enkoder

1.  Masked Multi-Head Self Attention

-   Dekoder używa mechanizmu samo-uwagi na już wygenerowanych tokenach
-   Maskowanie, czyli model nie może "patrzeć w przyszłość", znaczy to, że uwaga jest ograniczona do aktualnych i wcześniejszych tokenów.
-   Dzięki temuu dredykcja kolejnego słowa bazuje tylko na wcześniejszych słowach, a nie na tych które właśnie będą generowane

2.  Add & Norm

-   Warstwy normalizacji oraz reszt

3.  Multi-Head Cross-Attention

-   Dekoder zwraca uwagę na wyjście z enkodera
-   Mechanizm polega na tym, że **Query(Q)** pochodzi z dekodera, a **Key(K)** i **Value(V)** z enkodera dzięki temu dekoder szuka odpowiednich fragmentów informacji potrzebnych do wygenerowania kolejnego słowa

4.  Add & Norm
5.  Feed-Forward Network (FFN)
6.  Add & Norm

### 2. Problem zanikającego i eksplodującego gradientu w modelach rekurencyjnych.

Problemy zanikającego i eksplodującego gradientu można przedstawić w następujący sposób:

-   **Zanikający gradient**: 
  - Coraz mniejsze gradienty powodują coraz mniejsze zmniany wag w węzłach głebkiej sieci neuronowej, co porowadzi do niewielkiego lub żadnego uczenia się.
  - Sieć ignoruje zależności długoterminowe (np. pamięta tylko kilka ostatnich kroków sekwencji).


-   **Eksplodujący gradient**: 
  - Gradienty stają się zaskakująco duże, przez co następują duże aktualizacje wag (powtarzające się mnożenie dużych wag) każdego węzła w głebokiej sieci neuronowej
  - Loss nagle skacze do ogromnych wartości

Aby zminimalizować te problemy stosuje się techniki takie jak:

  - Mniejszy *batch size* podczas uczenia sieci;
  - Dobór parametrów (np. learning rate, dropout);
  - Warstwy normalizacji wag (Batch Normalization, Layer Normalization); 

### 3. Rozwiązania z zakresu technik głębokiego uczenia dedykowanych do zadań wizji komputerowej.

1.  Konwolucyjne sieci neuronowe (CNN, Convolutional Neural Networks)

2.  Sieci generatywne

-   GAN (Geeral Adversarial Networks)
-   Variacynjy Auroenkoder (VAE) - probabilistyczne modele generatywne
-   Diffusion Models (np. DALLE) - obecnie dominujące

3.  Transformery w wizji komputerowej

-   Vision Transformer (ViT) - dzieli obraz na fragmenty, a następnie traktuje je jak sekwencje tokenów

4.  Sieci detekcji obiektów

-   One-stage detectors:
    -   Sieci YOLO (You Only Look Once) - szybkie modele które wykrywają obiekty w czasie rzeczywistym
-   Two-stage detectors:
    -   R-CNN, Fast R-CNN - najpierw generują regiony zainteresowanie (RoI), potem klasyfikują

<br>

## 3. Wdrażanie modeli uczenia maszynowego

### 1. Podstawowe komendy REST API służące do komunikacji.

***GET*** - Pobiera dane z serwera. Nie modyfikuje zasobów.

-   Przykład: GET /users — pobierz listę użytkowników.

***POST*** - Tworzy nowy zasób na serwerze. Przykład: POST /users — dodaj nowego użytkownika (dane w body).

***PUT*** - Aktualizuje istniejący zasób w całości (zastępuje go nowym).

-   Przykład: PUT /users/123 — nadpisz dane użytkownika o ID 123.

***PATCH*** - Aktualizuje tylko część zasobu.

-   Przykład: PATCH /users/123 — zmień np. tylko email użytkownika 123.

***DELETE*** - Usuwa zasób z serwera.

-   Przykład: DELETE /users/123 — usuń użytkownika o ID 123.

### 2. Reaktywność i realizacja w aplikacjach Shiny.

Reaktywność w Shiny to mechanizm, który śledzi zależności między częscią wejściową a wyjściową. Dzięki temu, aplikacja przelicza tylko te elementy, które są od siebie zależne niż wykonywać cały kod od nowa.

![](images/reaktywnosc.png)

Powyższa ilustracja przedstawia etapy reaktywności w Shiny:

-   W momencie uruchomienia aplikacji Shiny uruchamia (losowe) wyjście. Ponieważ wywołanie to jest zależne od wyników wywołań reaktywnych, tworzy się połączenia z wyrażeniami reaktywnymi. W tym przypadku pierwsze wywołanie nazwijmy je **x**.
-   Następnie inicjalizowane są wyrażenia reaktywne które są zależne od wyjścia, a następnie kolejno te które są zależne od innych metod aplikacji
-   Na sam koniec, wszystkie operacje wymagane do egzekucji wyjścia **x** zostały policzone a następnie wyświetlone

![](images/reaktywnosc2.png)

Powyższa ilustracja przedstawia moment w którym dochodzi do modyfikacji danych wejściowych\]

-   Wyjście oraz metody, które były zależne do wykonania obliczeń oznacza się jako "invalidated". Również połączenia z innymi metodami, które bezpośrednio nie miałyby zostać wyświetlone (patrz środkowe wyjście) oraz jednocześnie przypisywana jest nowa wartość dla wejścia (patrz pierwsze wejście od góry).
-   W dalszej kolejności znów jedno z wyjść unieważnionych (ang. invalidated) jest poddane egzekucji, która pociąga za sobą egzekucje tych wejść i wyrażeń reaktywnych, które są wymagane do obliczenia wartości lub wyświetlenia wyjścia.

### 3. Metody optymalizacji wydajności aplikacji Shiny obsługującej duże zbiory danych.

Optymalizacja w Shiny sprowadza się do:

-   Minimalizacji danych w pamięci (agregacje, filtrowanie, server-side processing).

-   Rozsądnego użycia reaktywności (tylko to, co trzeba, kiedy trzeba).

-   Wydzielenia ciężkich obliczeń do backendu lub równoległości (future, API).

-   Skalowania serwera przy produkcyjnych wdrożeniach.

<br>

## 4. Wybrane problemy teorii niezawodności

### 1. Rozkłady statystyczne stosowane w analizie niezawodności.

#### 1. Rozkład wykładniczy
Funkcja gęstości prawdopodobieństwa dla zmiennej losowej $x \ge 0$.

*   **Parametr:** $\lambda > 0$ (parametr częstości, *rate parameter*)

$$
f(x; \lambda) = \lambda e^{-\lambda x}
$$

#### 2. Rozkład Weibulla
Funkcja gęstości prawdopodobieństwa dla zmiennej losowej $x \ge 0$.

*   **Parametry:**
    *   $k > 0$ (parametr kształtu, *shape parameter*)
    *   $\lambda > 0$ (parametr skali, *scale parameter*)

$$
f(x; k, \lambda) = \frac{k}{\lambda} \left(\frac{x}{\lambda}\right)^{k-1} e^{-(x/\lambda)^k}
$$

*Uwaga: Gdy $k=1$, rozkład Weibulla sprowadza się do rozkładu wykładniczego z parametrem $\lambda$.*

#### 3. Rozkład normalny
Funkcja gęstości prawdopodobieństwa (PDF) dla zmiennej losowej $x \in (-\infty, \infty)$.

*   **Parametry:**
    *   $\mu$ (wartość oczekiwana, *mean*)
    *   $\sigma^2 > 0$ (wariancja, *variance*), gdzie $\sigma$ to odchylenie standardowe

$$
f(x; \mu, \sigma) = \frac{1}{\sigma\sqrt{2\pi}} e^{ - \frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 }
$$

#### 4. Rozkład Gamma
Funkcja gęstości prawdopodobieństwa dla zmiennej losowej $x \ge 0$.

*   **Parametry:**
    *   $\alpha > 0$ (parametr kształtu, *shape parameter*)
    *   $\beta > 0$ (parametr częstości, *rate parameter*)

$$
f(x; \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x}
$$

gdzie $\Gamma(\alpha) = \int_0^\infty t^{\alpha-1}e^{-t}dt$ to funkcja Gamma.

#### 5. Rozkład Rayleigha
Funkcja gęstości prawdopodobieństwa dla zmiennej losowej $x \ge 0$.

*   **Parametr:** $\sigma > 0$ (parametr skali, *scale parameter*)

$$
f(x; \sigma) = \frac{x}{\sigma^2} e^{-x^2 / (2\sigma^2)}
$$

*Uwaga: Jest to szczególny przypadek rozkładu Weibulla dla $k=2$.*

***



#### Rozkład Bernoulliego
Opisuje wynik pojedynczej próby, która może zakończyć się sukcesem (1) lub porażką (0).

*   **Parametr:** $p \in [0, 1]$ (prawdopodobieństwo sukcesu)
*   **Wartości:** $k \in \{0, 1\}$

$$
P(X=k) = p^k (1-p)^{1-k}
$$

#### Rozkład dwumianowy
Opisuje liczbę sukcesów ($k$) w $n$ niezależnych próbach Bernoulliego.

*   **Parametry:**
    *   $n \ge 0$ (liczba prób, liczba całkowita)
    *   $p \in [0, 1]$ (prawdopodobieństwo sukcesu w pojedynczej próbie)
*   **Wartości:** $k \in \{0, 1, 2, ..., n\}$

$$
P(X=k) = \binom{n}{k} p^k (1-p)^{n-k}
$$

gdzie $\binom{n}{k} = \frac{n!}{k!(n-k)!}$ to symbol Newtona.

#### Rozkład Poissona
Opisuje liczbę zdarzeń w ustalonym przedziale czasu lub przestrzeni, jeśli zdarzenia te zachodzą ze stałą średnią częstotliwością.

*   **Parametr:** $\lambda > 0$ (średnia liczba zdarzeń w przedziale)
*   **Wartości:** $k \in \{0, 1, 2, ...\}$

$$
P(X=k) = \frac{\lambda^k e^{-\lambda}}{k!}
$$

### 2. Modele szeregowe, równoległe i mieszane obiektów technicznych.

1.  Model szeregowy (ang. series system)

    -   System działa tylko wtedy, gdy działają **wszystkie** jego elementy.

    -   Awaria **jednego elementu** powoduje **awarię całego systemu**.

2.  Model równoległy (ang. parallel system)

    -   System działa, jeżeli działa **przynajmniej jeden** z elementów.

    -   Awaria następuje dopiero, gdy **wszystkie** elementy zawiodą.

3.  Model mieszany (ang. mixed system)

    -   Rzeczywiste systemy rzadko są idealnie szeregowe lub równoległe.

    -   Najczęściej są to **kombinacje** obu typów — niektóre podzespoły muszą działać wszystkie (połączenie szeregowe), a inne mają redundancję (połączenie równoległe).

### 3. Wskaźniki gotowości systemu - MTBF, MTTR, dostępność eksploatacyjna.

1.  MTBF – Mean Time Between Failures (Średni czas między awariami)

    -   **Definicj:** Średni czas pracy systemu pomiędzy kolejnymi awariami wymagającymi naprawy.

    -   **Interpretacja:** Jest to miara **niezawodności** – im większy MTBF, tym system rzadziej ulega awarii.

2.  MTTR – Mean Time To Repair (Średni czas naprawy)

    -   **Definicja:** Średni czas potrzebny do przywrócenia systemu do pracy po awarii.

    -   **Interpretacja:** Jest to miara **utrzymywalności** (maintainability) – im mniejszy MTTR, tym szybciej system wraca do działania.

3.  Dostępność eksploatacyjna (Availability, A)

    -   **Definicja:** Prawdopodobieństwo, że system jest w danym momencie zdolny do wykonania swojej funkcji.

<br>

## 5 Metody numeryczne w zastosowaniach

### 1. Wartości własne macierzy i sposoby ich wyznaczania.

#### **Definicja wartości własnych**

Niech $A$ będzie \textbf{macierzą kwadratową} o wymiarze $n \times n$. 
Liczbę $\lambda \in \mathbb{R}$ (lub $\mathbb{C}$) nazywamy \textbf{wartością własną} macierzy $A$, jeśli istnieje \textbf{niezerowy wektor} $\mathbf{x} \in \mathbb{R}^n$, taki że:
$$
    A \mathbf{x} = \lambda \mathbf{x}
$$
Wektor $\mathbf{x}$ nazywa się wówczas \textbf{wektorem własnym} odpowiadającym wartości własnej $\lambda$.


Ponieważ $\lambda \mathbf{x} = \lambda I \mathbf{x}$, gdzie $I$ to macierz jednostkowa, możemy zapisać:
$$
    (A - \lambda I)\mathbf{x} = \mathbf{0}
$$
To jest \textbf{układ jednorodny równań liniowych}.
Aby istniało \textbf{niezerowe rozwiązanie} ($\mathbf{x} \neq \mathbf{0}$), macierz $(A - \lambda I)$ musi być \textbf{osobliwa}, czyli:
$$
    \det(A - \lambda I) = 0
$$
które nazywamy **równaniem charakterystycznym** macierzy $A$.



#### **Metoda potęgowa**

Służy do wyznaczenia maksymalnej co do modułu wartości własnej i odpowiadającego jej wektora własnego

![](images/metoda-potegowa.png)

#### **Metoda iteracji odwrotnej**

-   Wariant metody potęgowej służący do wyznaczenia wartości własnej macierzy, najbliższej zeru​

-   Podstawą jest twierdzenie, że wartości własne macierzy odwrotnej są odwrotnościami wartości własnych macierzy danej

-   Sposób postępowania jest podobny do metody zwykłej z zastrzeżeniem dotyczącym kroku potęgowego

![](images/iteracji-odwrotnej.png)

#### **Macierz Hessenbergowska (górna)**

### 2. Metody Rungego-Kutty do rozwiązywania równań różniczkowych.

#### **Metoda Rungego-Kutty (RK)**

Metody Rungego-Kutty służą do numerycznego rozwiązywania równań różniczkowych postaci $y' = f(t, y)$ z warunkiem początkowym $y(t_0) = y_0$. Idea polega na zastąpieniu prostego przybliżenia z metody Eulera (używającej nachylenia tylko na początku kroku) przez **ważoną średnią nachyleń** obliczonych w kilku punktach wewnątrz kroku czasowego $h$. Daje to znacznie dokładniejszą aproksymację.

#### **Porównanie metod RK 1., 2. i 4. rzędu**

##### 1. **Metoda 1. rzędu (RK1) – Metoda Eulera**
To najprostsza forma, stanowiąca punkt odniesienia.

*   **Idea:** Ekstrapolacja rozwiązania na podstawie nachylenia w punkcie początkowym kroku.
*   **Wzór:**
    $$ y_{n+1} = y_n + h \cdot f(t_n, y_n) $$

##### 2. **Metoda 2. rzędu (RK2) – np. Metoda Heuna**
Znaczne ulepszenie w stosunku do metody Eulera przy niewielkim dodatkowym koszcie.

*   **Idea:** Uśrednienie nachylenia z początku i (oszacowanego) końca kroku.
*   **Wzór:**
    1.  $k_1 = f(t_n, y_n)$  (nachylenie na początku)
    2.  $k_2 = f(t_n + h, y_n + h \cdot k_1)$ (nachylenie na końcu, oszacowane metodą Eulera)
    3.  $y_{n+1} = y_n + h \cdot \frac{k_1 + k_2}{2}$ (użycie średniego nachylenia)

##### 3. **Metoda 4. rzędu (RK4) – Klasyczna metoda Rungego-Kutty**
Najpopularniejsza metoda, oferująca doskonały kompromis między dokładnością a kosztem obliczeniowym.

*   **Idea:** Obliczenie ważonej średniej nachyleń z początku, dwóch punktów w środku i końca kroku. Wagi są dobrane tak, by zmaksymalizować dokładność.
*   **Wzór:**
    1.  $k_1 = f(t_n, y_n)$
    2.  $k_2 = f(t_n + \frac{h}{2}, y_n + h \frac{k_1}{2})$
    3.  $k_3 = f(t_n + \frac{h}{2}, y_n + h \frac{k_2}{2})$
    4.  $k_4 = f(t_n + h, y_n + h k_3)$
    5.  $y_{n+1} = y_n + \frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)$

#### Jak wyznaczane są parametry metody?

Parametry (współczynniki wagowe i punkty pośrednie) nie są przypadkowe. Wyznacza się je poprzez porównanie **rozwinięcia w szereg Taylora** numerycznej formuły metody z rozwinięciem w szereg Taylora dokładnego rozwiązania $y(t_n+h)$.

**Algorytm wyznaczania parametrów:**

1.  **Zapisz dokładne rozwiązanie** w postaci szeregu Taylora wokół punktu $t_n$ do rzędu $p$:
    $y(t_n+h) = y_n + h \cdot y'(t_n) + \frac{h^2}{2} y''(t_n) + \dots + \frac{h^p}{p!} y^{(p)}(t_n) + O(h^{p+1})$

2.  **Wyraź pochodne** $y', y'', \dots$ za pomocą funkcji $f(t,y)$ i jej pochodnych cząstkowych (np. $y' = f$, $y'' = \frac{\partial f}{\partial t} + \frac{\partial f}{\partial y} f$, itd.).

3.  **Rozwiń wzór numeryczny** metody RK (z niewiadomymi parametrami) również w szereg Taylora względem potęg kroku $h$.

4.  **Porównaj współczynniki** przy tych samych potęgach $h$ ($h^1, h^2, \dots, h^p$) w obu rozwinięciach.

5.  **Rozwiąż powstały układ równań** (zazwyczaj nieliniowych) na nieznane parametry. Co ciekawe, dla rzędów wyższych niż 1, układ ten ma często więcej niewiadomych niż równań, co prowadzi do istnienia całych rodzin metod RK tego samego rzędu (np. istnieje wiele różnych metod RK2).

#### Rząd metody a dokładność obliczeń

**Rząd metody ($p$)** jest kluczowym wskaźnikiem jej dokładności. Określa on, jak szybko maleje globalny błąd obliczeń wraz ze zmniejszaniem kroku $h$. Zależność ta jest następująca:

**Globalny błąd $\approx C \cdot h^p$**

gdzie $C$ to stała zależna od problemu.

*   **RK1 (rząd 1):** Błąd jest proporcjonalny do $h$. **Dwukrotne zmniejszenie kroku zmniejsza błąd dwukrotnie.** Jest to bardzo wolna zbieżność.
*   **RK2 (rząd 2):** Błąd jest proporcjonalny do $h^2$. **Dwukrotne zmniejszenie kroku zmniejsza błąd czterokrotnie.**
*   **RK4 (rząd 4):** Błąd jest proporcjonalny do $h^4$. **Dwukrotne zmniejszenie kroku zmniejsza błąd aż szesnastokrotnie!**

**Wniosek:** Metoda RK4 pozwala osiągnąć bardzo wysoką dokładność przy znacznie większym kroku $h$ w porównaniu do metod niższych rzędów, co czyni ją niezwykle wydajną i popularną w praktycznych zastosowaniach.



### 3. Generatory liczb pseudolosowych i ich zastosowanie do obliczania całek oznaczonych metodą Monte-Carlo.

Dlaczego generatory liczb pseudolosowych? Ponieważ znając algorytm oraz ziarno generatora jesteśmy w stanie przewidzieć kolejne elementy ciągu - brak w tym losowości

Generatory możemy podzielić na:

-   Liniowe
    -   Linowy generator kongruentny $$ 
        x_{n+1} = (ax_n+b)(\text{mod} m)  
        $$
    -   Generator Fibbonacciego $$
        x_n = (x_{n-l} + n_{n-k})(\text{mod} m)
        $$
-   Nieliniowe
    -   Charakteryzują się bardzo długim okresem i dobrą równomiernością rozkładu liczb. Oparte na bardziej złożonych zależnościach, np. Mersenne Twister

<br>


Metoda Monte Carlo to technika numeryczna służąca do przybliżania wartości całek oznaczonych. Jest szczególnie użyteczna w przypadkach, gdy:
*   Funkcja podcałkowa jest bardzo skomplikowana.
*   Obszar całkowania ma nieregularny kształt.
*   Całka jest wielowymiarowa (np. całka podwójna lub potrójna), co sprawia, że tradycyjne metody analityczne lub numeryczne (jak metoda trapezów czy Simpsona) stają się nieefektywne.

**Główna idea:** Zamiast analitycznie obliczać pole pod wykresem funkcji, "strzelamy" losowo punktami w zdefiniowany obszar i na podstawie proporcji trafień szacujemy wynik.

#### 2. Generatory liczb pseudolosowych 
Generatory liczb pseudolosowych to algorytmy, które produkują sekwencje liczb naśladujące właściwości liczb losowych. W kontekście całkowania potrzebujemy generatora, który potrafi tworzyć liczby z **rozkładu jednostajnego** (każda liczba w danym zakresie ma takie samo prawdopodobieństwo wylosowania).

Służą one do generowania współrzędnych `(x, y)` dla każdego z losowych "strzałów". Jakość i statystyczne właściwości generatora (np. brak korelacji między kolejnymi liczbami) mają bezpośredni wpływ na dokładność uzyskanej aproksymacji całki.

Załóżmy, że chcemy obliczyć całkę oznaczoną:
$$ I = \int_a^b f(x) dx $$

Reprezentuje ona pole powierzchni pod krzywą $y = f(x)$ na przedziale od $x=a$ do $x=b$.

**Algorytm postępowania:**

1.  **Określenie obszaru próbkowania:**
    Tworzymy prostokąt, który całkowicie zawiera interesujący nas obszar pod wykresem.
    *   Szerokość prostokąta to długość przedziału całkowania: $w = b - a$.
    *   Wysokość prostokąta $M$ musi być równa lub większa od maksymalnej wartości funkcji $f(x)$ na przedziale $[a, b]$. Czyli $M \ge \max_{x \in [a,b]} f(x)$.
    *   Pole tego prostokąta wynosi: $A_{\text{prostokąt}} = (b-a) \cdot M$.

2.  **Losowe próbkowanie:**
    Przy użyciu generatora liczb pseudolosowych generujemy dużą liczbę $N$ losowych punktów $(x_i, y_i)$ o współrzędnych równomiernie rozłożonych wewnątrz prostokąta:
    *   $x_i$ jest losowane z przedziału $[a, b]$.
    *   $y_i$ jest losowane z przedziału $[0, M]$.

3.  **Zliczanie "trafień":**
    Dla każdego wygenerowanego punktu $(x_i, y_i)$ sprawdzamy, czy znajduje się on **pod wykresem funkcji** $f(x)$. Warunek ten jest spełniony, jeśli:
    $$ y_i \le f(x_i) $$
    Zliczamy wszystkie punkty, które spełniają ten warunek. Nazwijmy tę liczbę $k$.

4.  **Aproksymacja pola:**
    Założenie metody Monte Carlo mówi, że stosunek pola pod wykresem do pola całego prostokąta jest w przybliżeniu równy stosunkowi liczby punktów pod wykresem ($k$) do całkowitej liczby wylosowanych punktów ($N$).

    $$ \frac{\text{Pole pod wykresem}}{\text{Pole prostokąta}} \approx \frac{k}{N} $$

    Przekształcając ten wzór, otrzymujemy przybliżoną wartość całki:

    $$ I \approx \frac{k}{N} \cdot \text{Pole prostokąta} $$

    Co daje:
    $$ \int_a^b f(x) dx \approx \frac{k}{N} \cdot (b-a) \cdot M $$

   #### 4. Właściwości i uwagi

*   **Zbieżność:** Dokładność metody rośnie wraz ze wzrostem liczby prób $N$. Błąd statystyczny aproksymacji jest proporcjonalny do $\frac{1}{\sqrt{N}}$, co oznacza, że aby dziesięciokrotnie zwiększyć dokładność, trzeba stukrotnie zwiększyć liczbę losowań.
*   **Zalety:**
    *   Prostota implementacji.
    *   Niezwykła skuteczność przy całkach wielowymiarowych (gdzie inne metody zawodzą z powodu tzw. "klątwy wymiarowości").
    *   Łatwość adaptacji do nieregularnych i złożonych obszarów całkowania.
*   **Wady:**
    *   Wolna zbieżność w porównaniu do deterministycznych metod numerycznych dla prostych całek jednowymiarowych.
    *   Wynik jest probabilistyczny – każde uruchomienie algorytmu da nieco inny, choć zbliżony, rezultat.

```{r}
#| echo: false
# Ustawienie ziarna losowości dla powtarzalności wyników
set.seed(123)

n_points <- 10000

radius <- 1

x_coords <- runif(n_points, min = -radius, max = radius)
y_coords <- runif(n_points, min = -radius, max = radius)


distance_sq <- x_coords^2 + y_coords^2
inside_circle <- distance_sq <= radius^2

k <- sum(inside_circle)

area_square <- (2 * radius)^2


approximated_area <- (k / n_points) * area_square

point_colors <- ifelse(inside_circle, "steelblue", "firebrick")


plot(x_coords, y_coords, 
     col = point_colors, 
     pch = 20,                          # Małe, pełne kółka jako punkty
     cex = 0.5,                         # Rozmiar punktów
     xlab = "Współrzędna X", 
     ylab = "Współrzędna Y",
     main = paste("Metoa Monte Carlo\nPrzybliżenie Pi =", round(approximated_area, 4)),
     asp = 1                            # Kluczowe dla zachowania proporcji (koło wygląda jak koło)
)

# Rysowanie granic kwadratu
rect(xleft = -radius, ybottom = -radius, xright = radius, ytop = radius, 
     border = "black", lwd = 2)

# Rysowanie idealnego okręgu
# Generujemy punkty na obwodzie koła
theta <- seq(0, 2 * pi, length.out = 200)
lines(x = radius * cos(theta), y = radius * sin(theta), 
      col = "darkgreen", lwd = 3)

# Dodanie legendy
legend("topright", 
       legend = c("Wewnątrz koła", "Na zewnątrz koła"), 
       col = c("steelblue", "firebrick"), 
       pch = 20, 
       bg = "white")
```

## 6. Podstawy teorii sterowania [Notatki na podstawie książki](http://bc.tu.kielce.pl/440/1/Stefanski_MPI-155.pdf)


### 1. Sposoby tworzenia modeli matematycznych obiektów lub procesów sterowania. Identyfikacja procesu sterowania.

Model matematyczny jest zdefiniowany jako **zależność sygnałów wyjściowych od sygnałów wejściowych, wyrażona w postaci równań matematycznych** (s. 13).

**Sposoby tworzenia modeli matematycznych to (s. 52):**

1.  **Równania różniczkowe i różnicowe:**
    *   **Równania różniczkowe** opisują obiekty ciągłe. Ogólna postać dla obiektu liniowego, stacjonarnego i jednowymiarowego jest przedstawiona na s. 52.
    *   **Równania różnicowe** są odpowiednikiem dla układów dyskretnych, gdzie czas ma wartość dyskretną (s. 53).

2.  **Transmitancje operatorowe:**
    *   Dla **układów ciągłych** jest to stosunek transformaty Laplace’a sygnału wyjściowego Y(s) do transformaty Laplace’a sygnału wejściowego U(s), przy zerowych warunkach początkowych (s. 56).
    *   Dla **układów dyskretnych** jest to stosunek transformaty Z sygnału wyjściowego Y(z) do transformaty sygnału wejściowego U(z) (s. 58).

3.  **Równania stanu:**
    *   Opisują dynamikę układu za pomocą układu równań różniczkowych (dla układów ciągłych) lub różnicowych (dla układów dyskretnych) pierwszego rzędu. Model ten składa się z **równania stanu** (opisującego dynamikę wewnętrznych zmiennych stanu) i **równania wyjścia** (wiążącego zmienne stanu z sygnałem wyjściowym) (s. 63-65).

4.  **Charakterystyki czasowe i częstotliwościowe:**
    *   Chociaż są to głównie narzędzia analizy, mogą również służyć jako forma modelu matematycznego, zwłaszcza gdy są wyznaczane eksperymentalnie. Przykłady to **odpowiedź skokowa h(t)**, **odpowiedź impulsowa g(t)** (s. 68) oraz charakterystyki częstotliwościowe (np. **amplitudowo-fazowa**) (s. 72).

**Identyfikacja procesu sterowania (s. 84):**

1.  **Analiza teoretyczna:** Budowa modelu na podstawie znanych praw fizycznych rządzących procesem.
2.  **Analiza eksperymentalna:** Określenie modelu na podstawie obserwacji "odpowiedzi układu na [...] typowe wymuszenia" (s. 85). Konkretnym przykładem jest **"Eksperymentalne wyznaczanie charakterystyk częstotliwościowych"** (s. 81), które polega na rejestrowaniu odpowiedzi obiektu na sygnał harmoniczny o różnej częstotliwości i na tej podstawie budowaniu modelu. Innym przykładem jest wyznaczanie charakterystyki statycznej przez pomiary w stanie ustalonym (s. 53).

---

### 2. Charakterystyka statyczna i charakterystyka dynamiczna procesu. Przykłady obu charakterystyk dla wybranego procesu.

**Charakterystyka statyczna:**

Jest to **zależność sygnału wyjściowego od wejściowego w stanie ustalonym** (s. 53). Wyznacza się ją z równania różniczkowego poprzez przyrównanie wszystkich pochodnych do zera. W przypadku opisu za pomocą transmitancji operatorowej G(s), charakterystykę statyczną uzyskuje się, przyjmując s = 0 (s. 57). Definiuje ona statyczne wzmocnienie obiektu.

**Charakterystyka dynamiczna:**

Charakterystyka dynamiczna pokazuje, jak układ zachowuje się w czasie w odpowiedzi na zmianę sygnału wejściowego. Główne formy opisu właściwości dynamicznych to (s. 52, 68, 72):

*   **Charakterystyki czasowe:** Pokazują odpowiedź układu w dziedzinie czasu. Najważniejsze z nich:
    *   **Odpowiedź skokowa h(t):** Odpowiedź na sygnał jednostkowy 1(t).
    *   **Odpowiedź impulsowa g(t):** Odpowiedź na impuls Diraca δ(t).
*   **Charakterystyki częstotliwościowe:** Opisują zachowanie układu w stanie ustalonym przy wymuszeniu sinusoidalnym o różnej częstotliwości. Przykłady to charakterystyka amplitudowo-fazowa (wykres Nyquista) oraz logarytmiczne charakterystyki amplitudowa i fazowa (wykresy Bodego).

**Przykład dla wybranego procesu (Człon inercyjny pierwszego rzędu, s. 112):**

*   **Równanie różniczkowe:** $T * \frac{dy(t)}{dt} + y(t) = K * u(t)$
*   **Transmitancja:** $G(s) = \frac{K}{(Ts + 1)}$

1.  **Charakterystyka statyczna:**
    *   Z równania różniczkowego: W stanie ustalonym $\frac{dy(t)}{dt} = 0$, co daje $y(t) = K * u(t)$. Jest to zależność liniowa, a jej nachylenie $K$ to wzmocnienie statyczne.
    *   Z transmitancji: $G(0) = \frac{K}{(T*0 + 1)}= K$.

2.  **Charakterystyki dynamiczne:**
    *   **Odpowiedź skokowa (czasowa):** $h(t) = K(1 - e^{(\frac{-t}{T})})$. Jest to narastająca funkcja wykładnicza, która asymptotycznie dąży do wartości $K$ (pokazana na Rys. 4.11).
    *   **Charakterystyka amplitudowo-fazowa (częstotliwościowa):** Jest to półokrąg o średnicy $K$ w prawej półpłaszczyźnie zespolonej (pokazana na Rys. 4.11).
    *   **Logarytmiczna charakterystyka amplitudowa:** Dla małych częstotliwości jest to linia pozioma na poziomie $20logK$, a dla dużych częstotliwości opada z nachyleniem -20 dB/dekadę (pokazana na Rys. 4.11).

---

### 3. Metody ograniczania skutków niepożądanego oddziaływania na proces.

Niepożądane oddziaływania na proces są **"zakłóceniami"** (s. 12). Główną metodą ograniczania ich skutków jest zastosowanie **sterowania w układzie zamkniętym, czyli regulacji ze sprzężeniem zwrotnym** (s. 15).

Mechanizm działania tej metody jest następujący (s. 15-17):

1.  **Pomiar sygnału wyjściowego:** Wartość regulowanej wielkości wyjściowej $y(t)$ jest stale mierzona.
2.  **Porównanie z wartością zadaną:** Zmierzona wartość jest porównywana z wartością pożądaną (zadaną) $w(t)$. Różnica tych sygnałów $e(t) = w(t) - y(t)$ nazywana jest **uchybem regulacji**.
3.  **Działanie regulatora:** Uchyb $e(t)$ jest wprowadzany do **regulatora**, który na jego podstawie generuje odpowiedni **sygnał sterujący $u(t)$**. Sygnał ten ma na celu takie oddziaływanie na obiekt, aby zminimalizować uchyb, a tym samym skompensować wpływ zakłóceń.

<br>

## 7. Systemy obsługi masowej

### 1. Korzystając z oznaczenia Kendalla podać charakterystykę systemu M/D/n/m.

![](images/kendall.png)

Charakterystyka systemu M/D/n/m:

-   **M** - czas przybycia klientów jest rozkładem wykładniczym;
-   **D** - czas trwania obsługi jest opisany rozkładem deterministycznym (stałym);
-   **n** - liczba liczba serwerów równoległych
-   **m** - maksymalna liczba osób w systemie (w kolejce (poczekalni) i w obsłudze).

### 2. Korzystając z formuł Littla opisz zależność pomiędzy oczekiwaną liczbą klientów w systemie a średnim czasem spędzonym w systemie.

![](images/little.png)

### 3. Różnice w oszacowaniu własności systemów obsługi ze względu na sposób połączenia serwerów

Analiza systemów kolejkowych wymaga zrozumienia, jak architektura połączeń między serwerami wpływa na kluczowe metryki wydajności, takie jak czas oczekiwania czy wykorzystanie zasobów. Poniżej przedstawiono trzy fundamentalne modele połączeń i metody ich analizy.

1.  **Serwery połączone równolegle z jedną, wspólną kolejką.**
2.  **Serwery połączone równolegle z oddzielnymi kolejkami dla każdego serwera.**
3.  **Serwery połączone szeregowo (kaskadowo).**

---

#### 1. Serwery Równoległe z Jedną Wspólną Kolejką (Model M/M/c)

Jest to najczęściej spotykany i zazwyczaj najwydajniejszy model obsługi w miejscach takich jak banki (jedna kolejka do wielu okienek), infolinie czy lotniska (jedna kolejka do kontroli bezpieczeństwa).

**Opis:**

*   Klienci (zgłoszenia) wchodzą do jednej, wspólnej kolejki.
*   Gdy dowolny z $c$ serwerów staje się wolny, pierwszy klient z kolejki jest kierowany do jego obsługi.
*   System jest opisywany w notacji Kendalla jako **M/M/c**.

<br>

**Właściwości i sposób oszacowania:**

*   **Wydajność i równoważenie obciążenia:** System jest wysoce wydajny. Żaden serwer nie jest bezczynny, jeśli w kolejce czeka choćby jedno zgłoszenie. Obciążenie jest automatycznie i idealnie zrównoważone między wszystkimi serwerami.

*   **Złożoność analizy:** Analiza matematyczna jest bardziej złożona niż dla pojedynczego serwera. Wykorzystuje się **wzory Erlanga-C**, które pozwalają obliczyć kluczowe metryki:
    *   **Prawdopodobieństwo, że system jest pusty ($P_0$):** Wymaga obliczenia sumy szeregu.
    *   **Prawdopodobieństwo oczekiwania w kolejce ($P_w$):** Znane jako wzór C Erlanga, zależy od $P_0$, liczby serwerów $c$ i współczynnika wykorzystania systemu $\rho$.
    *   **Średnia liczba klientów w kolejce ($L_q$):** $L_q = P_w \cdot \frac{\rho}{1 - \rho}$
    *   **Średni czas oczekiwania w kolejce ($W_q$):** $W_q = L_q / \lambda$ (gdzie $\lambda$ to średnie natężenie zgłoszeń).
    *   **Średni czas pobytu w systemie ($W$):** $W = W_q + 1/\mu$ (gdzie $\mu$ to średnie tempo obsługi jednego serwera).

*   **Kluczowa metryka:** **Współczynnik wykorzystania systemu $\rho = \lambda / (c \cdot \mu)$**. Warunkiem stabilności systemu jest $\rho < 1$.

**Podsumowując:** Ten model minimalizuje średni czas oczekiwania klienta, ponieważ zasoby (serwery) są wykorzystywane w sposób optymalny.

---

#### 2. Serwery Równoległe z Oddzielnymi Kolejkami (Model $c \times$ M/M/1)

Ten model jest typowy dla supermarketów z wieloma kasami, gdzie każda kasa ma swoją własną kolejkę.

**Opis:**

*   Istnieje $c$ niezależnych kolejek, po jednej dla każdego z $c$ serwerów.
*   Klient po przybyciu wybiera jedną z kolejek (np. najkrótszą) i pozostaje w niej.

<br>

**Właściwości i sposób oszacowania:**

*   **Wydajność i równoważenie obciążenia:** System ten jest **z natury mniej wydajny** niż system z jedną kolejką. Może wystąpić sytuacja, w której jeden serwer jest bezczynny (jego kolejka jest pusta), podczas gdy w innych kolejkach klienci oczekują na obsługę. Równoważenie obciążenia jest niedoskonałe i zależy od decyzji klientów.

*   **Złożoność analizy:** Analiza jest znacznie prostsza, ponieważ system można traktować jako **$c$ niezależnych systemów M/M/1**.
    *   Zakładając, że strumień wejściowy $\lambda$ jest równomiernie rozłożony na $c$ kolejek, każda z nich otrzymuje strumień zgłoszeń o natężeniu $\lambda_i = \lambda / c$.
    *   Dla każdej z tych kolejek stosuje się proste wzory dla systemu **M/M/1**:
        *   Współczynnik wykorzystania pojedynczego serwera: $\rho_i = \lambda_i / \mu = (\lambda / c) / \mu = \rho$.
        *   Średnia liczba klientów w i-tej kolejce: $L_{q_i} = \frac{\rho_i^2}{1 - \rho_i}$.
        *   Średni czas oczekiwania w i-tej kolejce: $W_{q_i} = L_{q_i} / \lambda_i$.
    *   Całkowite właściwości systemu uzyskuje się poprzez uśrednienie wyników z poszczególnych kolejek.

*   **Zjawisko "Jockeying":** W praktyce klienci mogą zmieniać kolejki, jeśli widzą, że inna porusza się szybciej. To zjawisko komplikuje analizę i zbliża właściwości systemu do modelu z jedną wspólną kolejką, ale rzadko jest uwzględniane w podstawowych modelach analitycznych.

**Podsumowując:** Choć prostszy w analizie, ten model prowadzi do dłuższego średniego czasu oczekiwania i mniejszej efektywności wykorzystania serwerów w porównaniu do modelu ze wspólną kolejką.

---

#### 3. Serwery Połączone Szeregowo (Systemy Tandemowe)

Model ten opisuje procesy wieloetapowe, takie jak linia produkcyjna, proces składania zamówienia w restauracji (zamówienie -> płatność -> odbiór) czy przetwarzanie danych w potoku.

**Opis:**

*   System składa się z sekwencji serwerów (stacji).
*   Wyjście z jednego serwera staje się wejściem do kolejnego.
*   Między serwerami mogą znajdować się bufory (kolejki) o skończonej lub nieskończonej pojemności.

<br>

**Właściwości i sposób oszacowania:**

*   **Złożoność analizy:** Sposób oszacowania silnie zależy od założeń dotyczących buforów i rozkładów czasów obsługi.
    *   **Przypadek prosty (Twierdzenie Burke'a):** Jeśli każdy etap to system M/M/1 z **nieskończonym buforem**, to wyjściowy strumień zgłoszeń z każdego etapu jest również procesem Poissona o tym samym natężeniu $\lambda$. Dzięki temu cały system można analizować jako **serię niezależnych systemów M/M/1**.
        *   **Średni czas pobytu w całym systemie ($W_{\text{total}}$)** jest po prostu sumą średnich czasów pobytu na każdym etapie: $W_{\text{total}} = W_1 + W_2 + \dots + W_c$.
        *   **Średnia liczba klientów w systemie ($L_{\text{total}}$)** to suma średnich liczb klientów na każdym etapie: $L_{\text{total}} = L_1 + L_2 + \dots + L_c$.
    *   **Przypadek złożony (Skończone bufory):** Jest to sytuacja znacznie bardziej realistyczna i trudniejsza analitycznie.
        *   **Zjawisko blokowania:** Jeśli bufor między serwerem $i$ a $i+1$ jest pełny, serwer $i$ po zakończeniu obsługi musi czekać (jest blokowany), aż zwolni się miejsce w buforze. To drastycznie obniża przepustowość całego systemu.
        *   **Wąskie gardło (Bottleneck):** Przepustowość całego systemu jest ograniczona przez najwolniejszy etap (serwer o najniższym tempie obsługi $\mu$). Ten etap nazywany jest "wąskim gardłem".
        *   **Metody analizy:** Dokładne rozwiązania analityczne są rzadkie. Do oszacowania właściwości takich systemów najczęściej wykorzystuje się **symulacje komputerowe** lub metody aproksymacyjne.

**Podsumowując:** Kluczowe dla analizy systemów szeregowych jest zjawisko blokowania i identyfikacja wąskiego gardła. Wydajność całego łańcucha jest determinowana przez jego najsłabsze ogniwo.
---

#### Tabela Porównawcza

| Cecha | System Równoległy - Jedna Kolejka (M/M/c) | System Równoległy - Oddzielne Kolejki (c x M/M/1) | System Szeregowy (Tandem) |
| :--- | :--- | :--- | :--- |
| **Opis** | Jedna kolejka do wielu serwerów | Wiele kolejek, po jednej na serwer | Sekwencja serwerów, jeden po drugim |
| **Wydajność** | **Najwyższa** | Niższa (ryzyko bezczynności serwerów) | Ograniczona przez "wąskie gardło" |
| **Równoważenie obciążenia** | Idealne, automatyczne | Niedoskonałe, zależne od wyboru klienta | Nie dotyczy (każde zadanie przechodzi przez każdy serwer) |
| **Złożoność Analizy** | Umiarkowana (wzory Erlanga-C) | **Niska** (analiza niezależnych systemów M/M/1) | Bardzo wysoka (zwłaszcza przy skończonych buforach) |
| **Kluczowe Zjawisko** | Efektywność współdzielenia zasobów | Niewydajność i możliwość "jockeyingu" | Blokowanie i "wąskie gardło" |
| **Typowy Przykład** | Obsługa w banku, infolinia | Kasy w supermarkecie | Linia produkcyjna, myjnia samochodowa |

<br>

## 8. Multimedialne metody opracowywania danych

### 1. Mechanizm działania algorytmu najczęściej używanego do kompresji wideo.

#### **Kodowanie między klatkowe** ([materiał](https://swistak.codes/post/kompresja-wideo/))

Mówiąc najprościej jak się da, kodowanie to polega na wykorzystaniu zależności między sąsiadującymi klatkami. W normalnym zapisie wideo, czy to z kamery, czy też animacji, nie jest powszechne, aby każda klatka miała całkowicie inny obraz. Zmieniają się tylko wybrane obszary. Dlatego zamiast zapisywać całą klatkę, możemy zapisać jedynie różnice, które zapisane są w tzw. makroblokach (wycinki obrazu np $16 \times 16$) W ten sposób tworzymy całe sekwencje, gdzie mamy całą klatkę (I-frame, klatka kluczowa), po której następuje wiele tych zapisujących różnice (P-frame lub B-frame). Taka sekwencja jest nazywana **GOP** (group of pictures, po pol. grupa obrazów).

Wewnątrz sekwencji GOP możemy wyróżnić trzy rodzaje klatek:

  - **I-frame** (Intra frame, klatka kluczowa) — zaczyna sekwencję. Jest to jedyna klatka zapisana w całości. Czasem określa się, że GOP to po prostu odległość między klatkami tego typu. Klatki te w zależności od formatu mogą być niekompresowane lub kompresowane tak, jak robi się to ze zwykłymi obrazami. Na przykład w MPEG-1 kodowanie I-frame jest niemal identyczne jak kodowanie plików JPEG (też stosuje się transformację DCT).
  - **P-frame** (Predicted frame, po pol. klatka przewidywana) — jest to klatka, która koduje ruch na podstawie klatki będącej wcześniej w sekwencji. W starszych formatach (m.in. H.261, H.263) musiała być to klatka znajdująca się bezpośrednio przed P-frame, jednak w nowszych standardach (m.in. H.264, H.265) może się odnosić do dowolnej wcześniejszej (a nawet wielu na raz). Warto dodać, że ruch może być kodowany na podstawie dowolnej klatki w sekwencji, niekoniecznie względem I-frame.
  - **B-frame** (Bidirectional/bipredictive frame, po pol. klatka dwukierunkowa/podwójnie przewidywana) — w przeciwieństwie do P-frame mogą korzystać z klatek, które są zarówno przed nimi, jak i po nich. Analogicznie jak wcześniej, w starszych standardach mogły wykorzystywać informacje jedynie z klatek bezpośrednio przed i bezpośrednio po, a obecnie jest większa swoboda. Ten rodzaj klatek jest najbardziej wymagający obliczeniowo, dlatego np. w czasach MPEG-1 rezygnowano z kodowania w ten sposób, stosując jedynie I-frame i P-frame. Dziś jednak nie stanowi już to problemu.

Aby zakodować różnice, nie potrzebujemy kodować całej klatki. Też jednak różnic nie zapisujemy z dokładnością do 1 piksela. W standardach wideo, począwszy od H.261, po dzisiejsze H.264 (aczkolwiek już nie w H.265), wykorzystuje się do tego makrobloki. Jest to samodzielnie kodowany mały wycinek klatki (standardowy wymiar $16 \times 16$), na którym wykonuje się między innymi transformację liniową w celu jego dalszego optymalnego zakodowania.

### 2. Pojęcie „przetwarzania obrazów cyfrowych”. Zasady postępowania.

1.  Pozyskanie (akwizycja) obrazu i przetworzenie do postaci cyfrowej;
2.  Wstępne przetworzenie obrazu, jego filtracja i wyostrzanie, a także jego binaryzacja;
3.  Segmentacja obrazu i wydzielenie poszczególnych obiektów oraz ich fragmentów (np. krawędzi i innych linii);
4.  Analiza obrazu i wyznaczenie cech obiektów oraz informacji o ich lokalizacji;
5.  Rozpoznanie i rozumienie obrazu (identyfikacja klasy).

### 3. Formaty plików obrazów bez kompresji stratnej i ich charakterystyka.

-   **PNG (Portable Network Graphics)**:
    -   Lepsza kompresja niż BMP/TIFF przy zachowaniu jakości,
    -   Obsługa przezroczystości (kanał alfa).
-   **GIF**
    -   Obsługuje animacje,
    -   Ograniczona paleta kolorów - 256 kolorów (8 bitów),
-   **TIFF (Tagged Image File Format)**:
    -   Wysoka jakość obrazu,
    -   Obsługuje różne metody kompresji, w tym bezstratną (LZW) i stratną (JPEG).
    -   Obsługuje bardzo wysoką jakość obrazu i głębię bitową (np. 16 bitów na kanał).
    -   Obsługuje warstwy, kanały alfa i metadane.
-   **BMP (Bitmap, Windows Bitmap)**:
    -   Prosty format bez kompresji,
    -   Duże rozmiary plików,
    -   Obsługuje różne głębie kolorów (1, 4, 8, 16, 24, 32 bity).

<br>

## 9. Zaawansowane metody probabilistyczne

### 1. Proces Poissona – definicja, konstrukcja i zastosowania.

::: callout-note
## Definicja (Proces Poissona)

Rodzinę mierzalnych zmiennych losowych $\{Z_t, t \geq 0\}$ określonych na przestrzeni probabilistycznej $(\Omega, \mathcal{F}, \mathbb{P})$ nazywamy **procesem Poissona** o intensywności $\alpha > 0$, gdy spełnione są warunki:

1.  $\mathbb{P}[Z_0 = 0] = 1$

2.  Dla dowolnego układu $0 \leq t_0 < t_1 < \dots < t_n$ zmienne losowe

    $$
    Z_{t_1} - Z_{t_0},\; Z_{t_2} - Z_{t_1},\; \dots,\; Z_{t_n} - Z_{t_{n-1}}
    $$

    są stochastycznie niezależne.

3.  Dla dowolnych $0 \leq s < t$ zmienna losowa $Z_t - Z_s$ ma rozkład Poissona z parametrem $\alpha (t-s)$, tzn.

    $$
    \mathbb{P}[Z_t - Z_s = i] \;=\; \frac{(\alpha (t-s))^i}{i!} e^{-\alpha (t-s)}, \quad i = 0,1,2,\dots
    $$
:::

### 2.Proces urodzin i śmierci – definicja i przykłady zastosowania.

::: callout-note
## Definicja (Proces urodzin i śmierci)

Proces stochastyczny $\{Z_t, t \geq 0\}$ o wartościach w $\mathbb{N}_0$ nazywamy **procesem urodzin i śmierci**, jeżeli:

-   jest łańcuchem Markowa,
-   istnieją stałe dodatnie $\{\lambda_n\}_{n \geq 0}$ (intensywności urodzin) oraz $\{\mu_n\}_{n \geq 1}$ (intensywności śmierci), dla których spełnione są równania:

$$
\begin{aligned}
P_{n,n+1}'(t) &= \lambda_n P_{n}(t), \\
P_{n,n}'(t) &= -(\lambda_n + \mu_n) P_{n}(t), \\
P_{n,n-1}'(t) &= \mu_n P_{n}(t),
\end{aligned}
$$

gdzie $P_n(t) = \Pr(Z_t = n)$.

------------------------------------------------------------------------

### Macierz intensywności

Macierz $Q = (q_{ij})$ nazywamy **macierzą intensywności** procesu urodzin i śmierci (lub generatorem procesów Markowa w czasie ciągłym). Ma ona postać:

$$
Q =
\begin{bmatrix}
 -\lambda_0 & \lambda_0 & 0 & 0 & 0 & \cdots \\
 \mu_1 & -(\mu_1 + \lambda_1) & \lambda_1 & 0 & 0 & \cdots \\
 0 & \mu_2 & -(\mu_2 + \lambda_2) & \lambda_2 & 0 & \cdots \\
 0 & 0 & \mu_3 & -(\mu_3 + \lambda_3) & \lambda_3 & \cdots \\
 \vdots & \vdots & \vdots & \vdots & \vdots & \ddots
\end{bmatrix}
$$

------------------------------------------------------------------------

### Oznaczenia

-   $\lambda_n$ – intensywność urodzin w stanie $n$,\
-   $\mu_n$ – intensywność śmierci w stanie $n$.\
:::

#### Zastosowania: 

-   problemy czasu oczekiwania,

-   problemy związane z liniami telefonicznymi,

-   proces obsługi klientów,

-   proces odnowy.

<br>

### 3. Twierdzenie ergodyczne i przykłady jego zastosowania.

#### [Twierdzenie o ergodyczności](http://tomasz.home.amu.edu.pl/wrp/11_mark.pdf) łańcucha Markowa

::: {.callout-note}
## Definicja

G

Jednorodny łańcuch Markowa $\{Z_n, n \in \mathbb{N}_0\}$ jest **ergodyczny**,  
jeśli dla każdego $j \in S$ istnieją i nie zależą od $i \in S$ granice:

$$\pi_j = \lim_{n \to \infty} p_{ij}^{(n)} > 0,
$$

oraz

$$
\sum_{j \in S} \pi_j = 1.
$$

:::

---

#### Rozkład graniczny

::: {.callout-tip}
**Definicja:**  
Wektor $q = (q_j, \, j \in S)$ nazywamy **rozkładem ergodycznym**.
:::

---

#### Twierdzenie

Jeśli łańcuch Markowa $\{Z_n, n \in \mathbb{N}_0\}$ jest **ergodyczny**,  
to macierz przejścia w $n$-tym kroku spełnia:

$$
P^{(n)} \xrightarrow[n \to \infty]{} 
\begin{bmatrix}
q_1 & q_2 & q_3 & \cdots \\
q_1 & q_2 & q_3 & \cdots \\
q_1 & q_2 & q_3 & \cdots \\
\vdots & \vdots & \vdots & \ddots
\end{bmatrix}
$$

czyli każdy wiersz macierzy granicznej jest identyczny i równy rozkładowi ergodycznemu $q$.

---

#### Uwaga

- Wektor $q$ jest **jedynym rozkładem stacjonarnym** łańcucha.  
- Rozkład graniczny opisuje zachowanie procesu w nieskończoności, niezależnie od stanu początkowego.  


## 10. Stochastyczne równania różniczkowe

### 1. Całki stochastyczne: ich rodzaje i definicje.

Całka stochastyczna jest narzędziem analizy stochastycznej, uogólniającym pojęcie całki deterministycznej (np. Riemanna-Stieltjesa) na przypadki, w których funkcja, po której całkujemy, jest procesem stochastycznym. Klasyczne teorie całkowania zawodzą, ponieważ trajektorie wielu ważnych procesów, jak proces Wienera, mają **nieskończone wahanie** co zostało wspomniane w rozdziale 7.3 [skryptu](https://mst.mimuw.edu.pl/wyklady/was/wyklad.pdf), co uniemożliwia zdefiniowanie dla nich całki w sensie Riemanna-Stieltjesa.

Najważniejszymi rodzajami całek stochastycznych są całka Itô i całka Stratonowicza.

#### a) Całka Itô

Całka Itô jest najczęściej stosowaną całką stochastyczną, głównie ze względu na jej kluczową własność: całka z procesu jest [martyngałem](https://www.deltami.edu.pl/media/articles/2007/05/delta-2007-05-martyngaly.pdf). Jej konstrukcja, opisana w rozdziale 8 [skryptu](https://mst.mimuw.edu.pl/wyklady/was/wyklad.pdf), przebiega w kilku krokach, analogicznie do konstrukcji całki Lebesgue'a.

**Krok 1: Definicja dla procesów prostych (elementarnych)**

Najpierw definiuje się całkę dla klasy tzw. **procesów elementarnych** (lub prostych, w skrypcie "prognozowalnych"), które są stałe na przedziałach czasowych. Proces elementarny $X_t$ ma postać:
$$
X_t = \sum_{k=1}^{m} \xi_{k-1} \mathbb{I}_{(t_{k-1}, t_k]}(t)
$$
gdzie $\xi_{k-1}$ jest zmienną losową mierzalną względem $\sigma$-ciała $\mathcal{F}_{t_{k-1}}$ (informacji dostępnej do chwili $t_{k-1}$). Definicja całki Itô dla takiego procesu względem procesu Wienera $W_t$ jest naturalna:
$$
\int_0^t X_s dW_s := \sum_{k=1}^{m} \xi_{k-1} (W_{t_k \land t} - W_{t_{k-1} \land t})
$$
Kluczowe jest to, że wartość procesu $X_s$ na przedziale $(t_{k-1}, t_k]$ jest ustalana na początku tego przedziału. Mówimy, że proces jest **nieantycypujący**.

**Krok 2: Izometria Itô**

Dla procesów elementarnych zachodzi fundamentalna własność, tzw. **izometria Itô** (wspomniana w Stwierdzeniu 8.4). Łączy ona drugi moment całki z całką drugiego momentu integranda:
$$
E\left[ \left( \int_0^T X_s dW_s \right)^2 \right] = E\left[ \int_0^T X_s^2 ds \right]
$$
Ta równość oznacza, że operator całkowania stochastycznego jest izometrią pomiędzy przestrzenią procesów $L^2(\Omega \times [0,T])$ a przestrzenią zmiennych losowych $L^2(\Omega)$.

**Krok 3: Rozszerzenie na ogólne procesy**

Dzięki własności izometrii, definicję całki można rozszerzyć z gęstej podprzestrzeni procesów elementarnych na całą przestrzeń procesów prognozowalnych $X_t$ spełniających warunek $E[\int_0^T X_s^2 ds] < \infty$.

**Uogólnienie: Całka względem martyngałów**

Konstrukcję można uogólnić, zastępując proces Wienera $W_t$ dowolnym ciągłym martyngałem (lub lokalnym martyngałem) $M_t$ (rozdział 10. skryptu). Wówczas w izometrii Itô zwykła miara czasu $ds$ zostaje zastąpiona przez miarę związaną z **wariacją kwadratową** martyngału, $d\langle M \rangle_s$:
$$
E\left[ \left( \int_0^T X_s dM_s \right)^2 \right] = E\left[ \int_0^T X_s^2 d\langle M \rangle_s \right]
$$

#### b) Całka Stratonowicza

Całka Stratonowicza (oznaczana jako $\int Y_s \circ dW_s$) jest alternatywną definicją, motywowaną chęcią zachowania klasycznych reguł rachunku różniczkowego, w szczególności reguły łańcuchowej. W jej definicji, zamiast brać wartość integranda na początku przedziału (jak w całce Itô), nieformalnie używa się punktu pośredniego.

Formalnie, całkę Stratonowicza często definiuje się poprzez całkę Itô (jak w Ćwiczeniu 13.12 skryptu):
$$
\int_0^t Y_s \circ dZ_s := \int_0^t Y_s dZ_s + \frac{1}{2} \langle Y, Z \rangle_t
$$
gdzie $\langle Y, Z \rangle_t$ to **kowariacja kwadratowa** procesów $Y$ i $Z$.

#### Porównanie całki Itô i Stratonowicza

| Cecha | Całka Itô ($\int X_s dW_s$) | Całka Stratonowicza ($\int X_s \circ dW_s$) |
| :--- | :--- | :--- |
| **Punkt ewaluacji** | Początek przedziału (nieantycypująca) | Środek przedziału (antycypująca) |
| **Własność martyngałowa** | $\int X_s dW_s$ jest martyngałem (lokalnym) | Generalnie nie jest martyngałem |
| **Reguła łańcuchowa** | Wymaga dodatkowego członu (wzór Itô) | Ma taką samą postać jak w klasycznym rachunku |
| **Zastosowania** | Finanse matematyczne, biologia, teoria filtracji | Inżynieria, fizyka (gdy szum jest idealizacją procesu gładkiego) |

---

### 2. Różniczka stochastyczna Itô, wzór Itô.

#### a) Różniczka stochastyczna

Równanie w postaci **różniczki stochastycznej** jest zwięzłym zapisem stochastycznego równania całkowego. Zapis:
$$
dX_t = b(t, X_t) dt + \sigma(t, X_t) dW_t
$$
jest formalnym skrótem dla równania (jak w Definicji 14.1 skryptu):
$$
X_t = X_0 + \int_0^t b(s, X_s) ds + \int_0^t \sigma(s, X_s) dW_s
$$
- **$b(t, X_t)$** to **dryf (drift)**, opisujący deterministyczną tendencję procesu.
- **$\sigma(t, X_t)$** to **dyfuzja (diffusion)** lub **zmienność (volatility)**, opisująca losową składową procesu.

Proces $X_t$ opisany takim równaniem nazywany jest **procesem Itô** lub procesem dyfuzji.

#### b) Wzór Itô (Lemat Itô)

Wzór Itô jest jednym z najważniejszych wyników analizy stochastycznej. Jest to odpowiednik reguły łańcuchowej dla funkcji od procesów Itô. Pokazuje, jak zmienia się w czasie gładka funkcja $f$ procesu stochastycznego.

W odróżnieniu od klasycznego rachunku, ze względu na niezerową wariację kwadratową procesu Wienera (nieformalnie $(dW_t)^2 = dt$), w rozwinięciu Taylora funkcji $f(X_t)$ należy uwzględnić również wyraz drugiego rzędu.

**Wzór Itô dla ogólnego semimartyngału**

W skrypcie (Twierdzenie 13.1) wzór jest podany dla ogólnego ciągłego semimartyngału $Z_t = Z_0 + M_t + A_t$, gdzie $M_t$ jest ciągłym martyngałem lokalnym, a $A_t$ procesem o skończonym wahaniu. Jeśli $f$ jest funkcją klasy $C^2$, to $f(Z_t)$ również jest semimartyngałem i zachodzi:
$$
f(Z_t) = f(Z_0) + \int_0^t f'(Z_s) dZ_s + \frac{1}{2} \int_0^t f''(Z_s) d\langle M \rangle_s
$$
gdzie $\langle M \rangle_s$ to wariacja kwadratowa procesu $M_s$.

**Wzór Itô dla procesu Itô**

Niech $X_t$ będzie procesem Itô danym przez $dX_t = b_t dt + \sigma_t dW_t$, a $f(t, x)$ będzie gładką funkcją (klasy $C^{1,2}$). Wówczas proces $Y_t = f(t, X_t)$ również jest procesem Itô, a jego różniczka stochastyczna wynosi:
$$
dY_t = \frac{\partial f}{\partial t}(t, X_t) dt + \frac{\partial f}{\partial x}(t, X_t) dX_t + \frac{1}{2} \frac{\partial^2 f}{\partial x^2}(t, X_t) (dX_t)^2
$$
Stosując nieformalne reguły rachunku Itô: $(dt)^2=0$, $dt dW_t = 0$ oraz $(dW_t)^2 = dt$, i podstawiając $dX_t$, otrzymujemy pełną postać wzoru:
$$
df(t, X_t) = \left( \frac{\partial f}{\partial t} + b_t \frac{\partial f}{\partial x} + \frac{1}{2} \sigma_t^2 \frac{\partial^2 f}{\partial x^2} \right) dt + \sigma_t \frac{\partial f}{\partial x} dW_t
$$
Pojawienie się członu z drugą pochodną ($\frac{\partial^2 f}{\partial x^2}$) jest kluczową różnicą w stosunku do klasycznego rachunku różniczkowego i stanowi sedno rachunku Itô.

**Wzór Itô w wersji wielowymiarowej**

Wzór ten można uogólnić na funkcje wielu procesów stochastycznych. Dla funkcji $f$ i $d$-wymiarowego procesu $Z_t = (Z_t^{(1)}, ..., Z_t^{(d)})$, wzór przyjmuje postać (Twierdzenie 13.2):
$$
df(Z_t) = \sum_{i=1}^d \frac{\partial f}{\partial x_i}(Z_t) dZ_t^{(i)} + \frac{1}{2} \sum_{i,j=1}^d \frac{\partial^2 f}{\partial x_i \partial x_j}(Z_t) d\langle M^{(i)}, M^{(j)} \rangle_t
$$
gdzie $d\langle M^{(i)}, M^{(j)} \rangle_t$ jest kowariacją kwadratową części martyngałowych procesów $Z^{(i)}$ i $Z^{(j)}$.

<br>

## 11. Podstawy analizy danych finansowych

### 1. Nominalna i efektywna stopa procentowa oraz twierdzenie charakteryzujące relacje między nimi.

Oczywiście, wyjaśnijmy te fundamentalne pojęcia analizy finansowej w prosty i zrozumiały sposób.

#### Wprowadzenie

W świecie finansów rzadko kiedy sprawy są tak proste, jak się na pierwszy rzut oka wydaje. Dotyczy to zwłaszcza oprocentowania. Kiedy bank reklamuje lokatę lub kredyt, podaje tzw. **nominalną stopę procentową**. Jednak to, ile faktycznie zarobisz lub zapłacisz, zależy od **efektywnej stopy procentowej**. Zrozumienie różnicy między nimi jest kluczowe do podejmowania świadomych decyzji finansowych.

---

#### 1. Nominalna Stopa Procentowa (r_nom)

Nominalna stopa procentowa, często oznaczana jako **stopa nominalna w skali roku** (np. 8% p.a. - *per annum*), to podstawowa, "reklamowana" wartość oprocentowania.

**Kluczowe cechy:**

*   **Jest to stopa deklarowana:** Służy jako punkt wyjścia do obliczeń.
*   **Nie uwzględnia częstotliwości kapitalizacji:** Sama w sobie nie mówi, jak często odsetki są doliczane do kapitału. Dlatego informacja o stopie nominalnej jest niekompletna bez podania okresu kapitalizacji (np. roczna, kwartalna, miesięczna).
*   **Jest użyteczna do prostych obliczeń:** Jeśli kapitalizacja jest roczna, to stopa nominalna jest równa stopie efektywnej.

**Analogia:** Pomyśl o niej jak o cenie na metce produktu, która nie uwzględnia ewentualnych dodatkowych opłat czy podatków. To cena wyjściowa, a nie ostateczny koszt.

**Przykład:**
Bank oferuje lokatę na 10% w skali roku. To jest właśnie nominalna stopa procentowa.

---

#### 2. Efektywna Stopa Procentowa (r_eff)

Efektywna stopa procentowa to **rzeczywista stopa zwrotu** z inwestycji lub **realny koszt** kredytu po uwzględnieniu efektu **procentu składanego** (czyli doliczania odsetek do kapitału w ciągu roku).

**Kluczowe cechy:**

*   **Odzwierciedla realny zysk/koszt:** Uwzględnia, że odsetki naliczone w jednym okresie (np. w jednym miesiącu) same zaczynają zarabiać w kolejnych okresach.
*   **Jest narzędziem do porównywania ofert:** To jedyny miarodajny wskaźnik, który pozwala porównać różne produkty finansowe, nawet jeśli mają różną nominalną stopę procentową i różną częstotliwość kapitalizacji.
*   **Jest zawsze równa lub wyższa od stopy nominalnej** (przy kapitalizacji rocznej są równe; im częstsza kapitalizacja, tym większa różnica).

**Analogia:** Wracając do poprzedniej analogii, efektywna stopa procentowa to ostateczna, całkowita cena, którą płacisz za produkt po doliczeniu wszystkich dodatkowych kosztów.

**Przykład:**
Masz 1000 zł na lokacie z nominalnym oprocentowaniem 12% w skali roku.

*   **Scenariusz A: Kapitalizacja roczna**
    Po roku otrzymasz: 1000 zł * 12% = 120 zł odsetek.
    Stan konta: 1120 zł.
    **Efektywna stopa procentowa = 12%**.

*   **Scenariusz B: Kapitalizacja kwartalna**
    Nominalna stopa 12% rocznie oznacza 12% / 4 = 3% na kwartał.
    *   Po I kwartale: 1000 zł * 1,03 = 1030 zł
    *   Po II kwartale: 1030 zł * 1,03 = 1060,90 zł (odsetki naliczone od 1030 zł, a nie 1000 zł!)
    *   Po III kwartale: 1060,90 zł * 1,03 = 1092,73 zł
    *   Po IV kwartale: 1092,73 zł * 1,03 ≈ **1125,51 zł**

    Całkowity zysk to 125,51 zł.
    **Efektywna stopa procentowa = (125,51 zł / 1000 zł) * 100% = 12,55%**.

Jak widać, mimo tej samej stopy nominalnej (12%), częstsza kapitalizacja sprawiła, że realny zysk był wyższy.

---

#### 3. Twierdzenie Charakteryzujące Relacje Między Nimi (Wzór)

Relację między nominalną a efektywną stopą procentową opisuje precyzyjny wzór matematyczny.

**Wzór:**

![r_{eff} = \left(1 + \frac{r_{nom}}{m}\right)^m - 1](https://latex.codecogs.com/svg.latex?r_{eff}%20=%20\left(1%20+%20\frac{r_{nom}}{m}\right)^m%20-%201)

* Gdzie:
  *   **r_eff** – efektywna roczna stopa procentowa (ang. *Effective Interest Rate*)
  *   **r_nom** – nominalna roczna stopa procentowa (ang. *Nominal Interest Rate*)
  *   **m** – liczba okresów kapitalizacji w ciągu roku

* **Wartości `m` dla różnych okresów kapitalizacji:**
  *   Roczna: `m = 1`
  *   Półroczna: `m = 2`
  *   Kwartalna: `m = 4`
  *   Miesięczna: `m = 12`
  *   Tygodniowa: `m = 52`
  *   Dzienna: `m = 365`

**Zastosowanie wzoru na poprzednim przykładzie:**
Dane:
  *   r_nom = 12% = 0,12
  *   m = 4 (kapitalizacja kwartalna)

Obliczenia:
- r_eff = (1 + 0,12 / 4)^4 - 1
- r_eff = (1 + 0,03)^4 - 1
- r_eff = (1,03)^4 - 1
- r_eff ≈ 1,1255088 - 1
- r_eff ≈ 0,1255
- **r_eff ≈ 12,55%**

Wynik jest identyczny z tym, który uzyskaliśmy, licząc "krok po kroku".

---

#### Podsumowanie i Praktyczne Zastosowanie

| Cecha | **Nominalna Stopa Procentowa** | **Efektywna Stopa Procentowa** |
| :--- | :--- | :--- |
| **Definicja** | Deklarowana, "reklamowa" stopa roczna. | Rzeczywista stopa zwrotu lub kosztu. |
| **Co uwzględnia?** | Tylko wartość bazową oprocentowania. | Wartość bazową **oraz** efekt procentu składanego. |
| **Kiedy używać?** | Jako punkt wyjścia do obliczeń. | Do **porównywania** różnych ofert finansowych. |
| **Relacja** | `r_nom ≤ r_eff` | `r_eff ≥ r_nom` |

**Złota zasada:** Zawsze, gdy porównujesz dwie lokaty lub dwa kredyty, **patrz na efektywną stopę procentową** (lub jej odpowiednik, np. RRSO – Rzeczywistą Roczną Stopę Oprocentowania w przypadku kredytów). Tylko ona powie Ci, która oferta jest naprawdę korzystniejsza.

**Przykład:**
*   **Kredyt A:** 10% nominalnie, kapitalizacja miesięczna.
*   **Kredyt B:** 10,1% nominalnie, kapitalizacja półroczna.

Na pierwszy rzut oka Kredyt A wydaje się tańszy. Obliczmy efektywne stopy:
*   **Kredyt A (r_eff):** (1 + 0,10 / 12)¹² - 1 ≈ **10,47%**
*   **Kredyt B (r_eff):** (1 + 0,101 / 2)² - 1 ≈ **10,36%**

Okazuje się, że Kredyt B, mimo wyższej stopy nominalnej, jest w rzeczywistości tańszy, ponieważ odsetki są doliczane rzadziej.

### 2. Pojęcie renty oraz główne rodzaje rent – ich wartości obecne, wartości przyszłe i przykłady zastosowań.

#### **Renty**

Renta to ciąg płatności (rat) dokonywanych w równych odstępach czasu.

---

-   **Renta odroczona (płatna z dołu)**  

$$
PV = R \cdot \frac{1 - (1+i)^{-n}}{i}, 
\qquad
FV = R \cdot \frac{(1+i)^n - 1}{i}
$$

---

-   **Renta płatna z góry**  

$$
PV = R \cdot \frac{1 - (1+i)^{-n}}{i} \cdot (1+i),
\qquad
FV = R \cdot \frac{(1+i)^n - 1}{i} \cdot (1+i)
$$

---

-   **Renta o ratach tworzących ciąg arytmetyczny**  

$$
R_k = R_1 + (k-1)d
$$  

$$
PV = \sum_{k=1}^{n} \frac{R_1 + (k-1)d}{(1+i)^k},
\qquad
FV = \sum_{k=1}^{n} (R_1 + (k-1)d) \cdot (1+i)^{\,n-k}
$$

---

-   **Renta o ratach tworzących ciąg geometryczny**  

$$
R_k = R_1 \cdot q^{k-1}
$$  

$$
PV = \sum_{k=1}^{n} \frac{R_1 \cdot q^{k-1}}{(1+i)^k},
\qquad
FV = \sum_{k=1}^{n} R_1 \cdot q^{k-1} \cdot (1+i)^{\,n-k}
$$

---

-   **Renty ciągłe**  

$$
PV = \int_{0}^{n} R \cdot e^{-i t} \, dt 
    = \frac{R}{i} \left(1 - e^{-i n}\right)
$$  

$$
FV = \int_{0}^{n} R \cdot e^{i (n-t)} \, dt 
    = \frac{R}{i} \left(e^{i n} - 1\right)
$$



### 3. Procesy akumulacji i dyskontowania oraz ich rodzaje.

| Proces            | Rodzaj  | Wzór matematyczny               |
|-------------------|---------|---------------------------------|
| **Akumulacja**    | Prosta  | $K(t)= K \cdot (1 + i \cdot t)$ |
|                   | Złożona | $K(t) = K \cdot (1+i)^t$        |
|                   | Ciągła  | $K(t) = K \cdot e^{i \cdot t}$  |
| **Dyskontowanie** | Proste  | $PV = \frac{FV}{1 + i \cdot t}$ |
|                   | Złożone | $PV = \frac{FV}{(1+i)^t}$       |
|                   | Ciągłe  | $PV = FV \cdot e^{-i \cdot t}$  |

-   **Akumulacja**:
    -   **Prosta**: Opiera się na idei ciągu arytmetycznego. Odsetki dopisujemy [po upływie okresu bazowego]{.underline}. Każdy okres daje nam taką samą wartość odsetek.
    -   **Złożona**: opiera się na idei ciągu geometrycznego – odsetki są doliczane do kapitału i [w kolejnych okresach również pracują]{.underline}, dlatego kapitał rośnie szybciej niż w przypadku odsetek prostych.
    -   **Ciągła**: zakładamy, że kapitalizacja następuje w nieskończenie wielu małych krokach, co prowadzi do użycia funkcji wykładniczej. To model najbardziej "teoretyczny", ale użyteczny np. w analizach rynkowych.
-   **Dyskontowanie**: proces odwrotny do akumulacji (liczymy wartość bieżącą z wartości przyszłej).
    -   **Proste**: zakładamy, że odsetki są odejmowane liniowo (tak jak w akumulacji prostej). Każdy kolejny okres obniża wartość przyszłą o taką samą "porcję" czasu
    -   **Złożone**: tu również działa mechanizm kapitalizacji odsetek składanych, tylko w odwrotną stronę – sprowadzamy przyszłą wartość poprzez dzielenie przez kolejne potęgi czynnika $(1+i)$.
    -   **Ciągłe**: To podejście często używane w finansach matematycznych (np. przy wycenie obligacji i instrumentów pochodnych).

<br>

## 12. Inżynieria ubezpieczeń majątkowych

### 1. Modele ryzyka stosowane w ubezpieczeniach majątkowych

W teorii ubezpieczeń majątkowych do opisu i kwantyfikacji ryzyka portfela stosuje się dwa fundamentalne modele: **model ryzyka indywidualnego** oraz **model ryzyka łącznego (kolektywnego)**.

#### Model Ryzyka Indywidualnego

Model ten koncentruje się na pojedynczych polisach w portfelu. Całkowita strata portfela ($S$) jest modelowana jako suma strat ($X_i$) z poszczególnych, niezależnych ryzyk (polis).

*   **Definicja:**
    $$S = X_1 + X_2 + \dots + X_n$$
    gdzie:
    *   $n$ jest **ustaloną** (nielosową) liczbą ryzyk w portfelu.
    *   $X_i$ to zmienna losowa opisująca wysokość szkody z $i$-tej polisy.

*   **Założenia:**
    *   Ryzyka (zmienne losowe $X_i$) są statystycznie niezależne.
    *   W okresie ubezpieczenia dla każdego ryzyka szkoda może wystąpić co najwyżej raz.

*   **Zastosowanie:** Model ten jest użyteczny do analizy jednorodnych portfeli. Jednak ze względu na złożoność obliczeniową (wymaga tzw. **splotów rozkładów prawdopodobieństwa**) jest mniej praktyczny dla dużych i zróżnicowanych portfeli ubezpieczeń majątkowych.

#### Model Ryzyka Łącznego (Kolektywnego)

Model ten traktuje portfel jako całość -- jako proces, który w danym okresie generuje pewną liczbę szkód o różnej wysokości. Zamiast sumować straty po polisach, modeluje się zagregowaną (łączną) wartość szkód.

*   **Definicja:**
    $$X = Y_1 + Y_2 + \dots + Y_N$$
    gdzie:
    *   $N$ jest **zmienną losową** oznaczającą łączną liczbę szkód w portfelu.
    *   $Y_i$ to zmienna losowa opisująca wysokość $i$-tej szkody.
    *   Gdy $N=0$, wtedy $X=0$.

*   **Założenia:**
    *   Proces generujący liczbę szkód ($N$) jest niezależny od wysokości poszczególnych szkód ($Y_i$).
    *   Wysokości szkód ($Y_i$) są zmiennymi losowymi o identycznym rozkładzie i są wzajemnie niezależne.

*   **Zastosowanie:** Jest to dominujący model w ubezpieczeniach majątkowych. Jego siła polega na rozdzieleniu ryzyka na dwa kluczowe komponenty:
    1.  **Częstotliwość szkód** (modelowana przez rozkład zmiennej $N$).
    2.  **Wysokość (dotkliwość) szkód** (modelowana przez rozkład zmiennej $Y$).
    Rozkład łącznej wartości szkód $X$ nazywany jest **rozkładem złożonym**.

---

### 2. Podstawowe rozkłady liczby szkód w modelu ryzyka łącznego

W modelu ryzyka łącznego kluczowym elementem jest właściwe zamodelowanie losowej liczby szkód ($N$). W praktyce aktuarialnej stosuje się głównie trzy poniższe rozkłady.

#### Rozkład Poissona

Jest to najczęściej stosowany i fundamentalny rozkład dla liczby szkód.

*   **Charakterystyka:** Modeluje liczbę zdarzeń (szkód) zachodzących losowo i niezależnie w ustalonym przedziale czasu, przy stałej średniej intensywności ($\lambda$).
*   **Wzór:**
    $$P(N = k) = \frac{\lambda^k}{k!} e^{-\lambda}, \quad k=0, 1, 2, \dots$$
*   **Własności w ubezpieczeniach:**
    *   Równość wartości oczekiwanej i wariancji: $E(N) = \text{Var}(N) = \lambda$.
    *   **Własność agregacji:** Suma niezależnych zmiennych losowych o rozkładach Poissona również ma rozkład Poissona. Ułatwia to łączenie subportfeli.

#### Rozkład ujemny dwumianowy

Jest to uogólnienie rozkładu Poissona, które oferuje większą elastyczność.

*   **Charakterystyka:** Stosowany, gdy wariancja liczby szkód jest większa niż jej wartość oczekiwana (**zjawisko naddyspersji**). Jest to częsta sytuacja w praktyce, gdy ryzyko w portfelu nie jest w pełni jednorodne.
*   **Własności w ubezpieczeniach:**
    *   Wariancja większa od wartości oczekiwanej: $\text{Var}(N) > E(N)$.
    *   Lepiej dopasowuje się do danych, gdzie szkody występują w sposób bardziej skumulowany lub nieregularny niż w modelu Poissona.

#### Rozkład dwumianowy

Stosowany w bardziej specyficznych sytuacjach, gdy liczba potencjalnych szkód jest z góry ograniczona.

*   **Charakterystyka:** Opisuje liczbę szkód w stałej liczbie $n$ niezależnych polis, gdzie prawdopodobieństwo szkody $q$ jest takie samo dla każdej polisy.
*   **Wzór:**
    $$P(N = k) = \binom{n}{k} q^k (1-q)^{n-k}, \quad k=0, 1, \dots, n$$
*   **Własności w ubezpieczeniach:**
    *   Wariancja mniejsza od wartości oczekiwanej: $\text{Var}(N) < E(N)$.
    *   Stosuje się go głównie w zamkniętych, jednorodnych portfelach o znanej liczbie ryzyk.

::: {.callout-note title="Podsumowanie wyboru rozkładu"}
Wybór rozkładu zależy od charakterystyki portfela. Rozkład Poissona jest punktem wyjścia, rozkład ujemny dwumianowy jego elastycznym rozszerzeniem dla danych o dużej zmienności, a rozkład dwumianowy ma zastosowanie w specyficznych, ograniczonych przypadkach.
:::

---

### 3. Funkcja generująca momenty i funkcja generująca kumulanty oraz ich zastosowanie

Funkcja generująca momenty (FGM) i funkcja generująca kumulanty (FGK) to potężne narzędzia matematyczne, które znacząco upraszczają analizę ryzyka w portfelu.

#### Definicje

*   **Funkcja Generująca Momenty (FGM):** Dla zmiennej losowej $X$, jej FGM jest zdefiniowana jako:
    $$M_X(t) = E(e^{tX})$$
    Jej $k$-ta pochodna w punkcie $t=0$ jest równa $k$-temu **momentowi zwykłemu** ($E(X^k)$).

*   **Funkcja Generująca Kumulanty (FGK):** Jest zdefiniowana jako logarytm naturalny z FGM:
    $$C_X(t) = \ln(M_X(t))$$
    Jej $k$-ta pochodna w $t=0$ jest równa $k$-tej **kumulancie** ($c_k$), która jest powiązana z momentami centralnymi (np. $c_1 = \mu$, $c_2 = \sigma^2$).

#### Zastosowanie w teorii ubezpieczeń

1.  **Uproszczenie analizy sumy ryzyk:**
    Analiza rozkładu sumy niezależnych ryzyk $S = X_1 + \dots + X_n$ za pomocą standardowych metod (splotów) jest bardzo skomplikowana. FGM i FGK zamieniają tę operację na proste działania algebraiczne:
    *   **FGM sumy to iloczyn FGM składników:** $M_S(t) = \prod_{i=1}^n M_{X_i}(t)$
    *   **FGK sumy to suma FGK składników:** $C_S(t) = \sum_{i=1}^n C_{X_i}(t)$
    
    ::: {.callout-tip title="Kluczowa własność"}
    Addytywność kumulant jest niezwykle użyteczna. Pozwala obliczyć np. wariancję całego portfela poprzez proste zsumowanie wariancji poszczególnych, niezależnych ryzyk.
    :::

2.  **Analiza modelu ryzyka łącznego (rozkładu złożonego):**
    To jedno z najważniejszych zastosowań. Dla modelu łącznego, gdzie $X = Y_1 + \dots + Y_N$, zachodzi fundamentalna zależność:
    $$C_X(t) = C_N(C_Y(t))$$
    Wzór ten pozwala w elegancki sposób wyprowadzić momenty całego portfela, znając jedynie charakterystyki rozkładu liczby i wysokości szkód. Z tej zależności wynikają m.in. kluczowe wzory:
    $$E(X) = E(N) \cdot E(Y)$$
    $$\text{Var}(X) = \text{Var}(N) \cdot [E(Y)]^2 + E(N) \cdot \text{Var}(Y)$$

3.  **Charakterystyka i aproksymacja rozkładów:**
    Momenty i kumulanty, obliczone za pomocą FGM i FGK, dostarczają kluczowych informacji o kształcie rozkładu łącznej straty (np. o jego symetrii i "grubości ogonów"). Informacje te są niezbędne do:
    *   Kalkulacji **składki ryzyka** i **kapitału wymaganego**.
    *   Wyboru odpowiedniej **metody aproksymacji** rozkładu łącznej straty (np. aproksymacji normalnej lub przesuniętym rozkładem gamma).

<br>

## 13. Inżynieria ubezpieczeń życiowych

### 1. Tablice trwania życia i ich zastosowanie w ubezpieczeniach życiowych.

Tablice trwania życia (ang. life tables) to fundamentalne narzędzie statystyczne i demograficzne, które w formie tabelarycznej przedstawia proces wymierania hipotetycznej grupy osób (tzw. kohorty - grupa badawcza która ze względu na jej właściwość jest poddawana analizie) od momentu urodzenia aż do śmierci ostatniego jej członka. Są one tworzone na podstawie historycznych danych o śmiertelności w danej populacji (np. dla danego kraju, płci i rocznika).

#### Zastosowanie w ubezpieczeniach życiowych:

Na podstawie tablic trwania życia obliczane są wartości aktuarialne w ubezpieczeniach na życie. Generalne zastosowania:

-   ***Ocena Ryzyka***: Ubezpieczyciel musi oszacować ryzyko, że będzie musiał wypłacić świadczenie. Prawdopodobieństwo zgonu ($q_x$) jest bezpośrednią miarą tego ryzyka. Im wyższe $q_x$ dla danej grupy wiekowej, tym wyższe ryzyko dla ubezpieczyciela.
-   ***Kalkulacja Składek***: Prawdopodobieństwa przeżycia i zgonu są podstawą do obliczania składek ubezpieczeniowych. Na przykład w ubezpieczeniu na życie składka będzie zależała od prawdopodobieństwa śmierci w każdym kolejnym roku trwania umowy. W ubezpieczeniu na dożycie kluczowe będzie prawdopodobieństwo przeżycia określonego okresu.
-   ***Tworzenie Rezerw Techniczno-Ubezpieczeniowych***: Ubezpieczyciel ma obowiązek tworzenia rezerw finansowych na pokrycie przyszłych zobowiązań. Wysokość tych rezerw jest szacowana z wykorzystaniem tablic trwania życia, które pozwalają przewidzieć, ile świadczeń i kiedy będzie trzeba wypłacić w przyszłości.
-   ***Wycena Produktów Emerytalnych i Rentowych***: W przypadku rent życiowych, które są wypłacane "do końca życia", tablice pozwalają oszacować, jak długo statystycznie będą trwały wypłaty, co jest kluczowe dla ustalenia wartości takiego produktu i wysokości składki.

### 2. Pojęcie wartości aktuarialnej w ubezpieczeniach życiowych.

***Wartość aktuarialna*** (nazywana też wartością obecną netto świadczeń lub składką jednorazową netto) to wartość obecna oczekiwanych przyszłych płatności związanych z umową ubezpieczenia.

wartość aktuarialna ubezpieczenia (składka jednorazowa netto $Ā_x$) jest zdefiniowana jako wartość oczekiwana zmiennej losowej $Z$, która reprezentuje zdyskontowaną wartość przyszłego świadczenia: $$Ā_x = E(Z) = E(v^{T(x)})$$ gdzie: - $T(x)$ to przyszły czas życia osoby w wieku x (zmienna losowa). - $v^{T(x)}$ to zdyskontowana wartość świadczenia w wysokości 1, wypłaconego w momencie śmierci.

Wartość aktuarialna świadczenia reprezentuje ***średni koszt***, jaki ubezpieczyciel poniesie w związku z daną polisą, wyrażony w dzisiejszej wartości pieniądza. Jest to kwota, którą ubezpieczyciel musiałby otrzymać w momencie zawarcia umowy (jako jednorazową wpłatę), aby statystycznie być w stanie pokryć przyszłe zobowiązanie. Z tego powodu wartość aktuarialna świadczenia jest tożsama z ***jednorazową składką netto***.

### 3. Obliczanie składek netto w ubezpieczeniach życiowych.

Składka netto to część składki ubezpieczeniowej przeznaczona wyłącznie na pokrycie przewidywanych przyszłych świadczeń. Nie uwzględnia ona kosztów administracyjnych, prowizji, zysku ubezpieczyciela ani marginesu na nieprzewidziane ryzyko. Te dodatkowe elementy są zawarte w tzw. składce brutto, którą finalnie płaci klient.

Obliczanie składki netto opiera się na ***zasadzie równoważności***, która mówi, że w momencie zawarcia umowy: $$\text{Wartość aktuarialna przyszłych składek} = \text{Wartość aktuarialna przyszłych świadczeń}$$

-   ***Składka jednorazowa netto (SJN)***: Jest to najprostszy przypadek. Skoro składka jest płacona tylko raz, na początku, to jej wartość aktuarialna jest równa jej wysokości. Zgodnie z zasadą równoważności, jest ona po prostu równa wartości aktuarialnej świadczeń. $$JSN = A_x$$ (gdzie $A_x$ to wartość aktuarialna świadczenia, np. w ubezpieczeniu na życie)

-   ***Rozczna składka netto***: Jest to znacznie częstszy model, w którym klient płaci składki regularnie (np. co roku) przez cały okres trwania umowy. Strumień tych składek to tzw. renta życiowa.

Bezterminowe ubezpieczenie na życie, płatne nakoniec roku śmierci, równe składki coroczne:

$$L = v^{K(x)+1} - P_x \cdot \ddot{a}_{\overline{K(x)+1}}$$ czyli

$$ P_x = \frac{A_x}{\ddot{a}_x} $$ gdzie: - $P_x$ - roczna składka netto; - $\ddot{a}_x$ - wartość aktuarialna renty życiowej;

Składka roczna netto to nic innego jak całkowity, uśredniony koszt ubezpieczenia ($A_x$), "rozłożony na raty" płatne przez oczekiwany okres opłacania składek (którego wartość jest ujęta w $\ddot{a}_x$)

<br>
