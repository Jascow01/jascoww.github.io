[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tu beda fajne dashbordy i w ogóle",
    "section": "",
    "text": "Untitled\n\n\n\n\n\n\nSzymon Door\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Post\n\n\n\nIAD\n\n\n\nPost description\n\n\n\nSzymon Door\n\n\nAug 10, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "los.html",
    "href": "los.html",
    "title": "los",
    "section": "",
    "text": "# tutaj bedzie losowanie pytan"
  },
  {
    "objectID": "posts/post1.html",
    "href": "posts/post1.html",
    "title": "My Post",
    "section": "",
    "text": "siema co tutaj sie dzieje?"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#definicja-własności-i-wybrane-zastosowania-macierzy-jordana.",
    "href": "posts/10-08-2025-first-post/index.html#definicja-własności-i-wybrane-zastosowania-macierzy-jordana.",
    "title": "My Post",
    "section": "1. Definicja, własności i wybrane zastosowania macierzy Jordana.",
    "text": "1. Definicja, własności i wybrane zastosowania macierzy Jordana.\n\nDEFINICJA (Klatka Jordana)\nMacierz \\(J_r(\\lambda) \\in M_r(\\mathbb{K})\\) postaci: \\[\nJ_r(\\lambda) =\n\\begin{pmatrix}\n\\lambda & 1 & 0 & \\cdots & 0 \\\\\n0 & \\lambda & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda & 1 \\\\\n0 & 0 & \\cdots & 0 & \\lambda\n\\end{pmatrix}\n\\] gdzie \\(\\lambda \\in \\mathbb{K}\\), nazywamy klatką Jordana stopnia \\(r\\). W szczególnym przypadku \\(J_1(\\lambda) = [\\lambda]\\).\n\nDEFINICJA (Macierz Jordana)\nMacierz blokową \\(J \\in M_n(\\mathbb{K})\\) postaci: \\[\nJ =\n\\begin{pmatrix}\nJ_{n_1}(\\lambda_1) & & & \\\\\n& J_{n_2}(\\lambda_2) & & \\\\\n& & \\ddots & \\\\\n& & & J_{n_k}(\\lambda_k)\n\\end{pmatrix}\n\\] gdzie \\(n_1 + n_2 + \\dots + n_k = n\\), \\(\\lambda_1, \\dots, \\lambda_k \\in \\mathbb{K}\\) oraz wszystkie niewypisane elementy są zerami, nazywamy macierzą Jordana.\n\n\nTWIERDZENIE (Postać Jordana macierzy)\nNiech \\(A \\in M_n(\\mathbb{K})\\), gdzie \\(\\mathbb{K} = \\mathbb{R}\\) lub \\(\\mathbb{K} = \\mathbb{C}\\). Wtedy istnieje macierz nieosobliwa \\(P \\in M_n(\\mathbb{K})\\) taka, że macierz \\(J = P^{-1}AP\\) jest macierzą Jordana. Macierz \\(J\\) nazywamy macierzą Jordana macierzy A. Jest ona wyznaczona jednoznacznie z dokładnością do kolejności klatek Jordana.\n\n\nWłasności Macierzy Jordana\n\nWartości własne: Skalary \\(\\lambda_1, \\dots, \\lambda_k\\) tworzące główną przekątną macierzy Jordana \\(J\\) są jej wartościami własnymi.\nZwiązek z diagonalizacją: Każda macierz diagonalna jest macierzą Jordana (z klatkami wymiaru 1x1). Oznacza to, że każda macierz diagonalizowalna jest podobna do pewnej macierzy Jordana.\nLiczba klatek Jordana:\n\nLiczba wszystkich klatek Jordana w macierzy \\(J\\) jest równa liczbie liniowo niezależnych wektorów własnych macierzy \\(A\\).\nLiczba klatek Jordana odpowiadających konkretnej wartości własnej \\(\\lambda\\) jest równa wymiarowi podprzestrzeni własnej \\(W_\\lambda\\) (krotności geometrycznej tej wartości własnej).\n\nRozmiar klatek Jordana: Suma stopni (wymiarów) wszystkich klatek Jordana odpowiadających wartości własnej \\(\\lambda\\) jest równa krotności algebraicznej tej wartości własnej (czyli jej krotności jako pierwiastka wielomianu charakterystycznego).\nWektory dołączone: Struktura macierzy Jordana (liczba i rozmiary klatek) jest ściśle powiązana z istnieniem tzw. wektorów dołączonych. Dla wartości własnej \\(\\lambda\\) o krotności algebraicznej \\(r\\) istnieje dokładnie \\(r\\) liniowo niezależnych wektorów dołączonych, które tworzą bazę Jordana.\n\n\n\nWybrane Zastosowania Macierzy Jordana\nGłównym zastosowaniem przedstawionym w materiałach jest uproszczenie obliczeń funkcji macierzy.\n\n\nTWIERDZENIE\nJeżeli \\(f\\) jest wielomianem o współczynnikach z ciała \\(\\mathbb{K}\\), zaś \\(J\\) jest macierzą Jordana w postaci blokowej jak w definicji, to zachodzi równość: \\[\nf(J) =\n\\begin{pmatrix}\nf(J_{n_1}(\\lambda_1)) & & & \\\\\n& f(J_{n_2}(\\lambda_2)) & & \\\\\n& & \\ddots & \\\\\n& & & f(J_{n_k}(\\lambda_k))\n\\end{pmatrix}\n\\] Obliczenie funkcji dla całej macierzy sprowadza się do obliczenia jej dla poszczególnych klatek Jordana.\n\n\nTWIERDZENIE (Funkcja klatki Jordana)\nJeżeli \\(J_r(\\lambda)\\) jest klatką Jordana stopnia \\(r\\), to wartość funkcji \\(f(J_r(\\lambda))\\) można obliczyć za pomocą następującego wzoru, wykorzystującego pochodne funkcji \\(f\\): \\[\nf(J_r(\\lambda)) =\n\\begin{pmatrix}\nf(\\lambda) & f'(\\lambda) & \\frac{f''(\\lambda)}{2!} & \\cdots & \\frac{f^{(r-1)}(\\lambda)}{(r-1)!} \\\\\n0 & f(\\lambda) & f'(\\lambda) & \\cdots & \\frac{f^{(r-2)}(\\lambda)}{(r-2)!} \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & f(\\lambda) & f'(\\lambda) \\\\\n0 & 0 & \\cdots & 0 & f(\\lambda)\n\\end{pmatrix}\n\\] To zastosowanie jest kluczowe np. przy obliczaniu eksponenty macierzy \\(e^{At}\\), co jest fundamentalne w rozwiązywaniu układów równań różniczkowych liniowych.\n\n\n\n2. Definicja przestrzeni unitarnej i metoda ortogonalizacji Grama-Schmidta.\nDefinicja: Przestrzeń wektorową, w której wprowadzono iloczyn skalarny nazywamy przestrzenią unitarną.\n\n\nMetroda ortogonalizacji Grama-Schmidta:\n\n\n\n3. Wybrane metody dekompozycji macierzy.\n\nRozkład \\(LU\\)\nRozkład \\(QR\\)\nRozkład \\(SVD\\)\nRozkład \\(Shura\\)\nRozkłąd \\(Choleskiego\\)"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#definicja-przestrzeni-unitarnej-i-metoda-ortogonalizacji-grama-schmidta.",
    "href": "posts/10-08-2025-first-post/index.html#definicja-przestrzeni-unitarnej-i-metoda-ortogonalizacji-grama-schmidta.",
    "title": "My Post",
    "section": "2. Definicja przestrzeni unitarnej i metoda ortogonalizacji Grama-Schmidta.",
    "text": "2. Definicja przestrzeni unitarnej i metoda ortogonalizacji Grama-Schmidta.\nDefinicja: Przestrzeń wektorową, w której wprowadzono iloczyn skalarny nazywamy przestrzenią unitarną.\n\n\nMetroda ortogonalizacji Grama-Schmidta:"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#wybrane-metody-dekompozycji-macierzy.",
    "href": "posts/10-08-2025-first-post/index.html#wybrane-metody-dekompozycji-macierzy.",
    "title": "My Post",
    "section": "3. Wybrane metody dekompozycji macierzy.",
    "text": "3. Wybrane metody dekompozycji macierzy.\n\nRozkład \\(LU\\)\nRozkład \\(QR\\)\nRozkład \\(SVD\\)\nRozkład \\(Shura\\)\nRozkłąd \\(Choleskiego\\)"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#zaawansowane-metody-uczenia-maszynowego",
    "href": "posts/10-08-2025-first-post/index.html#zaawansowane-metody-uczenia-maszynowego",
    "title": "My Post",
    "section": "2. Zaawansowane metody uczenia maszynowego",
    "text": "2. Zaawansowane metody uczenia maszynowego\n\n1. Zasada działania sieci typu Transformer.\n\nEnkoder Dostaje na wejściu dane wejściowe które następnie są konwertowane na tzw. embeddingi (osadzenia) ponieważ dla komputera łatwiej jest interpretować cyfry. Do powstałej reprezentacji dodajemy tzw. positional embedding’s aby mógł interpretować pozycje słów występujących w sekwencji z uwagi na to, że słowa mogą mieć różne znaczenie ze względu na kolejnośc w zdaniu.\nDziałanie Self-Attention można opisać następująco:\nDla każdego tokenu tworzone są trzy wektory: Query (Q), Key (K) i Value (V).\n\nQuery (Q): Reprezentuje zapytanie, czyli to, czego szukamy w innych tokenach.\nKey (K): Reprezentuje cechy tokenu, które mogą być istotne dla innych tokenów.\nValue (V): Reprezentuje faktyczną wartość lub informację, którą token niesie.\n\nPorównując Query jednego tokenu z Key pozostałych tokenów, obliczana jest waga (stopień „uwagi”), czyli jak bardzo dany token powinien brać pod uwagę inny token.\nWagi te są następnie używane do zsumowania Value tokenów w sposób ważony, co daje nową reprezentację tokenu uwzględniającą kontekst całego zdania.\nPonieważ jeden mechanizm uwagi mógłby koncentrować się tylko na jednym aspekcie relacji między słowami, w transformerze stosuje się Multi-Head Attention – wiele równoległych głów uwagi. Każda z nich może analizować inny typ powiązań (np. składnię, znaczenie, zależności czasowe), a wyniki są łączone w jedną bogatszą reprezentację.\nPo bloku uwagi wyniki są przekazywane przez Feed-Forward Network – prostą, w pełni połączoną sieć neuronową, która przetwarza każdy token niezależnie, umożliwiając modelowi tworzenie bardziej złożonych reprezentacji. Każda warstwa transformera zawiera również resztkowe połączenia (residual connections) i normalizację warstw (Layer Normalization), co pozwala na stabilniejsze i szybsze uczenie się głębokiego modelu.\nDekoder\nDekoder odpowiedzialny jest za generowanie sekwencji wyjściowej. Token wyjściowy jest tworzony na podstawie: - wcześniej wygenerowanych tokenów, - reprezentacji wejściowej dostarczonej przez enkoder\n\nMasked Multi-Head Self Attention\n\n\nDekoder używa mechanizmu samo-uwagi na już wygenerowanych tokenach\nMaskowanie, czyli model nie może “patrzeć w przyszłość”, znaczy to, że uwaga jest ograniczona do aktualnych i wcześniejszych tokenów.\nDzięki temuu dredykcja kolejnego słowa bazuje tylko na wcześniejszych słowach, a nie na tych które właśnie będą generowane\n\n\nAdd & Norm\n\n\nWarstwy normalizacji oraz reszt\n\n\nMulti-Head Cross-Attention\n\n\nDekoder zwraca uwagę na wyjście z enkodera\nMechanizm polega na tym, że Query(Q) pochodzi z dekodera, a Key(K) i Value(V) z enkodera dzięki temu dekoder szuka odpowiednich fragmentów informacji potrzebnych do wygenerowania kolejnego słowa\n\n\nAdd & Norm\nFeed-Forward Network (FFN)\nAdd & Norm\n\n\n\n2. Problem zanikającego i eksplodującego gradientu w modelach rekurencyjnych.\nProblemy zanikającegi i eksplodującego gradientu można przedstawić w następujący sposób:\n\nZanikający gradient: Coraz mniejsze gradienty powodują coraz mniejsze zmniany wag w węzłach głebkiej sieci neuronowej, co porowadzi do niewielkiego lub żadnego uczenia się.\nEksplodujący gradient: Gradienty stają się zaskakująco duże, przez co następują duże aktualizacje wag (powtarzające się mnożenie dużych wag) każdego węzła w głebokiej sieci neuronowej\n\n\n\n3. Rozwiązania z zakresu technik głębokiego uczenia dedykowanych do zadań wizji komputerowej.\n\nKonwolucyjne sieci neuronowe (CNN, Convolutional Neural Networks)\nSieci generatywne\n\n\nGAN (Geeral Adversarial Networks)\nVariacynjy Auroenkoder (VAE) - probabilistyczne modele generatywne\nDiffusion Models (np. DALLE) - obecnie dominujące\n\n\nTransformery w wizji komputerowej\n\n\nVision Transformer (ViT) - dzieli obraz na fragmenty, a następnie traktuje je jak sekwencje tokenów\n\n\nSieci detekcji obiektów\n\n\nOne-stage detectors:\n\nSieci YOLO (You Only Look Once) - szybkie modele które wykrywają obiekty w czasie rzeczywistym\n\nTwo-stage detectors:\n\nR-CNN, Fast R-CNN - najpierw generują regiony zainteresowanie (RoI), potem klasyfikują"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#wdrażanie-modeli-uczenia-maszynowego",
    "href": "posts/10-08-2025-first-post/index.html#wdrażanie-modeli-uczenia-maszynowego",
    "title": "My Post",
    "section": "3. Wdrażanie modeli uczenia maszynowego",
    "text": "3. Wdrażanie modeli uczenia maszynowego\n\n1. Podstawowe komendy REST API służące do komunikacji.\nGET - Pobiera dane z serwera. Nie modyfikuje zasobów.\n\nPrzykład: GET /users — pobierz listę użytkowników.\n\nPOST - Tworzy nowy zasób na serwerze. Przykład: POST /users — dodaj nowego użytkownika (dane w body).\nPUT - Aktualizuje istniejący zasób w całości (zastępuje go nowym).\n\nPrzykład: PUT /users/123 — nadpisz dane użytkownika o ID 123.\n\nPATCH - Aktualizuje tylko część zasobu.\n\nPrzykład: PATCH /users/123 — zmień np. tylko email użytkownika 123.\n\nDELETE - Usuwa zasób z serwera.\n\nPrzykład: DELETE /users/123 — usuń użytkownika o ID 123.\n\n\n\n2. Reaktywność i realizacja w aplikacjach Shiny.\nReaktywność w Shiny to mechanizm, który śledzi zależności między częscią wejściową a wyjściową. Dzięki temu, aplikacja przelicza tylko te elementy, które są od siebie zależne niż wykonywać cały kod od nowa.\n\nPowyższa ilustracja przedstawia etapy reaktywności w Shiny:\n\nW momencie uruchomienia aplikacji Shiny uruchamia (losowe) wyjście. Ponieważ wywołanie to jest zależne od wyników wywołań reaktywnych, tworzy się połączenia z wyrażeniami reaktywnymi. W tym przypadku pierwsze wywołanie nazwijmy je x.\nNastępnie inicjalizowane są wyrażenia reaktywne które są zależne od wyjścia, a następnie kolejno te które są zależne od innych metod aplikacji\nNa sam koniec, wszystkie operacje wymagane do egzekucji wyjścia x zostały policzone a następnie wyświetlone\n\n\nPowyższa ilustracja przedstawia moment w którym dochodzi do modyfikacji danych wejściowych]\n\nWyjście oraz metody, które były zależne do wykonania obliczeń oznacza się jako “invalidated”. Również połączenia z innymi metodami, które bezpośrednio nie miałyby zostać wyświetlone (patrz środkowe wyjście) oraz jednocześnie przypisywana jest nowa wartość dla wejścia (patrz pierwsze wejście od góry).\nW dalszej kolejności znów jedno z wyjść unieważnionych (ang. invalidated) jest poddane egzekucji, która pociąga za sobą egzekucje tych wejść i wyrażeń reaktywnych, które są wymagane do obliczenia wartości lub wyświetlenia wyjścia.\n\n\n\n3. Metody optymalizacji wydajności aplikacji Shiny obsługującej duże zbiory danych.\nOptymalizacja w Shiny sprowadza się do:\n\nMinimalizacji danych w pamięci (agregacje, filtrowanie, server-side processing).\nRozsądnego użycia reaktywności (tylko to, co trzeba, kiedy trzeba).\nWydzielenia ciężkich obliczeń do backendu lub równoległości (future, API).\nSkalowania serwera przy produkcyjnych wdrożeniach."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#wybrane-problemy-teorii-niezawodności",
    "href": "posts/10-08-2025-first-post/index.html#wybrane-problemy-teorii-niezawodności",
    "title": "My Post",
    "section": "4. Wybrane problemy teorii niezawodności",
    "text": "4. Wybrane problemy teorii niezawodności\n\n1. Rozkłady statystyczne stosowane w analizie niezawodności.\n\nRozkład wykładniczy (Exponential distribution)\nRozkład Weibulla (Weibull distribution)\nRozkład normalny (Normal / Gaussian distribution)\nRozkład Gamma\nRozkład Rayleigha\nRozkład Bernoulliego / dwumianowy / Poissona\n\n\n\n2. Modele szeregowe, równoległe i mieszane obiektów technicznych.\n\nModel szeregowy (ang. series system)\n\nSystem działa tylko wtedy, gdy działają wszystkie jego elementy.\nAwaria jednego elementu powoduje awarię całego systemu.\n\nModel równoległy (ang. parallel system)\n\nSystem działa, jeżeli działa przynajmniej jeden z elementów.\nAwaria następuje dopiero, gdy wszystkie elementy zawiodą.\n\nModel mieszany (ang. mixed system)\n\nRzeczywiste systemy rzadko są idealnie szeregowe lub równoległe.\nNajczęściej są to kombinacje obu typów — niektóre podzespoły muszą działać wszystkie (połączenie szeregowe), a inne mają redundancję (połączenie równoległe).\n\n\n\n\n3. Wskaźniki gotowości systemu - MTBF, MTTR, dostępność eksploatacyjna.\n\nMTBF – Mean Time Between Failures (Średni czas między awariami)\n\nDefinicj: Średni czas pracy systemu pomiędzy kolejnymi awariami wymagającymi naprawy.\nInterpretacja: Jest to miara niezawodności – im większy MTBF, tym system rzadziej ulega awarii.\n\nMTTR – Mean Time To Repair (Średni czas naprawy)\n\nDefinicja: Średni czas potrzebny do przywrócenia systemu do pracy po awarii.\nInterpretacja: Jest to miara utrzymywalności (maintainability) – im mniejszy MTTR, tym szybciej system wraca do działania.\n\nDostępność eksploatacyjna (Availability, A)\n\nDefinicja: Prawdopodobieństwo, że system jest w danym momencie zdolny do wykonania swojej funkcji."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#metody-numeryczne-w-zastosowaniach",
    "href": "posts/10-08-2025-first-post/index.html#metody-numeryczne-w-zastosowaniach",
    "title": "My Post",
    "section": "5 Metody numeryczne w zastosowaniach",
    "text": "5 Metody numeryczne w zastosowaniach\n\n1. Wartości własne macierzy i sposoby ich wyznaczania.\n\nMetoda potęgowa\nSłuży do wyznaczenia maksymalnej co do modułu wartości własnej i odpowiadającego jej wektora własnego\n\n\n\nMetoda iteracji odwrotnej\n\nWariant metody potęgowej służący do wyznaczenia wartości własnej macierzy, najbliższej zeru​\nPodstawą jest twierdzenie, że wartości własne macierzy odwrotnej są odwrotnościami wartości własnych macierzy danej\nSposób postępowania jest podobny do metody zwykłej z zastrzeżeniem dotyczącym kroku potęgowego\n\n\n\n\nMacierz Hessenbergowska (górna)\n\n\n\n2. Metody Rungego-Kutty do rozwiązywania równań różniczkowych.\n\nMetoda Rungego-Kutty (RK)\nMetody Rungego-Kutty służą do numerycznego rozwiązywania równań różniczkowych postaci \\(y' = f(t, y)\\) z warunkiem początkowym \\(y(t_0) = y_0\\). Idea polega na zastąpieniu prostego przybliżenia z metody Eulera (używającej nachylenia tylko na początku kroku) przez ważoną średnią nachyleń obliczonych w kilku punktach wewnątrz kroku czasowego \\(h\\). Daje to znacznie dokładniejszą aproksymację.\n\n\nPorównanie metod RK 1., 2. i 4. rzędu\n\n1. Metoda 1. rzędu (RK1) – Metoda Eulera\nTo najprostsza forma, stanowiąca punkt odniesienia.\n\nIdea: Ekstrapolacja rozwiązania na podstawie nachylenia w punkcie początkowym kroku.\nWzór: \\[ y_{n+1} = y_n + h \\cdot f(t_n, y_n) \\]\n\n\n\n2. Metoda 2. rzędu (RK2) – np. Metoda Heuna\nZnaczne ulepszenie w stosunku do metody Eulera przy niewielkim dodatkowym koszcie.\n\nIdea: Uśrednienie nachylenia z początku i (oszacowanego) końca kroku.\nWzór:\n\n\\(k_1 = f(t_n, y_n)\\) (nachylenie na początku)\n\\(k_2 = f(t_n + h, y_n + h \\cdot k_1)\\) (nachylenie na końcu, oszacowane metodą Eulera)\n\\(y_{n+1} = y_n + h \\cdot \\frac{k_1 + k_2}{2}\\) (użycie średniego nachylenia)\n\n\n\n\n3. Metoda 4. rzędu (RK4) – Klasyczna metoda Rungego-Kutty\nNajpopularniejsza metoda, oferująca doskonały kompromis między dokładnością a kosztem obliczeniowym.\n\nIdea: Obliczenie ważonej średniej nachyleń z początku, dwóch punktów w środku i końca kroku. Wagi są dobrane tak, by zmaksymalizować dokładność.\nWzór:\n\n\\(k_1 = f(t_n, y_n)\\)\n\\(k_2 = f(t_n + \\frac{h}{2}, y_n + h \\frac{k_1}{2})\\)\n\\(k_3 = f(t_n + \\frac{h}{2}, y_n + h \\frac{k_2}{2})\\)\n\\(k_4 = f(t_n + h, y_n + h k_3)\\)\n\\(y_{n+1} = y_n + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)\\)\n\n\n\n\n\nJak wyznaczane są parametry metody?\nParametry (współczynniki wagowe i punkty pośrednie) nie są przypadkowe. Wyznacza się je poprzez porównanie rozwinięcia w szereg Taylora numerycznej formuły metody z rozwinięciem w szereg Taylora dokładnego rozwiązania \\(y(t_n+h)\\).\nAlgorytm wyznaczania parametrów:\n\nZapisz dokładne rozwiązanie w postaci szeregu Taylora wokół punktu \\(t_n\\) do rzędu \\(p\\): \\(y(t_n+h) = y_n + h \\cdot y'(t_n) + \\frac{h^2}{2} y''(t_n) + \\dots + \\frac{h^p}{p!} y^{(p)}(t_n) + O(h^{p+1})\\)\nWyraź pochodne \\(y', y'', \\dots\\) za pomocą funkcji \\(f(t,y)\\) i jej pochodnych cząstkowych (np. \\(y' = f\\), \\(y'' = \\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial y} f\\), itd.).\nRozwiń wzór numeryczny metody RK (z niewiadomymi parametrami) również w szereg Taylora względem potęg kroku \\(h\\).\nPorównaj współczynniki przy tych samych potęgach \\(h\\) (\\(h^1, h^2, \\dots, h^p\\)) w obu rozwinięciach.\nRozwiąż powstały układ równań (zazwyczaj nieliniowych) na nieznane parametry. Co ciekawe, dla rzędów wyższych niż 1, układ ten ma często więcej niewiadomych niż równań, co prowadzi do istnienia całych rodzin metod RK tego samego rzędu (np. istnieje wiele różnych metod RK2).\n\n\n\nRząd metody a dokładność obliczeń\nRząd metody (\\(p\\)) jest kluczowym wskaźnikiem jej dokładności. Określa on, jak szybko maleje globalny błąd obliczeń wraz ze zmniejszaniem kroku \\(h\\). Zależność ta jest następująca:\nGlobalny błąd \\(\\approx C \\cdot h^p\\)\ngdzie \\(C\\) to stała zależna od problemu.\n\nRK1 (rząd 1): Błąd jest proporcjonalny do \\(h\\). Dwukrotne zmniejszenie kroku zmniejsza błąd dwukrotnie. Jest to bardzo wolna zbieżność.\nRK2 (rząd 2): Błąd jest proporcjonalny do \\(h^2\\). Dwukrotne zmniejszenie kroku zmniejsza błąd czterokrotnie.\nRK4 (rząd 4): Błąd jest proporcjonalny do \\(h^4\\). Dwukrotne zmniejszenie kroku zmniejsza błąd aż szesnastokrotnie!\n\nWniosek: Metoda RK4 pozwala osiągnąć bardzo wysoką dokładność przy znacznie większym kroku \\(h\\) w porównaniu do metod niższych rzędów, co czyni ją niezwykle wydajną i popularną w praktycznych zastosowaniach.\n\n\n\n3. Generatory liczb pseudolosowych i ich zastosowanie do obliczania całek oznaczonych metodą Monte-Carlo.\nDlaczego generatory liczb pseudolosowych? Ponieważ znając algorytm oraz ziarno generatora jesteśmy w stanie przewidzieć kolejne elementy ciągu - brak w tym losowości\nGeneratory możemy podzielić na:\n\nLiniowe\n\nLinowy generator kongruentny \\[\nx_{n+1} = (ax_n+b)(\\text{mod} m)  \n\\]\nGenerator Fibbonacciego \\[\nx_n = (x_{n-l} + n_{n-k})(\\text{mod} m)\n\\]\n\nNieliniowe\n\nCharakteryzują się bardzo długim okresem i dobrą równomiernością rozkładu liczb. Oparte na bardziej złożonych zależnościach, np. Mersenne Twister"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#podstawy-teorii-sterowania",
    "href": "posts/10-08-2025-first-post/index.html#podstawy-teorii-sterowania",
    "title": "My Post",
    "section": "6. Podstawy teorii sterowania",
    "text": "6. Podstawy teorii sterowania\n\n1. Sposoby tworzenia modeli matematycznych obiektów lub procesów sterowania. Identyfikacja procesu sterowania.\n\n\n2. Charakterystyka statyczna i charakterystyka dynamiczna procesu. Przykłady obu charakterystyk dla wybranego procesu.\n\n\n3. Metody ograniczania skutków niepożądanego oddziaływania na proces."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#systemy-obsługi-masowej",
    "href": "posts/10-08-2025-first-post/index.html#systemy-obsługi-masowej",
    "title": "My Post",
    "section": "7. Systemy obsługi masowej",
    "text": "7. Systemy obsługi masowej\n\n1. Korzystając z oznaczenia Kendalla podać charakterystykę systemu M/D/n/m.\n\nCharakterystyka systemu M/D/n/m:\n\nM - czas przybycia klientów jest rozkładem wykładniczym;\nD - czas trwania obsługi jest opisany rozkładem deterministycznym (stałym);\nn - liczba liczba serwerów równoległych\nm - maksymalna liczba osób w systemie (w kolejce (poczekalni) i w obsłudze).\n\n\n\n2. Korzystając z formuł Littla opisz zależność pomiędzy oczekiwaną liczbą klientów w systemie a średnim czasem spędzonym w systemie.\n\n\n\n3. Różnice w oszacowaniu własności systemów obsługi ze względu na sposób połączenia serwerów\nAnaliza systemów kolejkowych wymaga zrozumienia, jak architektura połączeń między serwerami wpływa na kluczowe metryki wydajności, takie jak czas oczekiwania czy wykorzystanie zasobów. Poniżej przedstawiono trzy fundamentalne modele połączeń i metody ich analizy.\n\nSerwery połączone równolegle z jedną, wspólną kolejką.\nSerwery połączone równolegle z oddzielnymi kolejkami dla każdego serwera.\nSerwery połączone szeregowo (kaskadowo).\n\n\n\n1. Serwery Równoległe z Jedną Wspólną Kolejką (Model M/M/c)\nJest to najczęściej spotykany i zazwyczaj najwydajniejszy model obsługi w miejscach takich jak banki (jedna kolejka do wielu okienek), infolinie czy lotniska (jedna kolejka do kontroli bezpieczeństwa).\nOpis:\n\nKlienci (zgłoszenia) wchodzą do jednej, wspólnej kolejki.\nGdy dowolny z \\(c\\) serwerów staje się wolny, pierwszy klient z kolejki jest kierowany do jego obsługi.\nSystem jest opisywany w notacji Kendalla jako M/M/c.\n\n\nWłaściwości i sposób oszacowania:\n\nWydajność i równoważenie obciążenia: System jest wysoce wydajny. Żaden serwer nie jest bezczynny, jeśli w kolejce czeka choćby jedno zgłoszenie. Obciążenie jest automatycznie i idealnie zrównoważone między wszystkimi serwerami.\nZłożoność analizy: Analiza matematyczna jest bardziej złożona niż dla pojedynczego serwera. Wykorzystuje się wzory Erlanga-C, które pozwalają obliczyć kluczowe metryki:\n\nPrawdopodobieństwo, że system jest pusty (\\(P_0\\)): Wymaga obliczenia sumy szeregu.\nPrawdopodobieństwo oczekiwania w kolejce (\\(P_w\\)): Znane jako wzór C Erlanga, zależy od \\(P_0\\), liczby serwerów \\(c\\) i współczynnika wykorzystania systemu \\(\\rho\\).\nŚrednia liczba klientów w kolejce (\\(L_q\\)): \\(L_q = P_w \\cdot \\frac{\\rho}{1 - \\rho}\\)\nŚredni czas oczekiwania w kolejce (\\(W_q\\)): \\(W_q = L_q / \\lambda\\) (gdzie \\(\\lambda\\) to średnie natężenie zgłoszeń).\nŚredni czas pobytu w systemie (\\(W\\)): \\(W = W_q + 1/\\mu\\) (gdzie \\(\\mu\\) to średnie tempo obsługi jednego serwera).\n\nKluczowa metryka: Współczynnik wykorzystania systemu \\(\\rho = \\lambda / (c \\cdot \\mu)\\). Warunkiem stabilności systemu jest \\(\\rho &lt; 1\\).\n\nPodsumowując: Ten model minimalizuje średni czas oczekiwania klienta, ponieważ zasoby (serwery) są wykorzystywane w sposób optymalny.\n\n\n\n2. Serwery Równoległe z Oddzielnymi Kolejkami (Model \\(c \\times\\) M/M/1)\nTen model jest typowy dla supermarketów z wieloma kasami, gdzie każda kasa ma swoją własną kolejkę.\nOpis:\n\nIstnieje \\(c\\) niezależnych kolejek, po jednej dla każdego z \\(c\\) serwerów.\nKlient po przybyciu wybiera jedną z kolejek (np. najkrótszą) i pozostaje w niej.\n\n\nWłaściwości i sposób oszacowania:\n\nWydajność i równoważenie obciążenia: System ten jest z natury mniej wydajny niż system z jedną kolejką. Może wystąpić sytuacja, w której jeden serwer jest bezczynny (jego kolejka jest pusta), podczas gdy w innych kolejkach klienci oczekują na obsługę. Równoważenie obciążenia jest niedoskonałe i zależy od decyzji klientów.\nZłożoność analizy: Analiza jest znacznie prostsza, ponieważ system można traktować jako $c$ niezależnych systemów M/M/1.\n\nZakładając, że strumień wejściowy \\(\\lambda\\) jest równomiernie rozłożony na \\(c\\) kolejek, każda z nich otrzymuje strumień zgłoszeń o natężeniu \\(\\lambda_i = \\lambda / c\\).\nDla każdej z tych kolejek stosuje się proste wzory dla systemu M/M/1:\n\nWspółczynnik wykorzystania pojedynczego serwera: \\(\\rho_i = \\lambda_i / \\mu = (\\lambda / c) / \\mu = \\rho\\).\nŚrednia liczba klientów w i-tej kolejce: \\(L_{q_i} = \\frac{\\rho_i^2}{1 - \\rho_i}\\).\nŚredni czas oczekiwania w i-tej kolejce: \\(W_{q_i} = L_{q_i} / \\lambda_i\\).\n\nCałkowite właściwości systemu uzyskuje się poprzez uśrednienie wyników z poszczególnych kolejek.\n\nZjawisko “Jockeying”: W praktyce klienci mogą zmieniać kolejki, jeśli widzą, że inna porusza się szybciej. To zjawisko komplikuje analizę i zbliża właściwości systemu do modelu z jedną wspólną kolejką, ale rzadko jest uwzględniane w podstawowych modelach analitycznych.\n\nPodsumowując: Choć prostszy w analizie, ten model prowadzi do dłuższego średniego czasu oczekiwania i mniejszej efektywności wykorzystania serwerów w porównaniu do modelu ze wspólną kolejką.\n\n\n\n3. Serwery Połączone Szeregowo (Systemy Tandemowe)\nModel ten opisuje procesy wieloetapowe, takie jak linia produkcyjna, proces składania zamówienia w restauracji (zamówienie -&gt; płatność -&gt; odbiór) czy przetwarzanie danych w potoku.\nOpis:\n\nSystem składa się z sekwencji serwerów (stacji).\nWyjście z jednego serwera staje się wejściem do kolejnego.\nMiędzy serwerami mogą znajdować się bufory (kolejki) o skończonej lub nieskończonej pojemności.\n\n\nWłaściwości i sposób oszacowania:\n\nZłożoność analizy: Sposób oszacowania silnie zależy od założeń dotyczących buforów i rozkładów czasów obsługi.\n\nPrzypadek prosty (Twierdzenie Burke’a): Jeśli każdy etap to system M/M/1 z nieskończonym buforem, to wyjściowy strumień zgłoszeń z każdego etapu jest również procesem Poissona o tym samym natężeniu $\\lambda$. Dzięki temu cały system można analizować jako serię niezależnych systemów M/M/1.\n\nŚredni czas pobytu w całym systemie (\\(W_{\\text{total}}\\)) jest po prostu sumą średnich czasów pobytu na każdym etapie: \\(W_{\\text{total}} = W_1 + W_2 + \\dots + W_c\\).\nŚrednia liczba klientów w systemie (\\(L_{\\text{total}}\\)) to suma średnich liczb klientów na każdym etapie: \\(L_{\\text{total}} = L_1 + L_2 + \\dots + L_c\\).\n\nPrzypadek złożony (Skończone bufory): Jest to sytuacja znacznie bardziej realistyczna i trudniejsza analitycznie.\n\nZjawisko blokowania: Jeśli bufor między serwerem $i$ a $i+1$ jest pełny, serwer $i$ po zakończeniu obsługi musi czekać (jest blokowany), aż zwolni się miejsce w buforze. To drastycznie obniża przepustowość całego systemu.\nWąskie gardło (Bottleneck): Przepustowość całego systemu jest ograniczona przez najwolniejszy etap (serwer o najniższym tempie obsługi $\\mu$). Ten etap nazywany jest “wąskim gardłem”.\nMetody analizy: Dokładne rozwiązania analityczne są rzadkie. Do oszacowania właściwości takich systemów najczęściej wykorzystuje się symulacje komputerowe lub metody aproksymacyjne.\n\n\n\nPodsumowując: Kluczowe dla analizy systemów szeregowych jest zjawisko blokowania i identyfikacja wąskiego gardła. Wydajność całego łańcucha jest determinowana przez jego najsłabsze ogniwo.\n\n\n\nTabela Porównawcza\n\n\n\n\n\n\n\n\n\nCecha\nSystem Równoległy - Jedna Kolejka (M/M/c)\nSystem Równoległy - Oddzielne Kolejki (c x M/M/1)\nSystem Szeregowy (Tandem)\n\n\n\n\nOpis\nJedna kolejka do wielu serwerów\nWiele kolejek, po jednej na serwer\nSekwencja serwerów, jeden po drugim\n\n\nWydajność\nNajwyższa\nNiższa (ryzyko bezczynności serwerów)\nOgraniczona przez “wąskie gardło”\n\n\nRównoważenie obciążenia\nIdealne, automatyczne\nNiedoskonałe, zależne od wyboru klienta\nNie dotyczy (każde zadanie przechodzi przez każdy serwer)\n\n\nZłożoność Analizy\nUmiarkowana (wzory Erlanga-C)\nNiska (analiza niezależnych systemów M/M/1)\nBardzo wysoka (zwłaszcza przy skończonych buforach)\n\n\nKluczowe Zjawisko\nEfektywność współdzielenia zasobów\nNiewydajność i możliwość “jockeyingu”\nBlokowanie i “wąskie gardło”\n\n\nTypowy Przykład\nObsługa w banku, infolinia\nKasy w supermarkecie\nLinia produkcyjna, myjnia samochodowa"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#multimedialne-metody-opracowywania-danych",
    "href": "posts/10-08-2025-first-post/index.html#multimedialne-metody-opracowywania-danych",
    "title": "My Post",
    "section": "8. Multimedialne metody opracowywania danych",
    "text": "8. Multimedialne metody opracowywania danych\n\n1. Mechanizm działania algorytmu najczęściej używanego do kompresji wideo.\n\n\n2. Pojęcie „przetwarzania obrazów cyfrowych”. Zasady postępowania.\n\nPozyskanie (akwizycja) obrazu i przetworzenie do postaci cyfrowej;\nWstępne przetworzenie obrazu, jego filtracja i wyostrzanie, a także jego binaryzacja;\nSegmentacja obrazu i wydzielenie poszczególnych obiektów oraz ich fragmentów (np. krawędzi i innych linii);\nAnaliza obrazu i wyznaczenie cech obiektów oraz informacji o ich lokalizacji;\nRozpoznanie i rozumienie obrazu (identyfikacja klasy).\n\n\n\n3. Formaty plików obrazów bez kompresji stratnej i ich charakterystyka.\n\nPNG (Portable Network Graphics):\n\nLepsza kompresja niż BMP/TIFF przy zachowaniu jakości,\nObsługa przezroczystości (kanał alfa).\n\nGIF\n\nObsługuje animacje,\nOgraniczona paleta kolorów - 256 kolorów (8 bitów),\n\nTIFF (Tagged Image File Format):\n\nWysoka jakość obrazu,\nObsługuje różne metody kompresji, w tym bezstratną (LZW) i stratną (JPEG).\nObsługuje bardzo wysoką jakość obrazu i głębię bitową (np. 16 bitów na kanał).\nObsługuje warstwy, kanały alfa i metadane.\n\nBMP (Bitmap, Windows Bitmap):\n\nProsty format bez kompresji,\nDuże rozmiary plików,\nObsługuje różne głębie kolorów (1, 4, 8, 16, 24, 32 bity)."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#zaawansowane-metody-probabilistyczne",
    "href": "posts/10-08-2025-first-post/index.html#zaawansowane-metody-probabilistyczne",
    "title": "My Post",
    "section": "9. Zaawansowane metody probabilistyczne",
    "text": "9. Zaawansowane metody probabilistyczne\n\n1. Proces Poissona – definicja, konstrukcja i zastosowania.\n\n\n\n\n\n\nDefinicja (Proces Poissona)\n\n\n\nRodzinę mierzalnych zmiennych losowych \\(\\{Z_t, t \\geq 0\\}\\) określonych na przestrzeni probabilistycznej \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) nazywamy procesem Poissona o intensywności \\(\\alpha &gt; 0\\), gdy spełnione są warunki:\n\n\\(\\mathbb{P}[Z_0 = 0] = 1\\)\nDla dowolnego układu \\(0 \\leq t_0 &lt; t_1 &lt; \\dots &lt; t_n\\) zmienne losowe\n\\[\nZ_{t_1} - Z_{t_0},\\; Z_{t_2} - Z_{t_1},\\; \\dots,\\; Z_{t_n} - Z_{t_{n-1}}\n\\]\nsą stochastycznie niezależne.\nDla dowolnych \\(0 \\leq s &lt; t\\) zmienna losowa \\(Z_t - Z_s\\) ma rozkład Poissona z parametrem \\(\\alpha (t-s)\\), tzn.\n\\[\n\\mathbb{P}[Z_t - Z_s = i] \\;=\\; \\frac{(\\alpha (t-s))^i}{i!} e^{-\\alpha (t-s)}, \\quad i = 0,1,2,\\dots\n\\]\n\n\n\n\n\n2.Proces urodzin i śmierci – definicja i przykłady zastosowania.\n\n\n\n\n\n\nDefinicja (Proces urodzin i śmierci)\n\n\n\nProces stochastyczny \\(\\{Z_t, t \\geq 0\\}\\) o wartościach w \\(\\mathbb{N}_0\\) nazywamy procesem urodzin i śmierci, jeżeli:\n\njest łańcuchem Markowa,\nistnieją stałe dodatnie \\(\\{\\lambda_n\\}_{n \\geq 0}\\) (intensywności urodzin) oraz \\(\\{\\mu_n\\}_{n \\geq 1}\\) (intensywności śmierci), dla których spełnione są równania:\n\n\\[\n\\begin{aligned}\nP_{n,n+1}'(t) &= \\lambda_n P_{n}(t), \\\\\nP_{n,n}'(t) &= -(\\lambda_n + \\mu_n) P_{n}(t), \\\\\nP_{n,n-1}'(t) &= \\mu_n P_{n}(t),\n\\end{aligned}\n\\]\ngdzie \\(P_n(t) = \\Pr(Z_t = n)\\).\n\n\nMacierz intensywności\nMacierz \\(Q = (q_{ij})\\) nazywamy macierzą intensywności procesu urodzin i śmierci (lub generatorem procesów Markowa w czasie ciągłym). Ma ona postać:\n\\[\nQ =\n\\begin{bmatrix}\n-\\lambda_0 & \\lambda_0 & 0 & 0 & 0 & \\cdots \\\\\n\\mu_1 & -(\\mu_1 + \\lambda_1) & \\lambda_1 & 0 & 0 & \\cdots \\\\\n0 & \\mu_2 & -(\\mu_2 + \\lambda_2) & \\lambda_2 & 0 & \\cdots \\\\\n0 & 0 & \\mu_3 & -(\\mu_3 + \\lambda_3) & \\lambda_3 & \\cdots \\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots\n\\end{bmatrix}\n\\]\n\n\n\nOznaczenia\n\n\\(\\lambda_n\\) – intensywność urodzin w stanie \\(n\\),\n\n\\(\\mu_n\\) – intensywność śmierci w stanie \\(n\\).\n\n\n\n\n\n\nZastosowania:\n\nproblemy czasu oczekiwania,\nproblemy związane z liniami telefonicznymi,\nproces obsługi klientów,\nproces odnowy.\n\n\n\n\n\n3. Twierdzenie ergodyczne i przykłady jego zastosowania.\n\nTwierdzenie o ergodyczności łańcucha Markowa\n\n\n\n\n\n\nDefinicja\n\n\n\nJednorodny łańcuch Markowa \\(\\{Z_n, n \\in \\mathbb{N}_0\\}\\) jest ergodyczny,\njeśli dla każdego \\(j \\in S\\) istnieją i nie zależą od \\(i \\in S\\) granice:\n\\[\nq_j = \\lim_{n \\to \\infty} p_{ij}^{(n)} &gt; 0,\n\\]\noraz\n\\[\n\\sum_{j \\in S} q_j = 1.\n\\]\n\n\n\n\n\nRozkład graniczny\n\n\n\n\n\n\nTip\n\n\n\nDefinicja:\nWektor \\(q = (q_j, \\, j \\in S)\\) nazywamy rozkładem ergodycznym.\n\n\n\n\n\nTwierdzenie\nJeśli łańcuch Markowa \\(\\{Z_n, n \\in \\mathbb{N}_0\\}\\) jest ergodyczny,\nto macierz przejścia w \\(n\\)-tym kroku spełnia:\n\\[\nP^{(n)} \\xrightarrow[n \\to \\infty]{}\n\\begin{bmatrix}\nq_1 & q_2 & q_3 & \\cdots \\\\\nq_1 & q_2 & q_3 & \\cdots \\\\\nq_1 & q_2 & q_3 & \\cdots \\\\\n\\vdots & \\vdots & \\vdots & \\ddots\n\\end{bmatrix}\n\\]\nczyli każdy wiersz macierzy granicznej jest identyczny i równy rozkładowi ergodycznemu \\(q\\).\n\n\n\nUwaga\n\nWektor \\(q\\) jest jedynym rozkładem stacjonarnym łańcucha.\n\nRozkład graniczny opisuje zachowanie procesu w nieskończoności, niezależnie od stanu początkowego."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#stochastyczne-równania-różniczkowe",
    "href": "posts/10-08-2025-first-post/index.html#stochastyczne-równania-różniczkowe",
    "title": "My Post",
    "section": "10. Stochastyczne równania różniczkowe",
    "text": "10. Stochastyczne równania różniczkowe\n\n1. Całki stochastyczne: ich rodzaje i definicje.\n\n\n2. Różniczka stochastyczna Itô, wzór Itô."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#podstawy-analizy-danych-finansowych",
    "href": "posts/10-08-2025-first-post/index.html#podstawy-analizy-danych-finansowych",
    "title": "My Post",
    "section": "11. Podstawy analizy danych finansowych",
    "text": "11. Podstawy analizy danych finansowych\n\n1. Nominalna i efektywna stopa procentowa oraz twierdzenie charakteryzujące relacje między nimi.\nOczywiście, wyjaśnijmy te fundamentalne pojęcia analizy finansowej w prosty i zrozumiały sposób.\n\n\nWprowadzenie\nW świecie finansów rzadko kiedy sprawy są tak proste, jak się na pierwszy rzut oka wydaje. Dotyczy to zwłaszcza oprocentowania. Kiedy bank reklamuje lokatę lub kredyt, podaje tzw. nominalną stopę procentową. Jednak to, ile faktycznie zarobisz lub zapłacisz, zależy od efektywnej stopy procentowej. Zrozumienie różnicy między nimi jest kluczowe do podejmowania świadomych decyzji finansowych.\n\n\n\n1. Nominalna Stopa Procentowa (r_nom)\nNominalna stopa procentowa, często oznaczana jako stopa nominalna w skali roku (np. 8% p.a. - per annum), to podstawowa, “reklamowana” wartość oprocentowania.\nKluczowe cechy:\n\nJest to stopa deklarowana: Służy jako punkt wyjścia do obliczeń.\nNie uwzględnia częstotliwości kapitalizacji: Sama w sobie nie mówi, jak często odsetki są doliczane do kapitału. Dlatego informacja o stopie nominalnej jest niekompletna bez podania okresu kapitalizacji (np. roczna, kwartalna, miesięczna).\nJest użyteczna do prostych obliczeń: Jeśli kapitalizacja jest roczna, to stopa nominalna jest równa stopie efektywnej.\n\nAnalogia: Pomyśl o niej jak o cenie na metce produktu, która nie uwzględnia ewentualnych dodatkowych opłat czy podatków. To cena wyjściowa, a nie ostateczny koszt.\nPrzykład: Bank oferuje lokatę na 10% w skali roku. To jest właśnie nominalna stopa procentowa.\n\n\n\n2. Efektywna Stopa Procentowa (r_eff)\nEfektywna stopa procentowa to rzeczywista stopa zwrotu z inwestycji lub realny koszt kredytu po uwzględnieniu efektu procentu składanego (czyli doliczania odsetek do kapitału w ciągu roku).\nKluczowe cechy:\n\nOdzwierciedla realny zysk/koszt: Uwzględnia, że odsetki naliczone w jednym okresie (np. w jednym miesiącu) same zaczynają zarabiać w kolejnych okresach.\nJest narzędziem do porównywania ofert: To jedyny miarodajny wskaźnik, który pozwala porównać różne produkty finansowe, nawet jeśli mają różną nominalną stopę procentową i różną częstotliwość kapitalizacji.\nJest zawsze równa lub wyższa od stopy nominalnej (przy kapitalizacji rocznej są równe; im częstsza kapitalizacja, tym większa różnica).\n\nAnalogia: Wracając do poprzedniej analogii, efektywna stopa procentowa to ostateczna, całkowita cena, którą płacisz za produkt po doliczeniu wszystkich dodatkowych kosztów.\nPrzykład: Masz 1000 zł na lokacie z nominalnym oprocentowaniem 12% w skali roku.\n\nScenariusz A: Kapitalizacja roczna Po roku otrzymasz: 1000 zł * 12% = 120 zł odsetek. Stan konta: 1120 zł. Efektywna stopa procentowa = 12%.\nScenariusz B: Kapitalizacja kwartalna Nominalna stopa 12% rocznie oznacza 12% / 4 = 3% na kwartał.\n\nPo I kwartale: 1000 zł * 1,03 = 1030 zł\nPo II kwartale: 1030 zł * 1,03 = 1060,90 zł (odsetki naliczone od 1030 zł, a nie 1000 zł!)\nPo III kwartale: 1060,90 zł * 1,03 = 1092,73 zł\nPo IV kwartale: 1092,73 zł * 1,03 ≈ 1125,51 zł\n\nCałkowity zysk to 125,51 zł. Efektywna stopa procentowa = (125,51 zł / 1000 zł) * 100% = 12,55%.\n\nJak widać, mimo tej samej stopy nominalnej (12%), częstsza kapitalizacja sprawiła, że realny zysk był wyższy.\n\n\n\n3. Twierdzenie Charakteryzujące Relacje Między Nimi (Wzór)\nRelację między nominalną a efektywną stopą procentową opisuje precyzyjny wzór matematyczny.\nWzór:\n\n\n\nr_{eff} = (1 + )^m - 1\n\n\n\nGdzie:\n\nr_eff – efektywna roczna stopa procentowa (ang. Effective Interest Rate)\nr_nom – nominalna roczna stopa procentowa (ang. Nominal Interest Rate)\nm – liczba okresów kapitalizacji w ciągu roku\n\nWartości m dla różnych okresów kapitalizacji:\n\nRoczna: m = 1\nPółroczna: m = 2\nKwartalna: m = 4\nMiesięczna: m = 12\nTygodniowa: m = 52\nDzienna: m = 365\n\n\nZastosowanie wzoru na poprzednim przykładzie: Dane: * r_nom = 12% = 0,12 * m = 4 (kapitalizacja kwartalna)\nObliczenia: - r_eff = (1 + 0,12 / 4)^4 - 1 - r_eff = (1 + 0,03)^4 - 1 - r_eff = (1,03)^4 - 1 - r_eff ≈ 1,1255088 - 1 - r_eff ≈ 0,1255 - r_eff ≈ 12,55%\nWynik jest identyczny z tym, który uzyskaliśmy, licząc “krok po kroku”.\n\n\n\nPodsumowanie i Praktyczne Zastosowanie\n\n\n\n\n\n\n\n\nCecha\nNominalna Stopa Procentowa\nEfektywna Stopa Procentowa\n\n\n\n\nDefinicja\nDeklarowana, “reklamowa” stopa roczna.\nRzeczywista stopa zwrotu lub kosztu.\n\n\nCo uwzględnia?\nTylko wartość bazową oprocentowania.\nWartość bazową oraz efekt procentu składanego.\n\n\nKiedy używać?\nJako punkt wyjścia do obliczeń.\nDo porównywania różnych ofert finansowych.\n\n\nRelacja\nr_nom ≤ r_eff\nr_eff ≥ r_nom\n\n\n\nZłota zasada: Zawsze, gdy porównujesz dwie lokaty lub dwa kredyty, patrz na efektywną stopę procentową (lub jej odpowiednik, np. RRSO – Rzeczywistą Roczną Stopę Oprocentowania w przypadku kredytów). Tylko ona powie Ci, która oferta jest naprawdę korzystniejsza.\nPrzykład: * Kredyt A: 10% nominalnie, kapitalizacja miesięczna. * Kredyt B: 10,1% nominalnie, kapitalizacja półroczna.\nNa pierwszy rzut oka Kredyt A wydaje się tańszy. Obliczmy efektywne stopy: * Kredyt A (r_eff): (1 + 0,10 / 12)¹² - 1 ≈ 10,47% * Kredyt B (r_eff): (1 + 0,101 / 2)² - 1 ≈ 10,36%\nOkazuje się, że Kredyt B, mimo wyższej stopy nominalnej, jest w rzeczywistości tańszy, ponieważ odsetki są doliczane rzadziej.\n\n\n2. Pojęcie renty oraz główne rodzaje rent – ich wartości obecne, wartości przyszłe i przykłady zastosowań.\n\nRenty\nRenta to ciąg płatności (rat) dokonywanych w równych odstępach czasu.\n\n\nRenta odroczona (płatna z dołu)\n\n\\[\nPV = R \\cdot \\frac{1 - (1+i)^{-n}}{i},\n\\qquad\nFV = R \\cdot \\frac{(1+i)^n - 1}{i}\n\\]\n\n\nRenta płatna z góry\n\n\\[\nPV = R \\cdot \\frac{1 - (1+i)^{-n}}{i} \\cdot (1+i),\n\\qquad\nFV = R \\cdot \\frac{(1+i)^n - 1}{i} \\cdot (1+i)\n\\]\n\n\nRenta o ratach tworzących ciąg arytmetyczny\n\n\\[\nR_k = R_1 + (k-1)d\n\\]\n\\[\nPV = \\sum_{k=1}^{n} \\frac{R_1 + (k-1)d}{(1+i)^k},\n\\qquad\nFV = \\sum_{k=1}^{n} (R_1 + (k-1)d) \\cdot (1+i)^{\\,n-k}\n\\]\n\n\nRenta o ratach tworzących ciąg geometryczny\n\n\\[\nR_k = R_1 \\cdot q^{k-1}\n\\]\n\\[\nPV = \\sum_{k=1}^{n} \\frac{R_1 \\cdot q^{k-1}}{(1+i)^k},\n\\qquad\nFV = \\sum_{k=1}^{n} R_1 \\cdot q^{k-1} \\cdot (1+i)^{\\,n-k}\n\\]\n\n\nRenty ciągłe\n\n\\[\nPV = \\int_{0}^{n} R \\cdot e^{-i t} \\, dt\n    = \\frac{R}{i} \\left(1 - e^{-i n}\\right)\n\\]\n\\[\nFV = \\int_{0}^{n} R \\cdot e^{i (n-t)} \\, dt\n    = \\frac{R}{i} \\left(e^{i n} - 1\\right)\n\\]\n\n\n\n3. Procesy akumulacji i dyskontowania oraz ich rodzaje.\n\n\n\nProces\nRodzaj\nWzór matematyczny\n\n\n\n\nAkumulacja\nProsta\n\\(K(t)= K \\cdot (1 + i \\cdot t)\\)\n\n\n\nZłożona\n\\(K(t) = K \\cdot (1+i)^t\\)\n\n\n\nCiągła\n\\(K(t) = K \\cdot e^{i \\cdot t}\\)\n\n\nDyskontowanie\nProste\n\\(PV = \\frac{FV}{1 + i \\cdot t}\\)\n\n\n\nZłożone\n\\(PV = \\frac{FV}{(1+i)^t}\\)\n\n\n\nCiągłe\n\\(PV = FV \\cdot e^{-i \\cdot t}\\)\n\n\n\n\nAkumulacja:\n\nProsta: Opiera się na idei ciągu arytmetycznego. Odsetki dopisujemy po upływie okresu bazowego. Każdy okres daje nam taką samą wartość odsetek.\nZłożona: opiera się na idei ciągu geometrycznego – odsetki są doliczane do kapitału i w kolejnych okresach również pracują, dlatego kapitał rośnie szybciej niż w przypadku odsetek prostych.\nCiągła: zakładamy, że kapitalizacja następuje w nieskończenie wielu małych krokach, co prowadzi do użycia funkcji wykładniczej. To model najbardziej “teoretyczny”, ale użyteczny np. w analizach rynkowych.\n\nDyskontowanie: proces odwrotny do akumulacji (liczymy wartość bieżącą z wartości przyszłej).\n\nProste: zakładamy, że odsetki są odejmowane liniowo (tak jak w akumulacji prostej). Każdy kolejny okres obniża wartość przyszłą o taką samą “porcję” czasu\nZłożone: tu również działa mechanizm kapitalizacji odsetek składanych, tylko w odwrotną stronę – sprowadzamy przyszłą wartość poprzez dzielenie przez kolejne potęgi czynnika \\((1+i)\\).\nCiągłe: To podejście często używane w finansach matematycznych (np. przy wycenie obligacji i instrumentów pochodnych)."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#inżynieria-ubezpieczeń-majątkowych",
    "href": "posts/10-08-2025-first-post/index.html#inżynieria-ubezpieczeń-majątkowych",
    "title": "My Post",
    "section": "12. Inżynieria ubezpieczeń majątkowych",
    "text": "12. Inżynieria ubezpieczeń majątkowych\n\n1. Modele ryzyka stosowane w ubezpieczeniach majątkowych\nW teorii ubezpieczeń majątkowych do opisu i kwantyfikacji ryzyka portfela stosuje się dwa fundamentalne modele: model ryzyka indywidualnego oraz model ryzyka łącznego (kolektywnego).\n\nModel Ryzyka Indywidualnego\nModel ten koncentruje się na pojedynczych polisach w portfelu. Całkowita strata portfela (\\(S\\)) jest modelowana jako suma strat (\\(X_i\\)) z poszczególnych, niezależnych ryzyk (polis).\n\nDefinicja: \\[S = X_1 + X_2 + \\dots + X_n\\] gdzie:\n\n\\(n\\) jest ustaloną (nielosową) liczbą ryzyk w portfelu.\n\\(X_i\\) to zmienna losowa opisująca wysokość szkody z \\(i\\)-tej polisy.\n\nZałożenia:\n\nRyzyka (zmienne losowe \\(X_i\\)) są statystycznie niezależne.\nW okresie ubezpieczenia dla każdego ryzyka szkoda może wystąpić co najwyżej raz.\n\nZastosowanie: Model ten jest użyteczny do analizy jednorodnych portfeli. Jednak ze względu na złożoność obliczeniową (wymaga tzw. splotów rozkładów prawdopodobieństwa) jest mniej praktyczny dla dużych i zróżnicowanych portfeli ubezpieczeń majątkowych.\n\n\n\nModel Ryzyka Łącznego (Kolektywnego)\nModel ten traktuje portfel jako całość – jako proces, który w danym okresie generuje pewną liczbę szkód o różnej wysokości. Zamiast sumować straty po polisach, modeluje się zagregowaną (łączną) wartość szkód.\n\nDefinicja: \\[X = Y_1 + Y_2 + \\dots + Y_N\\] gdzie:\n\n\\(N\\) jest zmienną losową oznaczającą łączną liczbę szkód w portfelu.\n\\(Y_i\\) to zmienna losowa opisująca wysokość \\(i\\)-tej szkody.\nGdy \\(N=0\\), wtedy \\(X=0\\).\n\nZałożenia:\n\nProces generujący liczbę szkód (\\(N\\)) jest niezależny od wysokości poszczególnych szkód (\\(Y_i\\)).\nWysokości szkód (\\(Y_i\\)) są zmiennymi losowymi o identycznym rozkładzie i są wzajemnie niezależne.\n\nZastosowanie: Jest to dominujący model w ubezpieczeniach majątkowych. Jego siła polega na rozdzieleniu ryzyka na dwa kluczowe komponenty:\n\nCzęstotliwość szkód (modelowana przez rozkład zmiennej \\(N\\)).\nWysokość (dotkliwość) szkód (modelowana przez rozkład zmiennej \\(Y\\)). Rozkład łącznej wartości szkód \\(X\\) nazywany jest rozkładem złożonym.\n\n\n\n\n\n\n2. Podstawowe rozkłady liczby szkód w modelu ryzyka łącznego\nW modelu ryzyka łącznego kluczowym elementem jest właściwe zamodelowanie losowej liczby szkód (\\(N\\)). W praktyce aktuarialnej stosuje się głównie trzy poniższe rozkłady.\n\nRozkład Poissona\nJest to najczęściej stosowany i fundamentalny rozkład dla liczby szkód.\n\nCharakterystyka: Modeluje liczbę zdarzeń (szkód) zachodzących losowo i niezależnie w ustalonym przedziale czasu, przy stałej średniej intensywności (\\(\\lambda\\)).\nWzór: \\[P(N = k) = \\frac{\\lambda^k}{k!} e^{-\\lambda}, \\quad k=0, 1, 2, \\dots\\]\nWłasności w ubezpieczeniach:\n\nRówność wartości oczekiwanej i wariancji: \\(E(N) = \\text{Var}(N) = \\lambda\\).\nWłasność agregacji: Suma niezależnych zmiennych losowych o rozkładach Poissona również ma rozkład Poissona. Ułatwia to łączenie subportfeli.\n\n\n\n\nRozkład ujemny dwumianowy\nJest to uogólnienie rozkładu Poissona, które oferuje większą elastyczność.\n\nCharakterystyka: Stosowany, gdy wariancja liczby szkód jest większa niż jej wartość oczekiwana (zjawisko naddyspersji). Jest to częsta sytuacja w praktyce, gdy ryzyko w portfelu nie jest w pełni jednorodne.\nWłasności w ubezpieczeniach:\n\nWariancja większa od wartości oczekiwanej: \\(\\text{Var}(N) &gt; E(N)\\).\nLepiej dopasowuje się do danych, gdzie szkody występują w sposób bardziej skumulowany lub nieregularny niż w modelu Poissona.\n\n\n\n\nRozkład dwumianowy\nStosowany w bardziej specyficznych sytuacjach, gdy liczba potencjalnych szkód jest z góry ograniczona.\n\nCharakterystyka: Opisuje liczbę szkód w stałej liczbie \\(n\\) niezależnych polis, gdzie prawdopodobieństwo szkody \\(q\\) jest takie samo dla każdej polisy.\nWzór: \\[P(N = k) = \\binom{n}{k} q^k (1-q)^{n-k}, \\quad k=0, 1, \\dots, n\\]\nWłasności w ubezpieczeniach:\n\nWariancja mniejsza od wartości oczekiwanej: \\(\\text{Var}(N) &lt; E(N)\\).\nStosuje się go głównie w zamkniętych, jednorodnych portfelach o znanej liczbie ryzyk.\n\n\n\n\n\n\n\n\nPodsumowanie wyboru rozkładu\n\n\n\nWybór rozkładu zależy od charakterystyki portfela. Rozkład Poissona jest punktem wyjścia, rozkład ujemny dwumianowy jego elastycznym rozszerzeniem dla danych o dużej zmienności, a rozkład dwumianowy ma zastosowanie w specyficznych, ograniczonych przypadkach.\n\n\n\n\n\n\n3. Funkcja generująca momenty i funkcja generująca kumulanty oraz ich zastosowanie\nFunkcja generująca momenty (FGM) i funkcja generująca kumulanty (FGK) to potężne narzędzia matematyczne, które znacząco upraszczają analizę ryzyka w portfelu.\n\nDefinicje\n\nFunkcja Generująca Momenty (FGM): Dla zmiennej losowej \\(X\\), jej FGM jest zdefiniowana jako: \\[M_X(t) = E(e^{tX})\\] Jej \\(k\\)-ta pochodna w punkcie \\(t=0\\) jest równa \\(k\\)-temu momentowi zwykłemu (\\(E(X^k)\\)).\nFunkcja Generująca Kumulanty (FGK): Jest zdefiniowana jako logarytm naturalny z FGM: \\[C_X(t) = \\ln(M_X(t))\\] Jej \\(k\\)-ta pochodna w \\(t=0\\) jest równa \\(k\\)-tej kumulancie (\\(c_k\\)), która jest powiązana z momentami centralnymi (np. \\(c_1 = \\mu\\), \\(c_2 = \\sigma^2\\)).\n\n\n\nZastosowanie w teorii ubezpieczeń\n\nUproszczenie analizy sumy ryzyk: Analiza rozkładu sumy niezależnych ryzyk \\(S = X_1 + \\dots + X_n\\) za pomocą standardowych metod (splotów) jest bardzo skomplikowana. FGM i FGK zamieniają tę operację na proste działania algebraiczne:\n\nFGM sumy to iloczyn FGM składników: \\(M_S(t) = \\prod_{i=1}^n M_{X_i}(t)\\)\nFGK sumy to suma FGK składników: \\(C_S(t) = \\sum_{i=1}^n C_{X_i}(t)\\)\n\n\n\n\n\n\n\nKluczowa własność\n\n\n\nAddytywność kumulant jest niezwykle użyteczna. Pozwala obliczyć np. wariancję całego portfela poprzez proste zsumowanie wariancji poszczególnych, niezależnych ryzyk.\n\n\nAnaliza modelu ryzyka łącznego (rozkładu złożonego): To jedno z najważniejszych zastosowań. Dla modelu łącznego, gdzie \\(X = Y_1 + \\dots + Y_N\\), zachodzi fundamentalna zależność: \\[C_X(t) = C_N(C_Y(t))\\] Wzór ten pozwala w elegancki sposób wyprowadzić momenty całego portfela, znając jedynie charakterystyki rozkładu liczby i wysokości szkód. Z tej zależności wynikają m.in. kluczowe wzory: \\[E(X) = E(N) \\cdot E(Y)\\] \\[\\text{Var}(X) = \\text{Var}(N) \\cdot [E(Y)]^2 + E(N) \\cdot \\text{Var}(Y)\\]\nCharakterystyka i aproksymacja rozkładów: Momenty i kumulanty, obliczone za pomocą FGM i FGK, dostarczają kluczowych informacji o kształcie rozkładu łącznej straty (np. o jego symetrii i “grubości ogonów”). Informacje te są niezbędne do:\n\nKalkulacji składki ryzyka i kapitału wymaganego.\nWyboru odpowiedniej metody aproksymacji rozkładu łącznej straty (np. aproksymacji normalnej lub przesuniętym rozkładem gamma)."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#inżynieria-ubezpieczeń-życiowych",
    "href": "posts/10-08-2025-first-post/index.html#inżynieria-ubezpieczeń-życiowych",
    "title": "My Post",
    "section": "13. Inżynieria ubezpieczeń życiowych",
    "text": "13. Inżynieria ubezpieczeń życiowych\n\n1. Tablice trwania życia i ich zastosowanie w ubezpieczeniach życiowych.\nTablice trwania życia (ang. life tables) to fundamentalne narzędzie statystyczne i demograficzne, które w formie tabelarycznej przedstawia proces wymierania hipotetycznej grupy osób (tzw. kohorty - grupa badawcza która ze względu na jej właściwość jest poddawana analizie) od momentu urodzenia aż do śmierci ostatniego jej członka. Są one tworzone na podstawie historycznych danych o śmiertelności w danej populacji (np. dla danego kraju, płci i rocznika).\n\nZastosowanie w ubezpieczeniach życiowych:\nNa podstawie tablic trwania życia obliczane są wartości aktuarialne w ubezpieczeniach na życie. Generalne zastosowania:\n\nOcena Ryzyka: Ubezpieczyciel musi oszacować ryzyko, że będzie musiał wypłacić świadczenie. Prawdopodobieństwo zgonu (\\(q_x\\)) jest bezpośrednią miarą tego ryzyka. Im wyższe \\(q_x\\) dla danej grupy wiekowej, tym wyższe ryzyko dla ubezpieczyciela.\nKalkulacja Składek: Prawdopodobieństwa przeżycia i zgonu są podstawą do obliczania składek ubezpieczeniowych. Na przykład w ubezpieczeniu na życie składka będzie zależała od prawdopodobieństwa śmierci w każdym kolejnym roku trwania umowy. W ubezpieczeniu na dożycie kluczowe będzie prawdopodobieństwo przeżycia określonego okresu.\nTworzenie Rezerw Techniczno-Ubezpieczeniowych: Ubezpieczyciel ma obowiązek tworzenia rezerw finansowych na pokrycie przyszłych zobowiązań. Wysokość tych rezerw jest szacowana z wykorzystaniem tablic trwania życia, które pozwalają przewidzieć, ile świadczeń i kiedy będzie trzeba wypłacić w przyszłości.\nWycena Produktów Emerytalnych i Rentowych: W przypadku rent życiowych, które są wypłacane “do końca życia”, tablice pozwalają oszacować, jak długo statystycznie będą trwały wypłaty, co jest kluczowe dla ustalenia wartości takiego produktu i wysokości składki.\n\n\n\n\n2. Pojęcie wartości aktuarialnej w ubezpieczeniach życiowych.\nWartość aktuarialna (nazywana też wartością obecną netto świadczeń lub składką jednorazową netto) to wartość obecna oczekiwanych przyszłych płatności związanych z umową ubezpieczenia.\nwartość aktuarialna ubezpieczenia (składka jednorazowa netto \\(Ā_x\\)) jest zdefiniowana jako wartość oczekiwana zmiennej losowej \\(Z\\), która reprezentuje zdyskontowaną wartość przyszłego świadczenia: \\[Ā_x = E(Z) = E(v^{T(x)})\\] gdzie: - \\(T(x)\\) to przyszły czas życia osoby w wieku x (zmienna losowa). - \\(v^{T(x)}\\) to zdyskontowana wartość świadczenia w wysokości 1, wypłaconego w momencie śmierci.\nWartość aktuarialna świadczenia reprezentuje średni koszt, jaki ubezpieczyciel poniesie w związku z daną polisą, wyrażony w dzisiejszej wartości pieniądza. Jest to kwota, którą ubezpieczyciel musiałby otrzymać w momencie zawarcia umowy (jako jednorazową wpłatę), aby statystycznie być w stanie pokryć przyszłe zobowiązanie. Z tego powodu wartość aktuarialna świadczenia jest tożsama z jednorazową składką netto.\n\n\n3. Obliczanie składek netto w ubezpieczeniach życiowych.\nSkładka netto to część składki ubezpieczeniowej przeznaczona wyłącznie na pokrycie przewidywanych przyszłych świadczeń. Nie uwzględnia ona kosztów administracyjnych, prowizji, zysku ubezpieczyciela ani marginesu na nieprzewidziane ryzyko. Te dodatkowe elementy są zawarte w tzw. składce brutto, którą finalnie płaci klient.\nObliczanie składki netto opiera się na zasadzie równoważności, która mówi, że w momencie zawarcia umowy: \\[\\text{Wartość aktuarialna przyszłych składek} = \\text{Wartość aktuarialna przyszłych świadczeń}\\]\n\nSkładka jednorazowa netto (SJN): Jest to najprostszy przypadek. Skoro składka jest płacona tylko raz, na początku, to jej wartość aktuarialna jest równa jej wysokości. Zgodnie z zasadą równoważności, jest ona po prostu równa wartości aktuarialnej świadczeń. \\[JSN = A_x\\] (gdzie \\(A_x\\) to wartość aktuarialna świadczenia, np. w ubezpieczeniu na życie)\nRozczna składka netto: Jest to znacznie częstszy model, w którym klient płaci składki regularnie (np. co roku) przez cały okres trwania umowy. Strumień tych składek to tzw. renta życiowa.\n\nBezterminowe ubezpieczenie na życie, płatne nakoniec roku śmierci, równe składki coroczne:\n\\[L = v^{K(x)+1} - P_x \\cdot \\ddot{a}_{\\overline{K(x)+1}}\\] czyli\n\\[ P_x = \\frac{A_x}{\\ddot{a}_x} \\] gdzie: - \\(P_x\\) - roczna składka netto; - \\(\\ddot{a}_x\\) - wartość aktuarialna renty życiowej;\nSkładka roczna netto to nic innego jak całkowity, uśredniony koszt ubezpieczenia (\\(A_x\\)), “rozłożony na raty” płatne przez oczekiwany okres opłacania składek (którego wartość jest ujęta w \\(\\ddot{a}_x\\))"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#wdrażanie-modeli-uczenia-maszynowego-1",
    "href": "posts/10-08-2025-first-post/index.html#wdrażanie-modeli-uczenia-maszynowego-1",
    "title": "My Post",
    "section": "3. Wdrażanie modeli uczenia maszynowego",
    "text": "3. Wdrażanie modeli uczenia maszynowego\n\n1. Podstawowe komendy REST API służące do komunikacji.\n\n\n2. Reaktywność i realizacja w aplikacjach Shiny.\n\n\n3. Metody optymalizacji wydajności aplikacji Shiny obsługującej duże zbiory danych."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html",
    "href": "posts/10-08-2025-first-post/index.html",
    "title": "My Post",
    "section": "",
    "text": "Definicja\n\\[\n\\text{Niech } A \\in M_n(K), \\text{gdzie } K = R \\text{lub } K = C. \\text{Wtedy istnieje taka macierz nieosobliwa } P \\in M_n(K) \\text{ taka, że}\n\\]\n\n\n\nDefinicja: Przestrzeń wektorową, w której wprowadzono iloczyn skalarny nazywamy przestrzenią unitarną.\n\n\nMetroda ortogonalizacji Grama-Schmidta:"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#pytania-na-egzamin-dyplomowy-iad",
    "href": "posts/10-08-2025-first-post/index.html#pytania-na-egzamin-dyplomowy-iad",
    "title": "My Post",
    "section": "",
    "text": "Definicja\n\\[\n\\text{Niech } A \\in M_n(K), \\text{gdzie } K = R \\text{lub } K = C. \\text{Wtedy istnieje taka macierz nieosobliwa } P \\in M_n(K) \\text{ taka, że}\n\\]\n\n\n\nDefinicja: Przestrzeń wektorową, w której wprowadzono iloczyn skalarny nazywamy przestrzenią unitarną.\n\n\nMetroda ortogonalizacji Grama-Schmidta:"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#rozkład-graniczny",
    "href": "posts/10-08-2025-first-post/index.html#rozkład-graniczny",
    "title": "My Post",
    "section": "Rozkład graniczny",
    "text": "Rozkład graniczny\n\n\n\n\n\n\nTip\n\n\n\nDefinicja:\nWektor \\(q = (q_j, \\, j \\in S)\\) nazywamy rozkładem ergodycznym."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#twierdzenie",
    "href": "posts/10-08-2025-first-post/index.html#twierdzenie",
    "title": "My Post",
    "section": "Twierdzenie",
    "text": "Twierdzenie\nJeśli łańcuch Markowa \\(\\{Z_n, n \\in \\mathbb{N}_0\\}\\) jest ergodyczny,\nto macierz przejścia w \\(n\\)-tym kroku spełnia:\n\\[\nP^{(n)} \\xrightarrow[n \\to \\infty]{}\n\\begin{bmatrix}\nq_1 & q_2 & q_3 & \\cdots \\\\\nq_1 & q_2 & q_3 & \\cdots \\\\\nq_1 & q_2 & q_3 & \\cdots \\\\\n\\vdots & \\vdots & \\vdots & \\ddots\n\\end{bmatrix}\n\\]\nczyli każdy wiersz macierzy granicznej jest identyczny i równy rozkładowi ergodycznemu \\(q\\)."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#uwaga",
    "href": "posts/10-08-2025-first-post/index.html#uwaga",
    "title": "My Post",
    "section": "Uwaga",
    "text": "Uwaga\n\nWektor \\(q\\) jest jedynym rozkładem stacjonarnym łańcucha.\n\nRozkład graniczny opisuje zachowanie procesu w nieskończoności, niezależnie od stanu początkowego."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#algebra-zaawansowana",
    "href": "posts/10-08-2025-first-post/index.html#algebra-zaawansowana",
    "title": "My Post",
    "section": "1. Algebra zaawansowana",
    "text": "1. Algebra zaawansowana\n\n1. Definicja, własności i wybrane zastosowania macierzy Jordana.\n\nDEFINICJA (Klatka Jordana)\nMacierz \\(J_r(\\lambda) \\in M_r(\\mathbb{K})\\) postaci: \\[\nJ_r(\\lambda) =\n\\begin{pmatrix}\n\\lambda & 1 & 0 & \\cdots & 0 \\\\\n0 & \\lambda & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda & 1 \\\\\n0 & 0 & \\cdots & 0 & \\lambda\n\\end{pmatrix}\n\\] gdzie \\(\\lambda \\in \\mathbb{K}\\), nazywamy klatką Jordana stopnia \\(r\\). W szczególnym przypadku \\(J_1(\\lambda) = [\\lambda]\\).\n\n\nDEFINICJA (Macierz Jordana)\nMacierz blokową \\(J \\in M_n(\\mathbb{K})\\) postaci: \\[\nJ =\n\\begin{pmatrix}\nJ_{n_1}(\\lambda_1) & & & \\\\\n& J_{n_2}(\\lambda_2) & & \\\\\n& & \\ddots & \\\\\n& & & J_{n_k}(\\lambda_k)\n\\end{pmatrix}\n\\] gdzie \\(n_1 + n_2 + \\dots + n_k = n\\), \\(\\lambda_1, \\dots, \\lambda_k \\in \\mathbb{K}\\) oraz wszystkie niewypisane elementy są zerami, nazywamy macierzą Jordana.\n\n\nTWIERDZENIE (Postać Jordana macierzy)\nNiech \\(A \\in M_n(\\mathbb{K})\\), gdzie \\(\\mathbb{K} = \\mathbb{R}\\) lub \\(\\mathbb{K} = \\mathbb{C}\\). Wtedy istnieje macierz nieosobliwa \\(P \\in M_n(\\mathbb{K})\\) taka, że macierz \\(J = P^{-1}AP\\) jest macierzą Jordana. Macierz \\(J\\) nazywamy macierzą Jordana macierzy A. Jest ona wyznaczona jednoznacznie z dokładnością do kolejności klatek Jordana.\n\n\nWłasności Macierzy Jordana\n\nWartości własne: Skalary \\(\\lambda_1, \\dots, \\lambda_k\\) tworzące główną przekątną macierzy Jordana \\(J\\) są jej wartościami własnymi.\nZwiązek z diagonalizacją: Każda macierz diagonalna jest macierzą Jordana (z klatkami wymiaru 1x1). Oznacza to, że każda macierz diagonalizowalna jest podobna do pewnej macierzy Jordana.\nLiczba klatek Jordana:\n\nLiczba wszystkich klatek Jordana w macierzy \\(J\\) jest równa liczbie liniowo niezależnych wektorów własnych macierzy \\(A\\).\nLiczba klatek Jordana odpowiadających konkretnej wartości własnej \\(\\lambda\\) jest równa wymiarowi podprzestrzeni własnej \\(W_\\lambda\\) (krotności geometrycznej tej wartości własnej).\n\nRozmiar klatek Jordana: Suma stopni (wymiarów) wszystkich klatek Jordana odpowiadających wartości własnej \\(\\lambda\\) jest równa krotności algebraicznej tej wartości własnej (czyli jej krotności jako pierwiastka wielomianu charakterystycznego).\nWektory dołączone: Struktura macierzy Jordana (liczba i rozmiary klatek) jest ściśle powiązana z istnieniem tzw. wektorów dołączonych. Dla wartości własnej \\(\\lambda\\) o krotności algebraicznej \\(r\\) istnieje dokładnie \\(r\\) liniowo niezależnych wektorów dołączonych, które tworzą bazę Jordana.\n\n\n\nWybrane Zastosowania Macierzy Jordana\nGłównym zastosowaniem przedstawionym w materiałach jest uproszczenie obliczeń funkcji macierzy.\n\n\nTWIERDZENIE\nJeżeli \\(f\\) jest wielomianem o współczynnikach z ciała \\(\\mathbb{K}\\), zaś \\(J\\) jest macierzą Jordana w postaci blokowej jak w definicji, to zachodzi równość: \\[\nf(J) =\n\\begin{pmatrix}\nf(J_{n_1}(\\lambda_1)) & & & \\\\\n& f(J_{n_2}(\\lambda_2)) & & \\\\\n& & \\ddots & \\\\\n& & & f(J_{n_k}(\\lambda_k))\n\\end{pmatrix}\n\\] Obliczenie funkcji dla całej macierzy sprowadza się do obliczenia jej dla poszczególnych klatek Jordana.\n\n\nTWIERDZENIE (Funkcja klatki Jordana)\nJeżeli \\(J_r(\\lambda)\\) jest klatką Jordana stopnia \\(r\\), to wartość funkcji \\(f(J_r(\\lambda))\\) można obliczyć za pomocą następującego wzoru, wykorzystującego pochodne funkcji \\(f\\): \\[\nf(J_r(\\lambda)) =\n\\begin{pmatrix}\nf(\\lambda) & f'(\\lambda) & \\frac{f''(\\lambda)}{2!} & \\cdots & \\frac{f^{(r-1)}(\\lambda)}{(r-1)!} \\\\\n0 & f(\\lambda) & f'(\\lambda) & \\cdots & \\frac{f^{(r-2)}(\\lambda)}{(r-2)!} \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & f(\\lambda) & f'(\\lambda) \\\\\n0 & 0 & \\cdots & 0 & f(\\lambda)\n\\end{pmatrix}\n\\] To zastosowanie jest kluczowe np. przy obliczaniu eksponenty macierzy \\(e^{At}\\), co jest fundamentalne w rozwiązywaniu układów równań różniczkowych liniowych.\n\n\n\n2. Definicja przestrzeni unitarnej i metoda ortogonalizacji Grama-Schmidta.\nDefinicja: Przestrzeń wektorową, w której wprowadzono iloczyn skalarny nazywamy przestrzenią unitarną.\n\n\nMetroda ortogonalizacji Grama-Schmidta:\n\n\n\n3. Wybrane metody dekompozycji macierzy.\n\nRozkład \\(LU\\)\nRozkład \\(QR\\)\nRozkład \\(SVD\\)\nRozkład \\(Shura\\)\nRozkłąd \\(Choleskiego\\)"
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#definicja-macierzy-jordana",
    "href": "posts/10-08-2025-first-post/index.html#definicja-macierzy-jordana",
    "title": "My Post",
    "section": "Definicja Macierzy Jordana",
    "text": "Definicja Macierzy Jordana\nPodstawowym budulcem macierzy Jordana jest klatka Jordana.\n\nDEFINICJA (Klatka Jordana)\nMacierz \\(J_r(\\lambda) \\in M_r(\\mathbb{K})\\) postaci: \\[\nJ_r(\\lambda) =\n\\begin{pmatrix}\n\\lambda & 1 & 0 & \\cdots & 0 \\\\\n0 & \\lambda & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda & 1 \\\\\n0 & 0 & \\cdots & 0 & \\lambda\n\\end{pmatrix}\n\\] gdzie \\(\\lambda \\in \\mathbb{K}\\), nazywamy klatką Jordana stopnia \\(r\\). W szczególnym przypadku \\(J_1(\\lambda) = [\\lambda]\\).\n\n\nDEFINICJA (Macierz Jordana)\nMacierz blokową \\(J \\in M_n(\\mathbb{K})\\) postaci: \\[\nJ =\n\\begin{pmatrix}\nJ_{n_1}(\\lambda_1) & & & \\\\\n& J_{n_2}(\\lambda_2) & & \\\\\n& & \\ddots & \\\\\n& & & J_{n_k}(\\lambda_k)\n\\end{pmatrix}\n\\] gdzie \\(n_1 + n_2 + \\dots + n_k = n\\), \\(\\lambda_1, \\dots, \\lambda_k \\in \\mathbb{K}\\) oraz wszystkie niewypisane elementy są zerami, nazywamy macierzą Jordana.\n\n\nTWIERDZENIE (Postać Jordana macierzy)\nNiech \\(A \\in M_n(\\mathbb{K})\\), gdzie \\(\\mathbb{K} = \\mathbb{R}\\) lub \\(\\mathbb{K} = \\mathbb{C}\\). Wtedy istnieje macierz nieosobliwa \\(P \\in M_n(\\mathbb{K})\\) taka, że macierz \\(J = P^{-1}AP\\) jest macierzą Jordana. Macierz \\(J\\) nazywamy macierzą Jordana macierzy A. Jest ona wyznaczona jednoznacznie z dokładnością do kolejności klatek Jordana."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#własności-macierzy-jordana",
    "href": "posts/10-08-2025-first-post/index.html#własności-macierzy-jordana",
    "title": "My Post",
    "section": "Własności Macierzy Jordana",
    "text": "Własności Macierzy Jordana\n\nWartości własne: Skalary \\(\\lambda_1, \\dots, \\lambda_k\\) tworzące główną przekątną macierzy Jordana \\(J\\) są jej wartościami własnymi.\nZwiązek z diagonalizacją: Każda macierz diagonalna jest macierzą Jordana (z klatkami wymiaru 1x1). Oznacza to, że każda macierz diagonalizowalna jest podobna do pewnej macierzy Jordana.\nLiczba klatek Jordana:\n\nLiczba wszystkich klatek Jordana w macierzy \\(J\\) jest równa liczbie liniowo niezależnych wektorów własnych macierzy \\(A\\).\nLiczba klatek Jordana odpowiadających konkretnej wartości własnej \\(\\lambda\\) jest równa wymiarowi podprzestrzeni własnej \\(W_\\lambda\\) (krotności geometrycznej tej wartości własnej).\n\nRozmiar klatek Jordana: Suma stopni (wymiarów) wszystkich klatek Jordana odpowiadających wartości własnej \\(\\lambda\\) jest równa krotności algebraicznej tej wartości własnej (czyli jej krotności jako pierwiastka wielomianu charakterystycznego).\nWektory dołączone: Struktura macierzy Jordana (liczba i rozmiary klatek) jest ściśle powiązana z istnieniem tzw. wektorów dołączonych. Dla wartości własnej \\(\\lambda\\) o krotności algebraicznej \\(r\\) istnieje dokładnie \\(r\\) liniowo niezależnych wektorów dołączonych, które tworzą bazę Jordana."
  },
  {
    "objectID": "posts/10-08-2025-first-post/index.html#wybrane-zastosowania-macierzy-jordana",
    "href": "posts/10-08-2025-first-post/index.html#wybrane-zastosowania-macierzy-jordana",
    "title": "My Post",
    "section": "Wybrane Zastosowania Macierzy Jordana",
    "text": "Wybrane Zastosowania Macierzy Jordana\nGłównym zastosowaniem przedstawionym w materiałach jest uproszczenie obliczeń funkcji macierzy.\n\nTWIERDZENIE\nJeżeli \\(f\\) jest wielomianem o współczynnikach z ciała \\(\\mathbb{K}\\), zaś \\(J\\) jest macierzą Jordana w postaci blokowej jak w definicji, to zachodzi równość: \\[\nf(J) =\n\\begin{pmatrix}\nf(J_{n_1}(\\lambda_1)) & & & \\\\\n& f(J_{n_2}(\\lambda_2)) & & \\\\\n& & \\ddots & \\\\\n& & & f(J_{n_k}(\\lambda_k))\n\\end{pmatrix}\n\\] Obliczenie funkcji dla całej macierzy sprowadza się do obliczenia jej dla poszczególnych klatek Jordana.\n\n\nTWIERDZENIE (Funkcja klatki Jordana)\nJeżeli \\(J_r(\\lambda)\\) jest klatką Jordana stopnia \\(r\\), to wartość funkcji \\(f(J_r(\\lambda))\\) można obliczyć za pomocą następującego wzoru, wykorzystującego pochodne funkcji \\(f\\): \\[\nf(J_r(\\lambda)) =\n\\begin{pmatrix}\nf(\\lambda) & f'(\\lambda) & \\frac{f''(\\lambda)}{2!} & \\cdots & \\frac{f^{(r-1)}(\\lambda)}{(r-1)!} \\\\\n0 & f(\\lambda) & f'(\\lambda) & \\cdots & \\frac{f^{(r-2)}(\\lambda)}{(r-2)!} \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & f(\\lambda) & f'(\\lambda) \\\\\n0 & 0 & \\cdots & 0 & f(\\lambda)\n\\end{pmatrix}\n\\] To zastosowanie jest kluczowe np. przy obliczaniu eksponenty macierzy \\(e^{At}\\), co jest fundamentalne w rozwiązywaniu układów równań różniczkowych liniowych.\n\n\n2. Definicja przestrzeni unitarnej i metoda ortogonalizacji Grama-Schmidta.\nDefinicja: Przestrzeń wektorową, w której wprowadzono iloczyn skalarny nazywamy przestrzenią unitarną.\n\n\nMetroda ortogonalizacji Grama-Schmidta:\n\n\n\n3. Wybrane metody dekompozycji macierzy.\n\nRozkład \\(LU\\)\nRozkład \\(QR\\)\nRozkład \\(SVD\\)\nRozkład \\(Shura\\)\nRozkłąd \\(Choleskiego\\)"
  }
]